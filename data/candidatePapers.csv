"id","score","title","summary","venue","year","authors","citationCount","referenceCount","influentialCitationCount","url"
"075b6fb7d3787953164eecc1bd2e13f97c9f3c44",7,"Fault-Aware Neural Code Rankers","C ODE R ANKER is a neural ranker that can predict the correctness of a sampled program without executing it and can signiﬁcantly increase the pass@1 accuracy of various code generation models on APPS, HumanEval, and MBPP datasets.","ArXiv",2022,"J. Inala,Chenglong Wang,Mei Yang,Andrés Codas,Mark Encarnaci'on,Shuvendu K. Lahiri,M. Musuvathi,Jianfeng Gao",6,41,2,"https://www.semanticscholar.org/paper/075b6fb7d3787953164eecc1bd2e13f97c9f3c44"
"239b5649b12f28fd610de036afba41b9246db6c9",7,"Parsel: A Unified Natural Language Framework for Algorithmic Reasoning","This work introduces Parsel 2, a framework enabling automatic implementation and validation of complex algorithms with code LLMs, based on hierarchical function descriptions in natural language, which can be used across domains requiring hierarchical reasoning, e.g. code synthesis, theorem proving, and robotic planning.","ArXiv",2022,"E. Zelikman,Qian Huang,Gabriel Poesia,Noah D. Goodman,N. Haber",0,65,0,"https://www.semanticscholar.org/paper/239b5649b12f28fd610de036afba41b9246db6c9"
"b2c4fdb49bdb23e6ad0ac3272029324157046ea7",6,"Automated Repair of Code from Language Models","The study revealed that automatically generated code shares common programming mistakes with human-crafted solutions, indicating APR techniques may have potential to auto-generated code, and given bug location information provided by a statistical fault localization approach, Codex edit mode is similar to or better than existing Java repair tools TBar and Recoder in correcting incorrect solutions.","",2022,"Zhiyu Fan,Xiang Gao,M. Mirchev,Abhik Roychoudhury,Shin Hwei Tan",0,49,0,"https://www.semanticscholar.org/paper/b2c4fdb49bdb23e6ad0ac3272029324157046ea7"
"0bcd59da541fdae66884afba8d25475a54a9da1a",6,"Automated Repair of Programs from Large Language Models","The study revealed that automatically generated code shares common programming mistakes with human-crafted solutions, indicating APR techniques may have potential to auto-generated code, and given bug location information provided by a statistical fault localization approach, Codex edit mode is similar to or better than existing Java repair tools TBar and Recoder in correcting incorrect solutions.","",2022,"Zhiyu Fan,Xiang Gao,M. Mirchev,Abhik Roychoudhury,Shin Hwei Tan",0,49,0,"https://www.semanticscholar.org/paper/0bcd59da541fdae66884afba8d25475a54a9da1a"
"6074c7b75f27ca9adb6d74b080c07d5d079c3ea0",6,"Improving automatically generated code from Codex via Automated Program Repair","This study systematically study whether automated program repair (APR) techniques can fix the incorrect solutions produced by language models in LeetCode contests, revealing that automatically generated codes share some common programming mistakes with human-crafted solutions, indicating existing APR tools have the potential to fix auto-generated code.","ArXiv",2022,"Zhiyu Fan,Xiang Gao,Abhik Roychoudhury,Shin Hwei Tan",4,45,0,"https://www.semanticscholar.org/paper/6074c7b75f27ca9adb6d74b080c07d5d079c3ea0"
"35afb74de9660962ebac2843d26de22a6fac2ef6",6,"Learning from Self-Sampled Correct and Partially-Correct Programs","This work proposes to let the model perform sampling during training and learn from both self-sampled fully-Correct programs, which yield the gold execution results, as well as partially-correct programs, whose intermediate execution state matches another correct program.","ArXiv",2022,"Ansong Ni,J. Inala,Chenglong Wang,Oleksandr Polozov,Christopher Meek,Dragomir R. Radev,Jianfeng Gao",4,28,3,"https://www.semanticscholar.org/paper/35afb74de9660962ebac2843d26de22a6fac2ef6"
"045a6f92b58f08d5b305dd5d661316a506ee4d43",6,"Test-Driven Multi-Task Learning with Functionally Equivalent Code Transformation for Neural Code Generation","A method combining program analysis with deep learning for neural code generation, where functionally equivalent code snippets and test execution feedback will be considered at the training stage, and preliminary results on a newly published dataset demonstrate the effectiveness.","International Conference on Automated Software Engineering",2022,"Xin Wang,Xiao Liu,Pingyi Zhou,Qixia Liu,Jin Liu,Hao Wu,Xiao Cui",0,40,0,"https://www.semanticscholar.org/paper/045a6f92b58f08d5b305dd5d661316a506ee4d43"
"a3e355b5de868f34fdfa2500415c5f74c69d2091",6,"Recommending Root-Cause and Mitigation Steps for Cloud Incidents using Large Language Models","A rigorous study on the effectiveness of large language models for helping engineers root cause and mitigate production incidents, and a human evaluation with actual incident owners show the future potential of using artiﬁcial intelligence for resolving cloud incidents.","ArXiv",2023,"Toufique Ahmed,Supriyo Ghosh,Chetan Bansal,T. Zimmermann,Xuchao Zhang,S. Rajmohan",0,63,0,"https://www.semanticscholar.org/paper/a3e355b5de868f34fdfa2500415c5f74c69d2091"
"1c336c18e53ad878bf4688c864acd99f137ae29f",5,"Interactive Code Generation via Test-Driven User-Intent Formalization","This paper proposes the workflow of test-driven user-intent formalization (TDUIF), which leverages lightweight user feedback to jointly formalize the user intent as tests (a partial specification), and generates code that meets the formal user intent.","ArXiv",2022,"Shuvendu K. Lahiri,Aaditya Naik,Georgios Sakkas,Piali Choudhury,Curtis von Veh,M. Musuvathi,J. Inala,Chenglong Wang,Jianfeng Gao",2,27,0,"https://www.semanticscholar.org/paper/1c336c18e53ad878bf4688c864acd99f137ae29f"
"3d5463a16d85d9d1d0d8ebb4117a31aca3c240ff",5,"Fooling MOSS Detection with Pretrained Language Models","It is found that a student using GPT-J can complete introductory level programming assignments without triggering suspicion from MOSS, a widely used software similarity and plagiarism detection tool.","International Conference on Information and Knowledge Management",2022,"Stella Rose Biderman,Edward Raff",2,70,0,"https://www.semanticscholar.org/paper/3d5463a16d85d9d1d0d8ebb4117a31aca3c240ff"
"06ea568379211ffa07d9605f66f26f6f736ea5e0",5,"PanGu-Coder: Program Synthesis with Function-Level Language Modeling","A pretrained decoder-only language model adopting the P AN G U - α architecture for text-to-code generation, i.e. the synthesis of programming language solutions given a natural language problem description is presented.","ArXiv",2022,"Fenia Christopoulou,Gerasimos Lampouras,Milan Gritta,Guchun Zhang,Yinpeng Guo,Zhong-Yi Li,Qi Zhang,M. Xiao,Bo Shen,Lin Li,Hao Yu,Li-yu Yan,Pingyi Zhou,Xin Wang,Yu Ma,Ignacio Iacobacci,Yasheng Wang,Guangtai Liang,Jia Wei,Xin Jiang,Qianxiang Wang,Qun Liu",6,72,0,"https://www.semanticscholar.org/paper/06ea568379211ffa07d9605f66f26f6f736ea5e0"
"1b4c19168410fb2690d285b205ab2281793db81a",5,"A Scalable and Extensible Approach to Benchmarking NL2Code for 18 Programming Languages","It is shown that on several languages, Codex matches and even exceeds its performance on Python, and a general approach is described for easily adding support for new benchmarks and languages to MultiPL-E, the first multi-language parallel benchmark for natural-language-to-code-generation.","ArXiv",2022,"Federico Cassano,John Gouwar,Daniel Nguyen,S. Nguyen,Luna Phipps-Costin,Donald Pinckney,Ming-Ho Yee,Yangtian Zi,Carolyn Jane Anderson,Molly Q. Feldman,Arjun Guha,M. Greenberg,Abhinav Jangda",2,27,0,"https://www.semanticscholar.org/paper/1b4c19168410fb2690d285b205ab2281793db81a"
"6032212d5790b6a580d68d469a9895aad6238c89",5,"Diverse Title Generation for Stack Overflow Posts with Multiple Sampling Enhanced Transformer","A novel approach to automatically generate multiple post titles from the given code snippets, using the maximal marginal multiple nucleus sampling strategy to generate multiple high-quality and diverse title candidates at a time for the developers to choose from.","ArXiv",2022,"Fengji Zhang,Jin Liu,Yao Wan,Xiao Yu,Xiao Liu,J. Keung",0,56,0,"https://www.semanticscholar.org/paper/6032212d5790b6a580d68d469a9895aad6238c89"
"d8405996b4d08c304098636aedd9e1c1a1e262ee",5,"The Premature Obituary of Programming","Why deep learning will not replace programming and why deep learning should not be considered as a programming language.","",2023,"Daniel M. Yellin",0,23,0,"https://www.semanticscholar.org/paper/d8405996b4d08c304098636aedd9e1c1a1e262ee"
"407b9e9478ba6bff43ce4b20e8b6cb2b303477d2",4,"P LANNING WITH L ARGE L ANGUAGE M ODELS FOR C ODE G ENERATION","A novel Transformer decoding algorithm that uses a planning algorithm to do lookahead search and guide the Transformer to generate better programs, and enables controllable code generation, such as concise codes and highly-commented codes by optimizing modified objectives.","",2022,"",0,43,0,"https://www.semanticscholar.org/paper/407b9e9478ba6bff43ce4b20e8b6cb2b303477d2"
"6f84d0cc33c7c58f74b28ddcc1cbda91ea608c9f",4,"C ODE S UMMARIZATION : D O T RANSFORMERS R E ALLY U C","Overall, the quality of the generated summaries even from state-of-the-art (SOTA) models is quite poor, raising questions about the utility of current approaches and datasets.","",2022,"Manasi S. Patwardhan,L. Vig,Raveendra Kumar Medicherla,Ravindra Naik,Gautam M. Shroff",0,40,0,"https://www.semanticscholar.org/paper/6f84d0cc33c7c58f74b28ddcc1cbda91ea608c9f"
"3b0cf543a730e674d4213d344ebc857fada76ead",4,"Understanding High-Level Properties of Low-Level Programs Through Transformers","It is shown that Transformer models can translate C to LLVM-IR with high accuracy, by training on a parallel corpus of functions extract from 1 million compilable, open-sourced C programs and its corresponding LL VM-IR after compiling with Clang.","",2022,"William S. Moses",0,63,0,"https://www.semanticscholar.org/paper/3b0cf543a730e674d4213d344ebc857fada76ead"
"3fbc8d04a1f3dba58bdaada1924ee132512e98be",4,"Productivity assessment of neural code completion","It is found that the rate with which shown suggestions are accepted, rather than more specific metrics regarding the persistence of completions in the code over time, drives developers’ perception of productivity.","MAPS@PLDI",2022,"Albert Ziegler,Eirini Kalliamvakou,Shawn Simister,Ganesh Sittampalam,X. A. Li,A. Rice,Devon Rifkin,E. Aftandilian",15,23,2,"https://www.semanticscholar.org/paper/3fbc8d04a1f3dba58bdaada1924ee132512e98be"
"1100dee3fd78655cddc4b7bfaef1161351d4fab5",4,"Automated Feedback Generation for Competition-Level Code","This work presents Clef, the first data-driven tool that can generate feedback on competition-level code automatically by repairing programmers’ incorrect submissions, and introduces a new data structure, merge trees, to capture the changes between submissions.","International Conference on Automated Software Engineering",2022,"Jialu Zhang,De Li,John C. Kolesar,Hanyuan Shi,R. Piskac",1,48,0,"https://www.semanticscholar.org/paper/1100dee3fd78655cddc4b7bfaef1161351d4fab5"
"618d17d60fcdd5da1fd1d1e2b7e19a47af9c9ba7",4,"What is it like to program with artificial intelligence?","This paper explores how programming with large language models (LLM-assisted programming) is similar to, and differs from, prior conceptualisations of programmer assistance, and draws upon publicly available experience reports of LLM- assisted programming, as well as prior usability and design studies.","ArXiv",2022,"Advait Sarkar,A. Gordon,C. Negreanu,Christian Poelitz,Sruti Srinivasa Ragavan,B. Zorn",4,97,2,"https://www.semanticscholar.org/paper/618d17d60fcdd5da1fd1d1e2b7e19a47af9c9ba7"
"a7435722d8ab595da5a9c70ac9160f57d0dcd75a",4,"Enabling Transformers to Understand Low-Level Programs","This work applies transfer learning to low-level (LLVM) programs and study how low- level programs can be made more amenable to Transformer models through various techniques, including preprocessing, infix/prefix operators, and information deduplication.","IEEE Conference on High Performance Extreme Computing",2022,"Zifan Carl Guo,William S. Moses",0,53,0,"https://www.semanticscholar.org/paper/a7435722d8ab595da5a9c70ac9160f57d0dcd75a"
"8a854331c593c6a766fa3b8037fb2ad1b95a6f06",4,"An Empirical Study of Code Smells in Transformer-based Code Generation Techniques","This study investigates to what extent code smells are present in the datasets of coding generation techniques and verify whether they leak into the output of these techniques.","IEEE Working Conference on Source Code Analysis and Manipulation",2022,"Mohammed Latif Siddiq,Shafayat H. Majumder,Maisha R. Mim,Sourov Jajodia,Joanna C. S. Santos",3,57,1,"https://www.semanticscholar.org/paper/8a854331c593c6a766fa3b8037fb2ad1b95a6f06"
"39e40821b7207125e54e6ed7112e55cd38c6f0c3",4,"Language Models of Code are Few-Shot Commonsense Learners","This paper shows that when this task is frame as code generation tasks, pre-trained LMs of code are better structured commonsense reasoners than L Ms of natural language, even when the downstream task does not involve source code at all.","ArXiv",2022,"Aman Madaan,Shuyan Zhou,Uri Alon,Yiming Yang,Graham Neubig",9,38,1,"https://www.semanticscholar.org/paper/39e40821b7207125e54e6ed7112e55cd38c6f0c3"
"a6ef5bad716091fb1888bf365f6129628ab3a5ee",4,"ObSynth: An Interactive Synthesis System for Generating Object Models from Natural Language Specifications","ObSynth is introduced, an interactive system leveraging the domain knowledge em-bedded in large language models (LLMs) to help users design object models from high level natural language prompts, showing that it often synthesizes objects, methods, and methods users might have otherwise omitted.","ArXiv",2022,"Alex Gu,Tamara Mitrovska,D. Vélez,Jacob Andreas,Armando Solar-Lezama",0,29,0,"https://www.semanticscholar.org/paper/a6ef5bad716091fb1888bf365f6129628ab3a5ee"
"ec7324a15009a9bd0b676f6b17762f759cf5dd9a",4,"Large Language Models Are Human-Level Prompt Engineers","It is shown that APE-engineered prompts can be applied to steer models toward truthfulness and/or informativeness, as well as to improve few-shot learning performance by simply prepending them to standard in-context learning prompts.","ArXiv",2022,"Yongchao Zhou,Andrei Ioan Muresanu,Ziwen Han,Keiran Paster,Silviu Pitis,Harris Chan,Jimmy Ba",5,51,1,"https://www.semanticscholar.org/paper/ec7324a15009a9bd0b676f6b17762f759cf5dd9a"
"32b58766a1bfcef7ebba07070a272687aa518206",4,"Explicit Knowledge Transfer for Weakly-Supervised Code Generation","It is shown that EKT not only yields better performance than training with expert iteration, but also outperforms knowledge distillation, another form of knowledge transfer, and it is possible for a student model to outperform the teacher using EKT.","ArXiv",2022,"Zhangir Azerbayev,Ansong Ni,Hailey Schoelkopf,Dragomir R. Radev",0,25,0,"https://www.semanticscholar.org/paper/32b58766a1bfcef7ebba07070a272687aa518206"
"9e8f0d9ba4e7af673c8b214b3764e020706dd1f3",4,"Don't Generate, Discriminate: A Proposal for Grounding Language Models to Real-World Environments","Pangu is proposed, a generic framework for grounded language understanding that capitalizes on the discriminative ability of LMs instead of their generative ability, and enables, for the first time, effective few-shot in-context learning for KBQA with large LMs such as Codex.","ArXiv",2022,"Yu Gu,Xiang Deng,Yu Su",0,66,0,"https://www.semanticscholar.org/paper/9e8f0d9ba4e7af673c8b214b3764e020706dd1f3"
"dae74645479f7c1fa3671066f9e24ec6c20c17ec",4,"TrojanPuzzle: Covertly Poisoning Code-Suggestion Models","Two novel data poisoning attacks are demonstrated, C OVERT and T ROJAN P UZZLE, that can bypass static analysis by planting malicious poisoning data in out-of-context regions such as docstrings and have implications for how practitioners should select code used to be coded.","ArXiv",2023,"H. Aghakhani,Wei Dai,Andre Manoel,Xavier Fernandes,Anant Kharkar,Christopher Kruegel,Giovanni Vigna,David Evans,B. Zorn,Robert Sim",0,57,0,"https://www.semanticscholar.org/paper/dae74645479f7c1fa3671066f9e24ec6c20c17ec"
"b1eebb2df3b9ff7ff2b00fb1a786f6ada2caebce",3,"Towards a Mathematics Formalisation Assistant using Large Language Models","The abilities of a large language model (Codex) to help with formalisation in the Lean theorem prover are explored, finding that with careful inputdependent prompt selection and postprocessing, Codex is able to formalise short mathematical statements at undergrad level with nearly 75% accuracy for 120 theorem statements.","ArXiv",2022,"Ayush Agrawal,Siddhartha Gadgil,Navin Goyal,Ashvni Narayanan,Anand Tadipatri",0,26,0,"https://www.semanticscholar.org/paper/b1eebb2df3b9ff7ff2b00fb1a786f6ada2caebce"
"f7664102a451332ed7e1286561b2f621eaff128d",3,"Programming Puzzles","A positive correlation between puzzlesolving performance and coding experience, and between the puzzle difficulty for humans and AI solvers are found, and further improvements on P3 could have a significant impact on many program synthesis areas.","NeurIPS Datasets and Benchmarks",2021,"Tal Schuster,A. Kalyan,Oleksandr Polozov,A. Kalai",12,83,0,"https://www.semanticscholar.org/paper/f7664102a451332ed7e1286561b2f621eaff128d"
"92173d081b15824d22a9ef070e118744ceee8052",3,"Show Your Work: Scratchpads for Intermediate Computation with Language Models","Surprisingly, large pre-trained language models are able to perform complex multistep computations—even in the few-shot regime—when asked to perform the operation “step by step”, showing the results of intermediate computations.","ArXiv",2021,"Maxwell Nye,Anders Andreassen,Guy Gur-Ari,H. Michalewski,Jacob Austin,David Bieber,David Dohan,Aitor Lewkowycz,Maarten Bosma,D. Luan,Charles Sutton,Augustus Odena",102,30,10,"https://www.semanticscholar.org/paper/92173d081b15824d22a9ef070e118744ceee8052"
"a5731122200fbb8b37f048010a1e1ca4474aa606",3,"Examining Zero-Shot Vulnerability Repair with Large Language Models","This work examines the use of large language models for code (such as OpenAI’s Codex and AI21's Jurassic J-1) for zero-shot vulnerability repair, and investigates challenges in the design of prompts that coax LLMs into generating repaired versions of insecure code.","",2021,"H. Pearce,B. Tan,Baleegh Ahmad,R. Karri,Brendan Dolan-Gavitt",1,56,0,"https://www.semanticscholar.org/paper/a5731122200fbb8b37f048010a1e1ca4474aa606"
"5ff9032d0f7f246d01ae7b2c231ab03469a7344a",3,"Can OpenAI Codex and Other Large Language Models Help Us Fix Security Bugs?","This work examines the use of large language models for code (such as OpenAI's Codex and AI21's Jurassic J-1) for zero-shot vulnerability repair, and investigates challenges in the design of prompts that coax LLMs into generating repaired versions of insecure code.","ArXiv",2021,"H. Pearce,B. Tan,Baleegh Ahmad,R. Karri,Brendan Dolan-Gavitt",20,56,1,"https://www.semanticscholar.org/paper/5ff9032d0f7f246d01ae7b2c231ab03469a7344a"
"9a2ca811882ed7513f83014b9de4fb3b4ab218c4",3,"C OMPOSITIONAL G ENERALIZATION AND D ECOMPOSITION IN N EURAL P ROGRAM S YNTHESIS","A suite of generalization tasks, which measure different types of compositional generalization that are desirable for program synthesis and are particularly difﬁcult for current sequence to sequence models, are proposed.","",,"",0,0,0,"https://www.semanticscholar.org/paper/9a2ca811882ed7513f83014b9de4fb3b4ab218c4"
"a2b6e1f7d8a7963d321f29fca7c01eeb1ebd7f0f",3,"P ATCH G ENERATION WITH L ANGUAGE M ODELS : F EASIBILITY AND S CALING B EHAVIOR","This work highlights a noticeable correlation of model size with test-passing accuracy and patch ranking quality, and the propensity for especially the largest models to generate candidate patches that closely resemble (if not exactly match), the original developer patch.","",2022,"Sophia Kolak,Ruben Martins,Claire Le Goues,V. Hellendoorn",0,23,0,"https://www.semanticscholar.org/paper/a2b6e1f7d8a7963d321f29fca7c01eeb1ebd7f0f"
"78863000eb70945cc8d791d45d4a3fe8a6521cb6",3,"Open-Ended Knowledge Tracing for Computer Science Education","This paper develops an initial solution to the OKT problem, a student knowledge-guided code generation approach that combines program synthesis methods using language models with student knowledge tracing methods and conducts a series of quantitative and qualitative experiments to validate OKT and demonstrate its promise in educational applications.","",2022,"Naiming Liu,Zichao Wang",0,54,0,"https://www.semanticscholar.org/paper/78863000eb70945cc8d791d45d4a3fe8a6521cb6"
"1aed58bd07026492194672adec494dc37c894a28",3,"Leveraging Automated Unit Tests for Unsupervised Code Translation","This work proposes to leverage an automated unit-testing system to filter out invalid translations, thereby creating a fully tested parallel corpus, and finds that fine-tuning an unsupervised model with this filtered data set significantly reduces the noise in the translations so-generated, comfortably outperforming the state of the art for all language pairs studied.","International Conference on Learning Representations",2021,"Baptiste Rozière,J Zhang,François Charton,M. Harman,Gabriel Synnaeve,Guillaume Lample",16,60,1,"https://www.semanticscholar.org/paper/1aed58bd07026492194672adec494dc37c894a28"
"52db8674337e5d86dcb96d013734befc8c3d4581",3,"Large Language Models are not Models of Natural Language: they are Corpus Models.","It is argued that the term language model is misleading because deep learning models are not theoretical models of language and proposed the adoption of corpus model instead, which better reflects the genesis and contents of the model.","IEEE Access",2021,"C. Veres",1,63,0,"https://www.semanticscholar.org/paper/52db8674337e5d86dcb96d013734befc8c3d4581"
"7b5aa186ca8abc585607c5ec91562e127a398601",3,"Open-Ended Knowledge Tracing","This paper develops an initial solution to the OKT problem, a student knowledge-guided code generation approach that combines program synthesis methods using language models with student knowledge tracing methods and conducts a series of quantitative and qualitative experiments on a real-world student code dataset to validate OKT and demonstrate its promise in educational applications.","ArXiv",2022,"Naiming Liu,Zichao Wang,Richard Baraniuk,Andrew S. Lan",0,64,0,"https://www.semanticscholar.org/paper/7b5aa186ca8abc585607c5ec91562e127a398601"
"1f11601f9eb8c0bee1d1d2cc7f4fa187e8c5e525",3,"The impact of lexical and grammatical processing on generating code from natural language","The paper highlights the importance of the lexical substitution component in the current natural language to code systems with a state-of-the-art architecture that relies on BERT encoder and a grammar-based decoder for which a formalization is provided.","Findings",2022,"Nathanael Beau,Benoit Crabb'e",4,19,2,"https://www.semanticscholar.org/paper/1f11601f9eb8c0bee1d1d2cc7f4fa187e8c5e525"
"c96363c42bc8c465902c22b8c33c8704233f519e",3,"MCoNaLa: A Benchmark for Code Generation from Multiple Natural Languages","A multilingual dataset, MCoNaLa, is proposed to benchmark code generation from natural language commands extending beyond English, and a quantitative evaluation of performance on the M coNaLa dataset is presented by testing with state-of-theart code generation systems.","ArXiv",2022,"Zhiruo Wang,Grace Cuenca,Shuyan Zhou,Frank F. Xu,Graham Neubig",6,50,2,"https://www.semanticscholar.org/paper/c96363c42bc8c465902c22b8c33c8704233f519e"
"771371fb288da26a9812f5808535847a0a9c9a80",3,"A Conversational Paradigm for Program Synthesis","This work proposes and trains C ODE G EN, an interactive code generation model for program synthesis, and suggests that the capacity of conversational program synthesis scales as a function of the model size and data size.","ArXiv",2022,"Erik Nijkamp,Bo Pang,Hiroaki Hayashi,Lifu Tu,Haiquan Wang,Yingbo Zhou,S. Savarese,Caiming Xiong",52,39,19,"https://www.semanticscholar.org/paper/771371fb288da26a9812f5808535847a0a9c9a80"
"094ff971d6a8b8ff870946c9b3ce5aa173617bfb",3,"PaLM: Scaling Language Modeling with Pathways","A 540-billion parameter, densely activated, Transformer language model, which is called PaLM achieves breakthrough performance, outperforming the state-of-the-art on a suite of multi-step reasoning tasks, and outperforming average human performance on the recently released BIG-bench benchmark.","ArXiv",2022,"Aakanksha Chowdhery,Sharan Narang,Jacob Devlin,Maarten Bosma,Gaurav Mishra,Adam Roberts,P. Barham,Hyung Won Chung,Charles Sutton,Sebastian Gehrmann,Parker Schuh,Kensen Shi,Sasha Tsvyashchenko,Joshua Maynez,Abhishek Rao,Parker Barnes,Yi Tay,Noam M. Shazeer,Vinodkumar Prabhakaran,Emily Reif,Nan Du,B. Hutchinson,Reiner Pope,James Bradbury,Jacob Austin,M. Isard,Guy Gur-Ari,Pengcheng Yin,Toju Duke,Anselm Levskaya,S. Ghemawat,Sunipa Dev,H. Michalewski,Xavier García,Vedant Misra,Kevin Robinson,L. Fedus,Denny Zhou,Daphne Ippolito,D. Luan,Hyeontaek Lim,Barret Zoph,A. Spiridonov,Ryan Sepassi,David Dohan,Shivani Agrawal,Mark Omernick,Andrew M. Dai,T. S. Pillai,Marie Pellat,Aitor Lewkowycz,Erica Moreira,Rewon Child,Oleksandr Polozov,Katherine Lee,Zongwei Zhou,Xuezhi Wang,Brennan Saeta,Mark Díaz,Orhan Firat,Michele Catasta,Jason Wei,K. Meier-Hellstern,D. Eck,J. Dean,Slav Petrov,Noah Fiedel",470,173,68,"https://www.semanticscholar.org/paper/094ff971d6a8b8ff870946c9b3ce5aa173617bfb"
"6a250b904965732840a75b6a13e35ac15f5cce4d",3,"Compositional Generalization and Decomposition in Neural Program Synthesis","A suite of generalization tasks, which measure different types of compositional generalization that are desirable for program synthesis and are particularly difﬁcult for current sequence to sequence models, are proposed.","ArXiv",2022,"Kensen Shi,Joey Hong,M. Zaheer,Pengcheng Yin,Charles Sutton",0,67,0,"https://www.semanticscholar.org/paper/6a250b904965732840a75b6a13e35ac15f5cce4d"
"bb7e46f316d319f9819c3554c99995ef8361ae9c",3,"CodexDB: Generating Code for Processing SQL Queries using GPT-3 Codex","CodexDB is a framework on top of GPT-3 Codex that decomposes complex SQL queries into a series of simple processing steps, described in natural language, enriched with user-provided instructions and descriptions of database properties.","ArXiv",2022,"Immanuel Trummer",1,29,0,"https://www.semanticscholar.org/paper/bb7e46f316d319f9819c3554c99995ef8361ae9c"
"1f87dc41bdf2c4c78e2dce9c5c8adfef5e25a70c",3,"Passport: Improving Automated Formal Verification Using Identifiers","Passport is a fully-automated proof-synthesis tool that encodes one additional aspect of that rich proof data: identifiers, suggesting that modeling identifiers can play a significant role in improving proof synthesis, leading to higher-quality software.","ArXiv",2022,"Alex Sanchez-Stern,E. First,Timothy Zhou,Zhanna Kaufman,Yuriy Brun,T. Ringer",3,73,0,"https://www.semanticscholar.org/paper/1f87dc41bdf2c4c78e2dce9c5c8adfef5e25a70c"
"9a7d4c2f4309a2a38ea8e5b23c6d616fa0952d44",3,"Neural language models for network configuration: Opportunities and reality check","Recent advances in deep learning applied to programming languages are surveyed, for the purpose of code veriﬁcation, synthesis and translation: in particularly, their training requirements and expected performance are reviewed, and qualitatively assess whether similar techniques can bene⬁t corresponding use-cases in networking.","Computer Communications",2022,"Zied Ben-Houidi,Dario Rossi",3,63,0,"https://www.semanticscholar.org/paper/9a7d4c2f4309a2a38ea8e5b23c6d616fa0952d44"
"0efa0441da820b1905572666ba1974a06a9663fb",3,"NaturalProver: Grounded Mathematical Proof Generation with Language Models","N ATURAL P ROVER is capable of proving some theorems that require short (2-6 step) proofs, and providing next-step suggestions that are rated as correct and useful over 40% of the time, which is to the authors' knowledge the first demonstration of these capabilities using neural language models.","ArXiv",2022,"S. Welleck,Jiacheng Liu,Ximing Lu,Hannaneh Hajishirzi,Yejin Choi",6,53,1,"https://www.semanticscholar.org/paper/0efa0441da820b1905572666ba1974a06a9663fb"
"2edc8efcda27c944a46f367acf6a5280b8f65525",3,"FixEval: Execution-based Evaluation of Program Fixes for Competitive Programming Problems","This work introduces F IX E VAL, a benchmark comprising of buggy code submissions to competitive programming problems and their respective ﬁxes, and believes it provides a step towards real-world automatic bugﬁxing and model-generated code evaluation.","ArXiv",2022,"Md. Mahim Anjum Haque,W. Ahmad,Ismini Lourentzou,Chris Brown",0,56,0,"https://www.semanticscholar.org/paper/2edc8efcda27c944a46f367acf6a5280b8f65525"
"1d160123cbbef972ea151a641dd435d57c727de8",3,"AixBench: A Code Generation Benchmark Dataset","A benchmark dataset for evaluating method-level code generation task and a new metric for automatically evaluating the correctness of the generated code, and a set of criteria to manually evaluating the overall quality of thegenerated code are presented.","ArXiv",2022,"Yiyang Hao,Ge Li,Yongqiang Liu,Xiaowei Miao,He Zong,Siyuan Jiang,Yang Liu,He Wei",1,4,0,"https://www.semanticscholar.org/paper/1d160123cbbef972ea151a641dd435d57c727de8"
"ab0e3d3e4d42369de5933a3b4c237780b41c0d77",3,"Solving Quantitative Reasoning Problems with Language Models","","ArXiv",2022,"Aitor Lewkowycz,Anders Andreassen,David Dohan,Ethan Dyer,H. Michalewski,V. Ramasesh,Ambrose Slone,Cem Anil,Imanol Schlag,Theo Gutman-Solo,Yuhuai Wu,Behnam Neyshabur,Guy Gur-Ari,Vedant Misra",60,51,11,"https://www.semanticscholar.org/paper/ab0e3d3e4d42369de5933a3b4c237780b41c0d77"
"ef29fb8cc6bdda4b011288f51da521d3c25fc53d",3,"Learning to Prevent Profitless Neural Code Completion","An early-rejection mechanism to turn down low-return prompts by foretelling the completion qualities without sending them to the LCM is proposed and a lightweight Transformer-based estimator is proposed to demonstrate the feasibility of the mechanism.","ArXiv",2022,"Zhensu Sun,Xiaoning Du,Fu Song,Shangwen Wang,Mingze Ni,Li Li",0,51,0,"https://www.semanticscholar.org/paper/ef29fb8cc6bdda4b011288f51da521d3c25fc53d"
"971e875e28f26240987d2c9470d1ee74ad204205",3,"Large Language Models are Few-shot Testers: Exploring LLM-based General Bug Reproduction","Results show L IBRO has the potential to enhance developerency by automatically generating tests from bug reports, and is proposed as a framework that uses Large Language Models (LLMs), which have been shown to be capable of performing code-related tasks.","ArXiv",2022,"Sungmin Kang,Juyeon Yoon,Shin Yoo",0,39,0,"https://www.semanticscholar.org/paper/971e875e28f26240987d2c9470d1ee74ad204205"
"95fa2b27ab7eb84738441ee16da97323538938f9",3,"I Speak, You Verify: Toward Trustworthy Neural Program Synthesis","An approach for improving the trustworthiness and overall accuracy of program synthesizers based on large language models for source code by analyzing the agreement between programs and predicates to judge both which program is most likely to be correct and whether the language model is able to solve the programming problem in the first place.","ArXiv",2022,"Darren Key,Wen-Ding Li,Kevin Ellis",0,34,0,"https://www.semanticscholar.org/paper/95fa2b27ab7eb84738441ee16da97323538938f9"
"0b8772b7790c69f40897b5eb7f8fd57f24138f3d",3,"ContraGen: Effective Contrastive Learning For Causal Language Model","It is shown that C ONTRA G EN can effectively enhance both uniformity and discrimination of the representations and lead to the desired improvement on various language understanding tasks where discriminative representations are crucial for attaining good performance.","ArXiv",2022,"Nihal Jain,Dejiao Zhang,Wasi Uddin Ahmad,Zijian Wang,Feng Nan,Xiaopeng Li,M. Tan,Ramesh Nallapati,Baishakhi Ray,Parminder Bhatia,Xiaofei Ma,Bing Xiang",0,66,0,"https://www.semanticscholar.org/paper/0b8772b7790c69f40897b5eb7f8fd57f24138f3d"
"0c78a473e33a81246d5c0fbbda7e7de168814c18",3,"FlexType: A Plug-and-Play Framework for Type Inference Models","This work introduces FlexType, an IDE extension that can be used on both JavaScript and TypeScript to infer types in an interactive or automatic fashion and believes the interactive Visual Studio Code extension is inherently useful in both TypeScript and JavaScript especially when resolving types is taxing for the developer.","International Conference on Automated Software Engineering",2022,"Sivani Voruganti,Kevin Jesse,Prem Devanbu",0,39,0,"https://www.semanticscholar.org/paper/0c78a473e33a81246d5c0fbbda7e7de168814c18"
"663a41c866d49ce052801fbc88947d39764cad29",3,"Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them","It is found that applying chain-of-thought (CoT) prompting to BBH tasks enables PaLM to surpass the average human-rater performance on 10 of the 23 tasks, and Codex to surpass it on 17 of the23 tasks.","ArXiv",2022,"Mirac Suzgun,Nathan Scales,Nathanael Scharli,Sebastian Gehrmann,Yi Tay,Hyung Won Chung,Aakanksha Chowdhery,Quoc V. Le,E. Chi,Denny Zhou,Jason Wei",18,55,5,"https://www.semanticscholar.org/paper/663a41c866d49ce052801fbc88947d39764cad29"
"f031ba42cf82f106200bb03fbb91dd5671a59b9c",3,"Practical Program Repair in the Era of Large Pre-trained Language Models","This study demonstrates that directly applying state-of-the-art PLMs can already substantially outperform all existing APR techniques on all the authors' datasets and shows that PLM-based APR can be further substantially boosted via: increasing the sample size, and incorporating inﬁx template information.","ArXiv",2022,"Chun Xia,Yuxiang Wei,Lingming Zhang",2,69,0,"https://www.semanticscholar.org/paper/f031ba42cf82f106200bb03fbb91dd5671a59b9c"
"5f86bbe35dbca8d932b3110f0c98a6b2d06a0b5b",3,"Reading Between the Lines: Modeling User Behavior and Costs in AI-Assisted Programming","This work studied GitHub Copilot, developed CUPS– a taxonomy of 12 programmer activities common to AI code completion systems, and conducted a study with 21 programmers who completed coding tasks and used the labeling tool to retrospectively label their sessions with CUPS.","ArXiv",2022,"Hussein Mozannar,Gagan Bansal,Adam Fourney,E. Horvitz",0,32,0,"https://www.semanticscholar.org/paper/5f86bbe35dbca8d932b3110f0c98a6b2d06a0b5b"
"71280dba5bda65c162f9deaffed7d3d20692ca0a",3,"SecurityEval dataset: mining vulnerability examples to evaluate machine learning-based code generation techniques","SecurityEval, an evaluation dataset that contains 130 samples for 75 vulnerability types, which are mapped to the Common Weakness Enumeration (CWE) and demonstrated using one open-source and one closed-source code generation model to evaluate.","",2022,"Mohammed Latif Siddiq,msiddiq",2,28,0,"https://www.semanticscholar.org/paper/71280dba5bda65c162f9deaffed7d3d20692ca0a"
"327f1561b544b0a3b9d8d5d0e6d82c2a5911fca9",3,"BLOOM: A 176B-Parameter Open-Access Multilingual Language Model","BLOOM is a 176B-parameter open-access language model designed and built thanks to a collaboration of hundreds of researchers and achieves competitive performance on a wide variety of benchmarks, with stronger results after undergoing multitask prompted finetuning.","ArXiv",2022,"Teven Le Scao,Angela Fan,Christopher Akiki,Elizabeth-Jane Pavlick,Suzana Ili'c,Daniel Hesslow,Roman Castagn'e,A. Luccioni,Franccois Yvon,Matthias Gallé,J. Tow,Alexander M. Rush,Stella Rose Biderman,Albert Webson,Pawan Sasanka Ammanamanchi,Thomas Wang,Benoît Sagot,Niklas Muennighoff,Albert Villanova del Moral,Olatunji Ruwase,Rachel Bawden,Stas Bekman,Angelina McMillan-Major,Iz Beltagy,Huu Nguyen,Lucile Saulnier,Samson Tan,Pedro Ortiz Suarez,Victor Sanh,Hugo Laurenccon,Yacine Jernite,Julien Launay,Margaret Mitchell,Colin Raffel,Aaron Gokaslan,Adi Simhi,Aitor Soroa Etxabe,Alham Fikri Aji,Amit Alfassy,Anna Rogers,Ariel Kreisberg Nitzav,Canwen Xu,Chenghao Mou,Chris C. Emezue,Christopher Klamm,Colin Leong,Daniel Alexander van Strien,David Ifeoluwa Adelani,Dragomir R. Radev,Eduardo G. Ponferrada,Efrat Levkovizh,Ethan Kim,E. Natan,F. Toni,Gérard Dupont,Germán Kruszewski,Giada Pistilli,Hady ElSahar,Hamza Benyamina,Hieu Tran,Ian Yu,Idris Abdulmumin,Isaac Johnson,Itziar Gonzalez-Dios,Javier de la Rosa,Jenny Chim,Jesse Dodge,Jian Zhu,Jonathan Chang,Jorg Frohberg,Josephine L. Tobing,J. Bhattacharjee,Khalid Almubarak,Kimbo Chen,Kyle Lo,Leandro von Werra,Leon Weber,Long Phan,Loubna Ben Allal,Ludovic Tanguy,Manan Dey,M. Muñoz,Maraim Masoud,Mar'ia Grandury,Mario vSavsko,Max Huang,Maximin Coavoux,Mayank Singh,Mike Tian-Jian Jiang,Minh Chien Vu,M. A. Jauhar,Mustafa Ghaleb,Nishant Subramani,Nora Kassner,Nurulaqilla Khamis,Olivier Nguyen,Omar Espejel,Ona de Gibert,Paulo Villegas,Peter Henderson,Pierre Colombo,Priscilla Amuok,Quentin Lhoest,Rheza Harliman,Rishi Bommasani,R. L'opez,Rui Ribeiro,Salomey Osei,Sampo Pyysalo,Sebastian Nagel,Shamik Bose,Shamsuddeen Hassan Muhammad,Shanya Sharma,S. Longpre,Somaieh Nikpoor,Stanislav Silberberg,S. Pai,S. Zink,Tiago Timponi Torrent,Timo Schick,Tristan Thrush,V. Danchev,Vassilina Nikoulina,Veronika Laippala,Violette Lepercq,V. Prabhu,Zaid Alyafeai,Zeerak Talat,Arun Raja,Benjamin Heinzerling,Chenglei Si,Elizabeth Salesky,Sabrina J. Mielke,Wilson Y. Lee,Abheesht Sharma,Andrea Santilli,Antoine Chaffin,Arnaud Stiegler,Debajyoti Datta,Eliza Szczechla,Gunjan Chhablani,Han Wang,Harshit Pandey,Hendrik Strobelt,Jason Alan Fries,Jos Rozen,Leo Gao,Lintang Sutawika,M Saiful Bari,Maged S. Al-shaibani,Matteo Manica,Nihal V. Nayak,Ryan Teehan,Samuel Albanie,Sheng Shen,Srulik Ben-David,Stephen H. Bach,Taewoon Kim,T. Bers,Thibault Févry,Trishala Neeraj,Urmish Thakker,Vikas Raunak,Xiang Tang,Zheng Xin Yong,Zhiqing Sun,Shaked Brody,Y. Uri,Hadar Tojarieh,Adam Roberts,Hyung Won Chung,Jaesung Tae,Jason Phang,Ofir Press,Conglong Li,D. Narayanan,Hatim Bourfoune,J. Casper,Jeff Rasley,Max Ryabinin,Mayank Mishra,Minjia Zhang,M. Shoeybi,Myriam Peyrounette,N. Patry,Nouamane Tazi,Omar Sanseviero,Patrick von Platen,Pierre Cornette,Pierre Franccois Lavall'ee,R. Lacroix,Samyam Rajbhandari,Sanchit Gandhi,Shaden Smith,S. Requena,Suraj Patil,Tim Dettmers,Ahmed Baruwa,Amanpreet Singh,Anastasia Cheveleva,Anne-Laure Ligozat,Arjun Subramonian,Aur'elie N'ev'eol,Charles Lovering,Daniel H Garrette,D. Tunuguntla,Ehud Reiter,Ekaterina Taktasheva,E. Voloshina,Eli Bogdanov,Genta Indra Winata,Hailey Schoelkopf,Jan-Christoph Kalo,Jekaterina Novikova,J. Forde,Jordan Clive,Jungo Kasai,Ken Kawamura,Liam Hazan,Marine Carpuat,Miruna Clinciu,Najoung Kim,Newton Cheng,Oleg Serikov,Omer Antverg,Oskar van der Wal,Rui Zhang,Ruochen Zhang,Sebastian Gehrmann,S. Pais,Tatiana Shavrina,Thomas Scialom,Tian Yun,Tomasz Limisiewicz,Verena Rieser,Vitaly Protasov,V. Mikhailov,Yada Pruksachatkun,Yonatan Belinkov,Zachary Bamberger,Zdenvek Kasner,Alice Rueda,Amanda Pestana,A. Feizpour,Ammar Khan,Amy Faranak,A. Santos,A. Hevia,Antigona Unldreaj,Arash Aghagol,Arezoo Abdollahi,A. Tammour,Azadeh HajiHosseini,Bahareh Behroozi,B. Ajibade,B. Saxena,Carlos Muñoz Ferrandis,Danish Contractor,D. Lansky,Davis David,Douwe Kiela,D. A. Nguyen,Edward Tan,Emily Baylor,Ezinwanne Ozoani,Fatim T Mirza,Frankline Ononiwu,Habib Rezanejad,H.A. Jones,Indrani Bhattacharya,Irene Solaiman,Irina Sedenko,I. Nejadgholi,J. Passmore,Joshua Seltzer,Julio Bonis Sanz,Karen Fort,L. Dutra,Mairon Samagaio,Maraim Elbadri,M. Mieskes,Marissa Gerchick,Martha Akinlolu,Michael McKenna,Mike Qiu,M. Ghauri,Mykola Burynok,Nafis Abrar,Nazneen Rajani,Nour Elkott,N. Fahmy,O. Samuel,Ran An,R. Kromann,Ryan Hao,S. Alizadeh,Sarmad Shubber,Silas L. Wang,Sourav Roy,S. Viguier,Thanh-Cong Le,Tobi Oyebade,T. Le,Yoyo Yang,Z. Nguyen,Abhinav Ramesh Kashyap,Alfredo Palasciano,A. Callahan,Anima Shukla,Antonio Miranda-Escalada,A. Singh,Benjamin Beilharz,Bo Wang,C. Brito,Chenxi Zhou,Chirag Jain,Chuxin Xu,Clémentine Fourrier,Daniel Le'on Perin'an,Daniel Molano,Dian Yu,Enrique Manjavacas,Fabio Barth,Florian Fuhrimann,Gabriel Altay,Giyaseddin Bayrak,Gully A. Burns,Helena U. Vrabec,I. Bello,Isha Dash,J. Kang,John Giorgi,J. Golde,J. Posada,Karthi Sivaraman,Lokesh Bulchandani,Lu Liu,Luisa Shinzato,Madeleine Hahn de Bykhovetz,Maiko Takeuchi,Marc Pàmies,M. A. Castillo,Marianna Nezhurina,Mario Sanger,M. Samwald,Michael Cullan,Michael Weinberg,M. Wolf,Mina Mihaljcic,Minna Liu,M. Freidank,Myungsun Kang,Natasha Seelam,N. Dahlberg,N. Broad,N. Muellner,Pascale Fung,Patricia Haller,R. Chandrasekhar,R. Eisenberg,Robert Martin,Rodrigo L. Canalli,Rosaline Su,Ruisi Su,Samuel Cahyawijaya,Samuele Garda,Shlok S Deshmukh,Shubhanshu Mishra,Sid Kiblawi,Simon Ott,Sinee Sang-aroonsiri,Srishti Kumar,Stefan Schweter,S. Bharati,T. A. Laud,Th'eo Gigant,Tomoya Kainuma,Wojciech Kusa,Yanis Labrak,Yashasvi Bajaj,Y. Venkatraman,Yifan Xu,Ying Xu,Yun-chao Xu,Z. Tan,Zhongli Xie,Zifan Ye,M. Bras,Younes Belkada,Thomas Wolf",35,157,6,"https://www.semanticscholar.org/paper/327f1561b544b0a3b9d8d5d0e6d82c2a5911fca9"
"a4bdc300db297756f36bedee2859b62df8e268c2",3,"Follow the Wisdom of the Crowd: Effective Text Generation via Minimum Bayes Risk Decoding","This work presents crowd sampling, a family of decoding methods based on Bayesian risk minimization, to ad-dress this diversity-quality trade-off in open-ended natural-language generation.","ArXiv",2022,"Mirac Suzgun,Luke Melas-Kyriazi,Dan Jurafsky",3,83,0,"https://www.semanticscholar.org/paper/a4bdc300db297756f36bedee2859b62df8e268c2"
"20b60fb3993d2e9a5af04611f7bdf248e5a3a736",3,"Programming by Example and Text-to-Code Translation for Conversational Code Generation","Modular Programs for Text-guided Hierarchical Synthesis (MPaTHS), a method for integrating Programming by Example and text-to-code systems which uses an accessible natural language interface for synthesizing general programs, is proposed.","ArXiv",2022,"Eli Whitehouse,William Gerard,Yauhen Klimovich,Marc Franco-Salvador",0,21,0,"https://www.semanticscholar.org/paper/20b60fb3993d2e9a5af04611f7bdf248e5a3a736"
"30624a18720bf93a85dc3efe570df271a8c9f4c3",3,"Program Repair","Keeping intermediate rules, instead of producing the most generalized rule by generalizing all concrete transformations, enables us to apply the most suitable rule to transform a given code.","ArXiv",2022,"Xiang Gao,Yannic Noller,Abhik Roychoudhury",2,105,0,"https://www.semanticscholar.org/paper/30624a18720bf93a85dc3efe570df271a8c9f4c3"
"8175ce2cbb99b6a394bdac152ae39d413f4f1380",3,"Codex Hacks HackerRank: Memorization Issues and a Framework for Code Synthesis Evaluation","This work evaluates the code synthesis capabilities of the Codex model based on a set of 115 Python problem statements from a popular competitive programming portal: HackerRank, and proposes a framework for code-synthesis evaluation using variations of problem statements based on mutations.","ArXiv",2022,"Anjan Karmakar,Julian Aron Prenner,Marco D'Ambros,R. Robbes",1,37,0,"https://www.semanticscholar.org/paper/8175ce2cbb99b6a394bdac152ae39d413f4f1380"
"6bc87e51018d6de55011e95a0d43c588dd44a1e8",3,"ERNIE-Code: Beyond English-Centric Cross-lingual Pretraining for Programming Languages","This work releases ERNIE-Code, a uniﬁed pre-trained language model for 116 NLs and 6 PLs, and employs two methods for universal cross-lingual pre-training: span-corruption language modeling that learns patterns from monolingual NL or PL; and pivot-based translationlanguage modeling that re-lies on parallel data of manyNLs and PLs.","ArXiv",2022,"Yekun Chai,Shuohuan Wang,Chao Pang,Yu Sun,Hao Tian,Hua Wu",1,42,0,"https://www.semanticscholar.org/paper/6bc87e51018d6de55011e95a0d43c588dd44a1e8"
"bf5fbd690f24f873df86d1b0a06579cf42f7dc36",3,"Dialog2API: Task-Oriented Dialogue with API Description and Example Programs","An approach tailored for the Dialog2API, where the dialogue states are represented by a stack of programs, with most recently mentioned program on the top of the stack, is proposed.","ArXiv",2022,"Raphael Shu,Elman Mansimov,Tamer Alkhouli,Nikolaos Pappas,Salvatore Romeo,Arshit Gupta,Saab Mansour,Yi Zhang,D. Roth",0,32,0,"https://www.semanticscholar.org/paper/bf5fbd690f24f873df86d1b0a06579cf42f7dc36"
"0f38267a8ba32789f5d3b1b19820f86940fea052",3,"Generation-Augmented Query Expansion For Code Retrieval","This paper proposes a generation-augmented query expansion framework that leverages the code generation model to enhance the code retrieval task and achieves new state-of-the-art results on the CodeSearchNet benchmark and surpass the baselines signiﬁcantly.","ArXiv",2022,"Dong Li,Yelong Shen,Ruoming Jin,Yi Mao,Kuan Wang,Weizhu Chen",0,25,0,"https://www.semanticscholar.org/paper/0f38267a8ba32789f5d3b1b19820f86940fea052"
"269df328eec08b56b7b1f38a7555797fe2b999b6",3,"ReCode: Robustness Evaluation of Code Generation Models","This paper proposes ReCode, a comprehensive robustness evaluation benchmark for code generation models, and customizable over 30 transformations for code on docstrings, function and variable names, code syntax, and code format, which provide multifaceted assessments of a model’s robustness performance.","ArXiv",2022,"Shiqi Wang,Zheng Li,Haifeng Qian,Cheng Yang,Zijian Wang,Mingyue Shang,Varun Kumar,Samson Tan,Baishakhi Ray,Parminder Bhatia,Ramesh Nallapati,M. Ramanathan,D. Roth,Bing Xiang",0,35,0,"https://www.semanticscholar.org/paper/269df328eec08b56b7b1f38a7555797fe2b999b6"
"e9a64e58855dbbc725203d0202ceb9e7f8b7bb36",2,"A Survey of Learning-based Automated Program Repair","This work presents a meta-modelling system that automates the very labor-intensive and therefore time-heavy and therefore expensive and expensive process of manually cataloging and cataloging individual neurons in the brain.","ArXiv",2023,"Quanjun Zhang,Chunrong Fang,Yuxiang Ma,Weisong Sun,Zhenyu Chen",0,185,0,"https://www.semanticscholar.org/paper/e9a64e58855dbbc725203d0202ceb9e7f8b7bb36"
"6df98ac2300c6e9c232440147ba976b4f501ca67",2,"C ODEX HACKS H ACKER R ANK : B ENEFITS AND R ISKS OF L ARGE -S CALE S OURCE C ODE M ODELS","These studies evaluate Codex on code synthesis, similar to the approach, but their evaluation efforts remain limited to math problems.","",2022,"",0,56,0,"https://www.semanticscholar.org/paper/6df98ac2300c6e9c232440147ba976b4f501ca67"
"4ddc26b3a5fe9044b97b408d163f7464d769ebbf",2,"CODEP: Grammatical Seq2Seq Model for General-Purpose Code Generation","This paper proposes CODEP, a grammatical Seq2Seq code generation framework equipped with a Pushdown automaton (PDA) module, and constructs the DPA for the most popular GPL Python and conducts extensive experiments to evaluate the effectiveness.","ArXiv",2022,"Yihong Dong,Ge Li,Zhi Jin",1,41,0,"https://www.semanticscholar.org/paper/4ddc26b3a5fe9044b97b408d163f7464d769ebbf"
"3cba16fc46ac5b35c1cc72a822208aa0097384cc",2,"CodePAD: Sequence-based Code Generation with Pushdown Automaton","This paper devise a pushdown automaton (PDA)-based methodology to address the problem of grammar constraints of programming language (PL), and proposes CodePAD, a sequence-based code generation framework equipped with a PDA module, to integrate the deduction of PDA into deep learning.","",2022,"Yihong Dong,Xue Jiang,Yuchen Liu,Ge Li,Zhi Jin",0,40,0,"https://www.semanticscholar.org/paper/3cba16fc46ac5b35c1cc72a822208aa0097384cc"
"c125b0be73c8493ebc27beb572f6c1b21d6b4ae4",2,"Static Prediction of Runtime Errors by Learning to Execute Programs with External Resource Descriptions","Surprisingly, it is shown that the model can also predict the location of the error, despite being trained only on labels indicating the presence/absence and kind of error.","ArXiv",2022,"David Bieber,Rishab Goel,Daniel Zheng,H. Larochelle,Daniel Tarlow",1,36,0,"https://www.semanticscholar.org/paper/c125b0be73c8493ebc27beb572f6c1b21d6b4ae4"
"713bd2971116098211ef06336dfbe91a69854404",2,"Probing Semantic Grounding in Language Models of Code with Representational Similarity Analysis","This paper probes representations from the CodeBERT model for semantic grounding by using the data from the IBM CodeNet dataset, and shows that using bimodalinputs over unimodal inputs gives better semantic grounding and sample eﬃciency during semantic ﬁne-tuning.","International Conference on Advanced Data Mining and Applications",2022,"Shounak Naik,Rajaswa Patil,Swati Agarwal,V. Baths",0,18,0,"https://www.semanticscholar.org/paper/713bd2971116098211ef06336dfbe91a69854404"
"27e3ca4fd7b8290a0e12ca4fd2b7ad5bcd5900f2",2,"Are Transformers All That Karel Needs?","By changing the base architecture to a transformer based one, speciﬁcally GPT2, this work is able to apply simple execution guidance on top to achieve a generalization accurary of 89.64%, which is within 2.36 percentage points of the current state-of-the-art on Karel which uses ensembling.","",2021,"Abhay Garg,Anand Sriraman,Kunal Pagarey,S. Karande",0,37,0,"https://www.semanticscholar.org/paper/27e3ca4fd7b8290a0e12ca4fd2b7ad5bcd5900f2"
"27d16a7f2ce8f2b787b34ff1f9b4fece079700c3",2,"Figuring out Figures: Using Textual References to Caption Scientific Figures","This work uses the S CI C AP datasets curated by Hsu et al. and uses a variant of a CLIP+GPT-2 encoder-decoder model with cross-attention to generate captions conditioned on the image, and uses SciBERT to encode the textual metadata and uses this encoding alongside the figure embedding.","",2022,"Stanley Cao,Kevin Liu",0,25,0,"https://www.semanticscholar.org/paper/27d16a7f2ce8f2b787b34ff1f9b4fece079700c3"
"7497360b0f411a44aa6afbd8b830050c40ec8aed",2,"Dataset of Student Solutions to Algorithm and Data Structure Programming Assignments","This paper presents a dataset containing source code solutions to algorithmic programming exercises solved by hundreds of Bachelor-level students at the University of Hamburg, and plans to extend the dataset with tasks and solutions from upcoming courses.","International Conference on Language Resources and Evaluation",2022,"Fynn Petersen-Frey,Marcus Soll,Louis Kobras,Melf Johannsen,Peter Kling,Chris Biemann",0,18,0,"https://www.semanticscholar.org/paper/7497360b0f411a44aa6afbd8b830050c40ec8aed"
"317208b423d24d52ba04221cfb46956962364e22",2,"Extracting Meaningful Attention on Source Code: An Empirical Study of Developer and Neural Model Code Exploration","This work empirically evaluates attention-agnostic heuris-tics and ten attention-based post processing approaches of the attention signal against the ground truth of developers exploring code, including the novel concept of follow-up attention which exhibits the highest agreement.","ArXiv",2022,"Matteo Paltenghi,Rahul Pandita,Austin Z. Henley,Albert Ziegler",0,42,0,"https://www.semanticscholar.org/paper/317208b423d24d52ba04221cfb46956962364e22"
"e5993b3afe6384b5e6f90093989773ad1f868f71",2,"Towards Top-Down Deep Code Generation in Limited Scopes","A semantic pyramid framework (SPF) is proposed as the approach, focusing on softwares of high modularity and low complexity, and introduces a three-layer semantic pyramid (SP) to associate text data and code data.","ArXiv",2022,"Jian Gu,H. Gall",0,38,0,"https://www.semanticscholar.org/paper/e5993b3afe6384b5e6f90093989773ad1f868f71"
"bab6893ee48d168d27c227c3b0867f6d471fbea8",2,"Language Models are not Models of Language","It is argued that the term language model is misleading because deep learning models are not theoretical models of language and proposed the adoption of corpus model instead, which better reflects the genesis and contents of the model.","ArXiv",2021,"C. Veres",0,58,0,"https://www.semanticscholar.org/paper/bab6893ee48d168d27c227c3b0867f6d471fbea8"
"4f278ab5ad629267e06196e273252262854c1c57",2,"BF++: a language for general-purpose program synthesis","A new programming language, BF ++ is proposed, designed speciﬁcally for automatic programming of agents in a Partially Observable Markov Decision Process (POMDP) setting and apply neural program synthesis to solve standard OpenAI Gym benchmarks.","",2021,"Vadim Liventsev,A. Harma,M. Petkovi'c",0,57,0,"https://www.semanticscholar.org/paper/4f278ab5ad629267e06196e273252262854c1c57"
"57d1e7ac339e783898f2c3b1af55737cbeee9fc5",2,"Measuring Mathematical Problem Solving With the MATH Dataset","This work introduces MATH, a new dataset of 12, 500 challenging competition mathematics problems which can be used to teach models to generate answer derivations and explanations, and shows that accuracy remains relatively low, even with enormous Transformer models.","NeurIPS Datasets and Benchmarks",2021,"Dan Hendrycks,Collin Burns,Saurav Kadavath,Akul Arora,Steven Basart,Eric Tang,D. Song,J. Steinhardt",85,65,19,"https://www.semanticscholar.org/paper/57d1e7ac339e783898f2c3b1af55737cbeee9fc5"
"98485ce6532d69f34a8ec67de6b09a39532bd221",2,"Communicating Natural Programs to Humans and Machines","LARC, the Language-complete ARC is presented, a collection of natural language descriptions by a group of human participants who instruct each other on how to solve ARC tasks using language alone, which contains successful instructions for 88% of the ARC tasks.","ArXiv",2021,"Samuel Acquaviva,Yewen Pu,Marta Kryven,Catherine Wong,Gabrielle Ecanow,Maxwell Nye,Theo Sechopoulos,Michael Henry Tessler,J. Tenenbaum",7,87,0,"https://www.semanticscholar.org/paper/98485ce6532d69f34a8ec67de6b09a39532bd221"
"58a6ca2ae28a618126f71a07262cb958a8c37904",2,"Latent Execution for Neural Program Synthesis","LaSynth learns the latent representation to approximate the execution of partially generated programs, even if they are incomplete in syntax, and significantly improves the performance of next token prediction over existing approaches, facilitating search.","",2021,"Xinyun Chen,D. Song,Yuandong Tian",2,60,0,"https://www.semanticscholar.org/paper/58a6ca2ae28a618126f71a07262cb958a8c37904"
"4885e616e85d420576196b2578525cbc501137ec",2,"Programming and execution models for next generation code intelligence systems (keynote)","","ESEC/SIGSOFT FSE",2021,"M. Mezini",0,22,0,"https://www.semanticscholar.org/paper/4885e616e85d420576196b2578525cbc501137ec"
"3f97c2067cde9377e50b3160bbd7982c94abd88a",2,"An Empirical Cybersecurity Evaluation of GitHub Copilot's Code Contributions","This work systematically investigates the prevalence and conditions that can cause GitHub Copilot to recommend insecure code, and explores Copilot’s performance on three distinct code generation axes—examining how it performs given diversity of weaknesses, diversity of prompts, and diversity of domains.","ArXiv",2021,"H. Pearce,Baleegh Ahmad,Benjamin Tan,Brendan Dolan-Gavitt,R. Karri",19,29,1,"https://www.semanticscholar.org/paper/3f97c2067cde9377e50b3160bbd7982c94abd88a"
"a176b0de62840f7118006277d94bbc1547162a4d",2,"Learning to Synthesize Programs as Interpretable and Generalizable Policies","Experimental results demonstrate that the proposed framework not only learns to reliably synthesize task-solving programs but also outperforms DRL and program synthesis baselines while producing interpretable and more generalizable policies.","Neural Information Processing Systems",2021,"Dweep Trivedi,Jesse Zhang,Shao-Hua Sun,Joseph J. Lim",13,131,2,"https://www.semanticscholar.org/paper/a176b0de62840f7118006277d94bbc1547162a4d"
"a8863de15a5ee8eed98107f423138a1a8f5a2ba8",2,"Multi-modal program inference: a marriage of pre-trained language models and component-based synthesis","This work presents an approach that combines PTMs with component-based synthesis (CBS): PTMs are used to generate candidates programs from the natural language description of the task, which are then used to guide the CBS procedure to find the program that matches the precise examples-based specification.","Proc. ACM Program. Lang.",2021,"Kia Rahmani,Mohammad Raza,Sumit Gulwani,Vu Le,Daniel Morris,Arjun Radhakrishna,Gustavo Soares,A. Tiwari",16,77,0,"https://www.semanticscholar.org/paper/a8863de15a5ee8eed98107f423138a1a8f5a2ba8"
"bc9598dc4ed0472d8b59b87ed3a139f8347d40ee",2,"Towards A Measure Of General Machine Intelligence","A common language of instruction is proposed, a programming language that allows the expression of programs in the form of directed acyclic graphs across a wide variety of real-world domains and computing platforms and evaluates the suitability of some well-known models as general intelligence systems by calculating their g-index scores.","ArXiv",2021,"Gautham Venkatasubramanian,Sibesh Kar,Abhimanyu Singh,Shubham Mishra,Dushyant Yadav,Shreyansh Chandak",0,71,0,"https://www.semanticscholar.org/paper/bc9598dc4ed0472d8b59b87ed3a139f8347d40ee"
"05c2e1ee203be217f100d2da05bdcc52004f00b6",2,"Unsolved Problems in ML Safety","This work provides a new roadmap for ML Safety and presents four problems ready for research, namely withstanding hazards, identifying hazards, steering ML systems, and reducing deployment hazards.","ArXiv",2021,"Dan Hendrycks,Nicholas Carlini,J. Schulman,J. Steinhardt",59,217,4,"https://www.semanticscholar.org/paper/05c2e1ee203be217f100d2da05bdcc52004f00b6"
"6c2d43e71e240e354b5790a38da78a291ceffe7c",2,"Learning to Superoptimize Real-world Programs","A framework to learn to superoptimize real-world programs by using neural sequence-to-sequence models, and an approach to implement and outperforms a standard policy gradient learning approach on this dataset.","ArXiv",2021,"Alex Shypula,P. Yin,Jeremy Lacomis,Claire Le Goues,E. Schwartz,Graham Neubig",2,37,0,"https://www.semanticscholar.org/paper/6c2d43e71e240e354b5790a38da78a291ceffe7c"
"21e8e76386aaaa00e0971af70ce84a8a544e1aa1",2,"Cascaded Fast and Slow Models for Efficient Semantic Code Search","An efficient and accurate semantic code search framework with cascaded fast and slow models, in which a fast transformer encoder model is learned to optimize a scalable index for fast retrieval followed by learning a slow classification-based re-ranking model to improve the performance of the top K results from the fast retrieval.","ArXiv",2021,"Akhilesh Deepak Gotmare,Junnan Li,Shafiq R. Joty,S. Hoi",2,24,0,"https://www.semanticscholar.org/paper/21e8e76386aaaa00e0971af70ce84a8a544e1aa1"
"570a6a5b8ec2827c3f33bb1b1bd027190a0d3e07",2,"Neural Program Generation Modulo Static Analysis","The neurosymbolic method allows a deep generative model to symbolically compute, using calls to a static-analysis tool, long-distance semantic relationships in the code that it has already generated, and learns to generate programs conditioned on them.","Neural Information Processing Systems",2021,"Rohan Mukherjee,Yeming Wen,Dipak Chaudhari,T. Reps,Swarat Chaudhuri,C. Jermaine",9,56,0,"https://www.semanticscholar.org/paper/570a6a5b8ec2827c3f33bb1b1bd027190a0d3e07"
"091fa84bdc07dcb22a34060c3996d8c58d71cd20",2,"Towards Neural Functional Program Evaluation","A new program generation mechanism is introduced that allows control over syntactic sugar for semantically equivalent programs in transformer-based language models for program evaluation of simple functional programming languages.","ArXiv",2021,"Torsten Scholak,Jonathan Pilault,Joey Velez-Ginorio",0,19,0,"https://www.semanticscholar.org/paper/091fa84bdc07dcb22a34060c3996d8c58d71cd20"
"75c8f2916a2067f7549cf58ea8c9061565eb1dab",2,"C ROSS B EAM : L EARNING TO S EARCH IN B OTTOM -U P P ROGRAM S YNTHESIS","This work uses a neural model to learn a hands-on search policy for bottom-up synthesis, instead of relying on a combinatorial search algorithm, and observes that CROSSBEAM learns to search efficiently, exploring much smaller portions of the program space compared to the state-of-the-art.","",2022,"H. Dai,Kevin Ellis,Charles Sutton",0,49,0,"https://www.semanticscholar.org/paper/75c8f2916a2067f7549cf58ea8c9061565eb1dab"
"9bf75110ea0923bbed49256b5491f1ec284019ec",2,"From BERT to GPT-3 Codex: Harnessing the Potential of Very Large Language Models for Data Management","The goal of the tutorial is to introduce database researchers to the latest generation of language models, and to their use cases in the domain of data management.","Proc. VLDB Endow.",2022,"Immanuel Trummer",0,35,0,"https://www.semanticscholar.org/paper/9bf75110ea0923bbed49256b5491f1ec284019ec"
"ddab94478a7647ee136b1f6b5076417db3074d0f",2,"Machine Programming: Turning Data into Programmer Productivity","An introduction to machine programming is introduced introducing its three pillars: intention, invention, and adaptation, and an overview of the data ecosystem central to all machine programming systems is provided, highlighting challenges and novel opportunities relevant to the data systems community.","Proc. VLDB Endow.",2022,"A. Wasay,Nesime Tatbul,Justin Emile Gottschlich",0,39,0,"https://www.semanticscholar.org/paper/ddab94478a7647ee136b1f6b5076417db3074d0f"
"2443179d421e1faf7474add557b45add554723c7",2,"Formal Premise Selection With Language Models","This work provides a solution to the problem of selecting a useful premise to prove a new theorem by combining a premise selection model with a language model, and shows that this retrieval-augmented prover achieves significant improvements in proof rates compared to the language model alone.","",2022,"Szymon Tworkowski,Maciej Miku la,Tomasz Odrzygóźdź,K. Czechowski,Szymon Antoniak,Albert Qiaochu Jiang,Christian Szegedy,Lukasz Kucinski,Piotr Mi loś,Yuhuai Wu",0,34,0,"https://www.semanticscholar.org/paper/2443179d421e1faf7474add557b45add554723c7"
"a1ef81e17a9ca41e09aba802040a2eca2744716f",2,"Generation Probabilities are Not Enough: Improving Error Highlighting for AI Code Suggestions","It is unclear how best to convey the uncertainty of generative models to human operators or if doing so will positively impact human-AI collaboration.","",2022,"Helena Vasconcelos",1,15,0,"https://www.semanticscholar.org/paper/a1ef81e17a9ca41e09aba802040a2eca2744716f"
"b98d6fe8f0ef02ec0d1bb2bcfb924c8f01feb7d4",2,"Convergent Representations of Computer Programs in Human and Artificial Neural Networks","Analysis of brain recordings derived from functional magnetic resonance imaging studies of programmers comprehending Python code suggests at least two distinct neural mechanisms mediating computer program comprehension and evaluation, prompting the design of code model objectives that go beyond static language modeling.","",2022,"Shashank Srikant,Benjamin Lipkin,Anna A. Ivanova,Evelina Fedorenko,Una-May O’Reilly",0,79,0,"https://www.semanticscholar.org/paper/b98d6fe8f0ef02ec0d1bb2bcfb924c8f01feb7d4"
"15ef2d1b88f54fa32a32927463a7116219b89529",2,"L EARNING TO S UPEROPTIMIZE R EAL - WORLD P ROGRAMS","","",,"",0,0,0,"https://www.semanticscholar.org/paper/15ef2d1b88f54fa32a32927463a7116219b89529"
"660ca9e15e19409903a0605f0584d0f263c35c67",2,"S YNCHROMESH : R ELIABLE C ODE G ENERATION FROM P RE - TRAINED L ANGUAGE M ODELS","A framework for substantially improving the reliability of pre-trained models for code generation and observing substantial complementary gains from CSD and TST in prediction accuracy and in effectively preventing run-time errors is proposed.","",2022,"Gabriel Poesia,A. Tiwari,Gustavo Soares,Christopher Meek",0,29,0,"https://www.semanticscholar.org/paper/660ca9e15e19409903a0605f0584d0f263c35c67"
"ba5d21b7c65c6598c7bd39a5d992308c205df374",2,"A S YSTEMATIC E VALUATION OF L ARGE L ANGUAGE M ODELS OF C ODE","It is found that existing open-source models do achieve close results in some programming languages, although targeted mainly for natural language modeling, and a new model, PolyCoder, is released that was trained on 249GB of code across 12 programming languages on a single machine.","",2022,"Graham Neubig,V. Hellendoorn",0,33,0,"https://www.semanticscholar.org/paper/ba5d21b7c65c6598c7bd39a5d992308c205df374"
"56e6d62c638a24411f12d15cdc8821a31fc495c8",2,"Source Code Generation from Descriptions in a Natural Language","This work introduces CodeFormer, a Python source code generator pretrained on a massive GitHub crawl consisting of 230M Python functions, and releases the resulting model, built on BART architecture, which generates Python functions based on descriptions in English.","",2022,"Bc. Jan Pašek",0,70,0,"https://www.semanticscholar.org/paper/56e6d62c638a24411f12d15cdc8821a31fc495c8"
"6e5eb6167d9766fbb4d14611d15cf95d7b75fb9d",2,"Asleep at the Keyboard? Assessing the Security of GitHub Copilot’s Code Contributions","This work systematically investigates the prevalence and conditions that can cause GitHub Copilot to recommend insecure code, and explores Copilot’s performance on three distinct code generation axes—examining how it performs given diversity of weaknesses, diversity of prompts, and diversity of domains.","IEEE Symposium on Security and Privacy",2021,"H. Pearce,Baleegh Ahmad,Benjamin Tan,Brendan Dolan-Gavitt,R. Karri",26,35,4,"https://www.semanticscholar.org/paper/6e5eb6167d9766fbb4d14611d15cf95d7b75fb9d"
"ff0b2681d7b05e16c46dfb71d980cc2f605907cd",2,"Finetuned Language Models Are Zero-Shot Learners","It is shown that instruction tuning —ﬁnetuning language models on a collection of datasets described via instructions—substantially improves zero-shot performance on unseen tasks and outperforms few-shot GPT-3 by a large margin on ANLI, RTE, BoolQ, AI2-ARC, OpenbookQA, and StoryCloze.","International Conference on Learning Representations",2021,"Jason Wei,Maarten Bosma,Vincent Zhao,Kelvin Guu,A. Yu,Brian Lester,Nan Du,Andrew M. Dai,Quoc V. Le",326,167,74,"https://www.semanticscholar.org/paper/ff0b2681d7b05e16c46dfb71d980cc2f605907cd"
"6e8f8e2d2c73c91d1c9198eb802f1c64b860ea4a",2,"Few-Shot Semantic Parsing with Language Models Trained on Code","This paper evaluates OpenAI Codex on Overnight and SMCalFlow and finds that unlike GPT-3, Codex performs similarly when targeting meaning representations directly, perhaps because meaning representations are structured similar to code in these datasets.","North American Chapter of the Association for Computational Linguistics",2021,"Richard Shin,Benjamin Van Durme",16,18,3,"https://www.semanticscholar.org/paper/6e8f8e2d2c73c91d1c9198eb802f1c64b860ea4a"
"53c0abe83fe9b4fdaf2208295d8504fcf5241694",2,"UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding with Text-to-Text Language Models","The U NIFIED SKG framework is proposed, which uniﬁes 21 SKG tasks into a text-to-text format, aiming to promote systematic SKG research, instead of being exclu-sive to a single task, domain, or dataset.","ArXiv",2022,"Tianbao Xie,Chen Henry Wu,Peng Shi,Ruiqi Zhong,Torsten Scholak,Michihiro Yasunaga,Chien-Sheng Wu,Ming Zhong,Pengcheng Yin,Sida I. Wang,Victor Zhong,Bailin Wang,Chengzu Li,Connor Boyle,Ansong Ni,Ziyu Yao,Dragomir R. Radev,Caiming Xiong,Lingpeng Kong,Rui Zhang,Noah A. Smith,Luke Zettlemoyer,Tao Yu",87,113,11,"https://www.semanticscholar.org/paper/53c0abe83fe9b4fdaf2208295d8504fcf5241694"
"92a8f7f09f3705cb5a6009a42220a6f01ea084e8",2,"Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents","This paper investigates the possibility of grounding high-level tasks, expressed in natural language, to a chosen set of actionable steps and proposes a procedure that conditions on existing demonstrations and semantically translates the plans to admissible actions.","International Conference on Machine Learning",2022,"Wenlong Huang,P. Abbeel,Deepak Pathak,Igor Mordatch",81,55,13,"https://www.semanticscholar.org/paper/92a8f7f09f3705cb5a6009a42220a6f01ea084e8"
"b62d63580b81a2cbb20c3c1593dd62d118e4cb07",2,"Synchromesh: Reliable code generation from pre-trained language models","A framework for substantially improving the reliability of pre-trained models for code generation and observing substantial complementary gains from CSD and TST in prediction accuracy and in effectively preventing run-time errors is proposed.","International Conference on Learning Representations",2022,"Gabriel Poesia,Oleksandr Polozov,Vu Le,A. Tiwari,Gustavo Soares,Christopher Meek,Sumit Gulwani",29,31,5,"https://www.semanticscholar.org/paper/b62d63580b81a2cbb20c3c1593dd62d118e4cb07"
"7428f9b16a82839e2cb6e6c7a77c1ffeab898813",2,"HEAT: Hyperedge Attention Networks","This work presents HEAT, a neural model capable of representing typed and qualified hypergraphs, where each hyperedge explicitly qualifies how participating nodes con-tribute is treated, which can be viewed as a generalization of both message passing neural networks and Transformers.","ArXiv",2022,"Dobrik Georgiev,Marc Brockschmidt,Miltiadis Allamanis",3,39,0,"https://www.semanticscholar.org/paper/7428f9b16a82839e2cb6e6c7a77c1ffeab898813"
"1b6e810ce0afd0dd093f789d2b2742d047e316d5",2,"Chain of Thought Prompting Elicits Reasoning in Large Language Models","Experiments on three large language models show that chain-of-thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks.","ArXiv",2022,"Jason Wei,Xuezhi Wang,Dale Schuurmans,Maarten Bosma,E. Chi,Quoc Le,Denny Zhou",291,103,83,"https://www.semanticscholar.org/paper/1b6e810ce0afd0dd093f789d2b2742d047e316d5"
"9cbc044e315cdefe9a255119037ac7c23e9abdd5",2,"Predictability and Surprise in Large Generative Models","This paper highlights a counterintuitive property of large-scale generative models, which have a paradoxical combination of predictable loss on a broad training distribution, and unpredictable specific capabilities, inputs, and outputs, and analyzed how these conflicting properties combine to give model developers various motivations for deploying these models, and challenges that can hinder deployment.","Conference on Fairness, Accountability and Transparency",2022,"Deep Ganguli,Danny Hernandez,Liane Lovitt,Nova DasSarma,T. Henighan,Andy Jones,Nicholas Joseph,John Kernion,Benjamin Mann,Amanda Askell,Yuntao Bai,Anna Chen,Tom Conerly,Dawn Drain,Nelson Elhage,Sheer El Showk,Stanislav Fort,Zac Hatfield-Dodds,Scott Johnston,S. Kravec,Neel Nanda,Kamal Ndousse,Catherine Olsson,Daniela Amodei,Dario Amodei,Tom B. Brown,Jared Kaplan,Sam McCandlish,C. Olah,Jack Clark",23,92,2,"https://www.semanticscholar.org/paper/9cbc044e315cdefe9a255119037ac7c23e9abdd5"
"76f023c3a819fc58989a064a1b50825b11fce95d",2,"Capturing Failures of Large Language Models via Human Cognitive Biases","The results indicate that experimental methodology from cognitive science can help characterize how machine learning systems behave, and draw inspiration from human cognitive biases as motivation to generate hypotheses for problems that models may have and develop experiments that elicit these problems.","ArXiv",2022,"Erik Jones,J. Steinhardt",7,54,0,"https://www.semanticscholar.org/paper/76f023c3a819fc58989a064a1b50825b11fce95d"
"2b556fcf2ac634f03c1fb0ace5e602e829418e65",2,"ReACC: A Retrieval-Augmented Code Completion Framework","This work proposes a retrieval-augmented code completion framework, leveraging both lexical copying and referring to code with similar semantics by retrieval, and adopts a stage-wise training approach that combines a source code retriever and an auto-regressive language model for programming language.","Annual Meeting of the Association for Computational Linguistics",2022,"Shuai Lu,Nan Duan,Hojae Han,Daya Guo,Seung-won Hwang,Alexey Svyatkovskiy",13,70,2,"https://www.semanticscholar.org/paper/2b556fcf2ac634f03c1fb0ace5e602e829418e65"
"c347093e2dca530ce347526380b0b7aedf03a6b2",2,"CrossBeam: Learning to Search in Bottom-Up Program Synthesis","This work uses a neural model to learn a hands-on search policy for bottom-up synthesis, instead of relying on a combinatorial search algorithm, and observes that CROSSBEAM learns to search efficiently, exploring much smaller portions of the program space compared to the state-of-the-art.","ICLR",2022,"Kensen Shi,H. Dai,Kevin Ellis,Charles Sutton",4,56,0,"https://www.semanticscholar.org/paper/c347093e2dca530ce347526380b0b7aedf03a6b2"
"fb5c11bbf63884f75d2da615fbf37a3bcfa2bd20",2,"Wordcraft: Story Writing With Large Language Models","This work built Wordcraft, a text editor in which users collaborate with a generative language model to write a story, and shows that large language models enable novel co-writing experiences.","International Conference on Intelligent User Interfaces",2022,"Ann Yuan,Andy Coenen,Emily Reif,Daphne Ippolito",12,41,1,"https://www.semanticscholar.org/paper/fb5c11bbf63884f75d2da615fbf37a3bcfa2bd20"
"237f5ca6fcccef2b77a2212b34fb06a1dbd09b72",2,"Evaluating Prompts Across Multiple Choice Tasks In a Zero-Shot Setting","Collect and standardize prompts from a diverse range of tasks for use with tasks they were not designed for and evaluate these prompts across multiple choice datasets for a quantitative analysis of how certain attributes of a prompt affect performance.","ArXiv",2022,"Gabriel Orlanski",0,47,0,"https://www.semanticscholar.org/paper/237f5ca6fcccef2b77a2212b34fb06a1dbd09b72"
"2ba7104f7b93d77940312664f3467b8f090d6d16",2,"On Distribution Shift in Learning-based Bug Detectors","This work proposes to train a bug detector in two phases, first on a synthetic bug distribution to adapt the model to the bug detection domain, and then on a real bug distributionTo drive the model towards the real distribution, which leverage a multi-task hierarchy, focal loss, and contrastive learning to further boost performance.","International Conference on Machine Learning",2022,"Jingxuan He,Luca Beurer-Kellner,Martin T. Vechev",4,49,0,"https://www.semanticscholar.org/paper/2ba7104f7b93d77940312664f3467b8f090d6d16"
"6050454e0446a3068617f73b0301453f3f67844d",2,"Stylette: Styling the Web with Natural Language","Stylette is a browser extension that enables users to change the style of websites by expressing goals in natural language, and shows that Stylette lowered the learning curve, helping participants perform styling changes 35% faster than those using developer tools.","International Conference on Human Factors in Computing Systems",2022,"Tae Soo Kim,Yoonseo Choi,D. Choi,Juho Kim",1,65,0,"https://www.semanticscholar.org/paper/6050454e0446a3068617f73b0301453f3f67844d"
"4bc040835fbff57ce6612306d794b8c6c8226086",2,"Discovering the Syntax and Strategies of Natural Language Programming with Generative Language Models","A natural language code synthesis tool, GenLine, backed by a large generative language model and a set of task-specific prompts that create or change code is presented, indicating that while naturallanguage code synthesis can sometimes provide a magical experience, participants still faced challenges.","International Conference on Human Factors in Computing Systems",2022,"Ellen Jiang,Edwin Toh,A. Molina,Kristen Olson,Claire Kayacik,Aaron Donsbach,Carrie J. Cai,Michael Terry",9,36,2,"https://www.semanticscholar.org/paper/4bc040835fbff57ce6612306d794b8c6c8226086"
"f8aa0cab09bc0668276e2cb5690bae47fa50d350",2,"An Initial Look at Self-Reprogramming Artificial Intelligence","This paper develops and experimentally validate the first fully self-reprogramming AI system with the ability to continuously modify and rewrite its own neural network source code.","ArXiv",2022,"Alex Sheng",0,17,0,"https://www.semanticscholar.org/paper/f8aa0cab09bc0668276e2cb5690bae47fa50d350"
"cdfe9580f63070f311151444f9df32818cc858bf",2,"An Empirical Evaluation of GitHub Copilot's Code Suggestions","Overall, Copilot's suggestions have low complexity with no notable differences between the programming languages and some potential Copilot shortcomings are found.","IEEE Working Conference on Mining Software Repositories",2022,"N. Nguyen,Sarah Nadi",14,29,3,"https://www.semanticscholar.org/paper/cdfe9580f63070f311151444f9df32818cc858bf"
"5922f437512158970c417f4413bface021df5f78",2,"A Generalist Agent","","ArXiv",2022,"S. Reed,Konrad Zolna,Emilio Parisotto,Sergio Gomez Colmenarejo,Alexander Novikov,Gabriel Barth-Maron,Mai Gimenez,Yury Sulsky,Jackie Kay,J. T. Springenberg,Tom Eccles,Jake Bruce,Ali Razavi,Ashley D. Edwards,N. Heess,Yutian Chen,R. Hadsell,Oriol Vinyals,Mahyar Bordbar,N. D. Freitas",114,102,15,"https://www.semanticscholar.org/paper/5922f437512158970c417f4413bface021df5f78"
"c61ce808818308566124df2c8725c98d6bd38dc3",2,"A Precis of Language Models are not Models of Language","It is shown that despite their many successes at performing linguistic tasks, Large Neural Language Models are ill suited as comprehensive models of natural language.","ArXiv",2022,"C. Veres",0,16,0,"https://www.semanticscholar.org/paper/c61ce808818308566124df2c8725c98d6bd38dc3"
"58aacb967cc7fc25cfc9d51b7ad3e57ac00d119b",2,"Can Foundation Models Wrangle Your Data?","It is found that large FMs generalize and achieve SoTA performance on data cleaning and integration tasks, even though they are not trained for these data tasks.","Proceedings of the VLDB Endowment",2022,"A. Narayan,Ines Chami,Laurel J. Orr,Christopher R'e",6,91,1,"https://www.semanticscholar.org/paper/58aacb967cc7fc25cfc9d51b7ad3e57ac00d119b"
"adce1da47d490dcdca254ccd43055ed4f4423bc2",2,"Summarize and Generate to Back-translate: Unsupervised Translation of Programming Languages","It is shown that the proposed framework performsably to state-of-the-art methods, if not exceed their translation performance between Java 032 and Python languages.","ArXiv",2022,"Wasi Uddin Ahmad,Saikat Chakraborty,Baishakhi Ray,Kai-Wei Chang",0,49,0,"https://www.semanticscholar.org/paper/adce1da47d490dcdca254ccd43055ed4f4423bc2"
"f1b6b34b4440a77ba86493f7062e8974062508c5",2,"Applying genetic programming to PSB2: the next generation program synthesis benchmark suite","25 new general program synthesis benchmark problems that make up PSB2, a new benchmark suite curated from a variety of sources, including programming katas and college courses are described.","Genetic Programming and Evolvable Machines",2022,"Thomas Helmuth,Peter Kelly",1,62,0,"https://www.semanticscholar.org/paper/f1b6b34b4440a77ba86493f7062e8974062508c5"
"0d08ffccc982781e310bb184397bbe64b9aef157",2,"Automatic Generation of Programming Exercises and Code Explanations Using Large Language Models","The analysis suggests that there is significant value in massive generative machine learning models as a tool for instructors, although there remains a need for some oversight to ensure the quality of the generated content before it is delivered to students.","International Computing Education Research Workshop",2022,"Sami Sarsa,Paul Denny,Arto Hellas,Juho Leinonen",18,99,1,"https://www.semanticscholar.org/paper/0d08ffccc982781e310bb184397bbe64b9aef157"
"40edfa97cd02268fccff75eb9c693b11c1a968b2",2,"Formal Specifications from Natural Language","These experiments show that language models maintain their generalization capabilities from pre-trained knowledge of natural language to generalize, e.g., to new variable names or operator descriptions, and achieve competitive performance, and even outperform the state-of-the-art for translating into regular expressions.","ArXiv",2022,"Christopher Hahn,Frederik Schmitt,Julia J. Tillman,Niklas Metzger,Julian Siber,B. Finkbeiner",1,97,0,"https://www.semanticscholar.org/paper/40edfa97cd02268fccff75eb9c693b11c1a968b2"
"a64871352f8ac7f8aa226fda5cce70251a18a4fc",2,"Assessing Project-Level Fine-Tuning of ML4SE Models","It is shown that per-project fine-tuning can greatly improve the models’ quality as they capture the project’s domain and naming conventions.","ArXiv",2022,"Egor Bogomolov,Sergey Zhuravlev,Egor Spirin,T. Bryksin",0,39,0,"https://www.semanticscholar.org/paper/a64871352f8ac7f8aa226fda5cce70251a18a4fc"
"9aed848be4e9e401b0e61a2e5d60dbdafa0c6cc1",2,"A Dataset and Benchmark for Automatically Answering and Generating Machine Learning Final Exams","A student survey comparing the quality, appropriateness, andulty of machine- generated questions with human-written questions shows that across multiple aspects, machine-generated questions are indistinguishable from human-generated Questions and are suitable for ﬁnal exams.","ArXiv",2022,"Sarah Zhang,Reece Shuttleworth,Derek Austin,Yann Hicke,Leonard Tang,Sathwik Karnik,Darnell Granberry,Iddo Drori",2,15,1,"https://www.semanticscholar.org/paper/9aed848be4e9e401b0e61a2e5d60dbdafa0c6cc1"
"114eb5a35a3cd802cd1f46fff35c284e32ef6c54",2,"GitHub Copilot AI pair programmer: Asset or Liability?","Comparing Copilot to humans, the results show that the correct ratio of human solutions is greater than Copilot’s correct ratio, while the buggy solutions generated by Copilot require less time to be repaired.","ArXiv",2022,"Arghavan Moradi Dakhel,Vahid Majdinasab,Amin Nikanjam,F. Khomh,M. Desmarais,Z. Jiang",7,40,1,"https://www.semanticscholar.org/paper/114eb5a35a3cd802cd1f46fff35c284e32ef6c54"
"52ca0f589fdcde1c45fd6dfb1b72248d4ecaefc0",2,"Code Translation with Compiler Representations","This paper proposes to augment code translation with IRs, speciﬁcally LLVM IR, with results on the C++, Java, Rust, and Go languages, and improves upon the state of the art for unsupervised code translation.","ArXiv",2022,"Marc Szafraniec,Baptiste Rozière,Hugh Leather Francois Charton,Patrick Labatut,Gabriel Synnaeve",2,43,0,"https://www.semanticscholar.org/paper/52ca0f589fdcde1c45fd6dfb1b72248d4ecaefc0"
"8dd412cd31592ba633b5dac8b2e7b4c679ec1c0a",2,"Grounded Copilot: How Programmers Interact with Code-Generating Models","Interactions with programming assistants are bimodal : in acceleration mode , the programmer knows what to do next and uses Copilot to get there faster; in exploration mode, the programmer is unsure how to proceed and usesCopilot to explore their options.","ArXiv",2022,"Shraddha Barke,M. James,N. Polikarpova",9,61,0,"https://www.semanticscholar.org/paper/8dd412cd31592ba633b5dac8b2e7b4c679ec1c0a"
"53661ff6fdbfb8557c5b19895fad151792c62da7",2,"Few-shot training LLMs for project-specific code-summarization","This paper investigates the use few-shot training with the very large GPT (Generative Pre-trained Transformer) Codex model, and finds evidence suggesting that one can significantly surpass state-of-the-art models for code-summarization, leveraging project-specific training.","International Conference on Automated Software Engineering",2022,"Toufique Ahmed,Prem Devanbu",2,25,0,"https://www.semanticscholar.org/paper/53661ff6fdbfb8557c5b19895fad151792c62da7"
"f843233f76a5dff07bfa93a71a1cf13d8aa6a94a",2,"Exploring Length Generalization in Large Language Models","It is shown that combining pretrained large language models’ in-context learning abilities with scratchpad prompting results in a dramatic improvement in length generalization, and is run to identify common sources of mistakes that highlight opportunities in equipping language models with the ability to generalize to longer problems.","ArXiv",2022,"Cem Anil,Yuhuai Wu,Anders Andreassen,Aitor Lewkowycz,Vedant Misra,V. Ramasesh,Ambrose Slone,Guy Gur-Ari,Ethan Dyer,Behnam Neyshabur",18,32,4,"https://www.semanticscholar.org/paper/f843233f76a5dff07bfa93a71a1cf13d8aa6a94a"
"e37155d21818513bd40d64ee212099aac82bd6f8",2,"Less training, more repairing please: revisiting automated program repair via zero-shot learning","This paper proposesAlphaRepair, the first cloze-style (or infilling-style) APR approach to directly leveraging large pre-trained code models for APR without any fine-tuning/retraining on historical bug fixes, and implements AlphaRepair as a practical multilingual APR tool based on the recent CodeBERT model.","ESEC/SIGSOFT FSE",2022,"Chun Xia,Lingming Zhang",5,77,1,"https://www.semanticscholar.org/paper/e37155d21818513bd40d64ee212099aac82bd6f8"
"2f2750b48a6f958ff12cba90e99695123d1e2f47",2,"Using pre-trained language models to resolve textual and semantic merge conflicts (experience paper)","The feasibility of automatically repairing merge conflicts using k-shot learning with pre-trained large neural language models (LM) such as GPT-3 is explored, and LMs provide the state-of-the-art (SOTA) performance on semantic merge conflict resolution for Edge compared to earlier symbolic approaches.","International Symposium on Software Testing and Analysis",2022,"Jialu Zhang,Todd Mytkowicz,Mike Kaufman,R. Piskac,Shuvendu K. Lahiri",2,29,0,"https://www.semanticscholar.org/paper/2f2750b48a6f958ff12cba90e99695123d1e2f47"
"1e3ec5709b2ca43233c566cd77dbabbd6892bfa6",2,"Neurosymbolic repair for low-code formula languages","LaMirage, a LAst-MIle RepAir-engine GEnerator that combines symbolic and neural techniques to perform last-mile repair in low-code formula languages, is developed and compared to state-of-the-art neural and symbolic approaches on 400 real Excel and Power Fx formulas, where LaMirage outperforms all baselines.","Proc. ACM Program. Lang.",2022,"Rohan Bavishi,Harshit Joshi,Jos'e Pablo Cambronero S'anchez,Anna Fariha,Sumit Gulwani,Vu Le,Ivan Radicek,A. Tiwari",2,69,0,"https://www.semanticscholar.org/paper/1e3ec5709b2ca43233c566cd77dbabbd6892bfa6"
"ec4c8d99eb1c028c43af6d8bbf727392d351cb59",2,"Efficient Training of Language Models to Fill in the Middle","There is extensive evidence that training models with a large fraction of data transformed in this way does not harm the original left-to-right generative capability, as measured by perplexity and sampling evaluations across a wide range of scales.","ArXiv",2022,"Mohammad Bavarian,Heewoo Jun,N. Tezak,J. Schulman,C. McLeavey,Jerry Tworek,Mark Chen",13,60,1,"https://www.semanticscholar.org/paper/ec4c8d99eb1c028c43af6d8bbf727392d351cb59"
"654cd297b307c0c6fa08732511ba852b8dce1977",2,"Out of the BLEU: how should we assess quality of the Code Generation models?","A study on applicability of six metrics— BLEu, ROUGE-L, METEOR, ChrF, CodeBLEU, RUBY—for evaluation of the code generation models is presented and several recommendations on using metrics to estimate the model performance on the codegeneration tasks are derived.","SSRN Electronic Journal",2022,"Mikhail Evtikhiev,Egor Bogomolov,Yaroslav Sokolov,T. Bryksin",5,43,0,"https://www.semanticscholar.org/paper/654cd297b307c0c6fa08732511ba852b8dce1977"
"def2e28863338cb20782eb2015a39d32df697ed6",2,"Learning to Improve Code Efficiency","","ArXiv",2022,"Bing Chen,Daniel Tarlow,Kevin Swersky,M. Maas,P. Heiber,Ashish Naik,Milad Hashemi,P. Ranganathan",1,35,0,"https://www.semanticscholar.org/paper/def2e28863338cb20782eb2015a39d32df697ed6"
"8c2d9d2aa891e3b53bbd9166c1b804a0741fc44a",2,"Finding Reusable Machine Learning Components to Build Programming Language Processing Pipelines","To improve theability, accessibility, interoperability and reusability (FAIRness) of machine learning components, a set of representative papers in the domain of machineLearning-based PLP are collected and analyzed.","ArXiv",2022,"Patrick Flynn,T. Vanderbruggen,C. Liao,Pei-Hung Lin,M. Emani,Xipeng Shen",0,32,0,"https://www.semanticscholar.org/paper/8c2d9d2aa891e3b53bbd9166c1b804a0741fc44a"
"99f85119f113b5498517928eff74a904b69e37b7",2,"CCTEST: Testing and Repairing Code Completion Systems","This research proposes CCT EST, a framework to test and repair code completion systems in black-box settings, which features a set of novel mutation strategies, namely program structure-consistent (PSC) mutations, to generate mutated code completion inputs.","ArXiv",2022,"Zongjie Li,Chaozheng Wang,Zhibo Liu,Haoxuan Wang,Shuai Wang,Cuiyun Gao",1,81,0,"https://www.semanticscholar.org/paper/99f85119f113b5498517928eff74a904b69e37b7"
"9b61de7038290751377b64293baaf42f3e7cf441",2,"An Empirical Evaluation of Competitive Programming AI: A Case Study of AlphaCode","An empirical study to find code similarities and performance differences between AlphaCode-generated codes and human codes shows that the generated codes are similar to human codes and the generated code performs on par with or worse than the human code in terms of execution time and memory usage.","International Workshop on Software Clones",2022,"Sila Lertbanjongngam,Bodin Chinthanet,T. Ishio,R. Kula,P. Leelaprute,Bundit Manaskasemsak,A. Rungsawang,Kenichi Matsumoto",0,35,0,"https://www.semanticscholar.org/paper/9b61de7038290751377b64293baaf42f3e7cf441"
"befde3e07ce97f02f12fe92ab27e99f23ccd17aa",2,"Evaluating Progress in Automatic Chest X-Ray Radiology Report Generation","This study quantitatively examines the correlation between automated metrics and the scoring of reports by radiologists, and proposes a composite metric, called RadCliQ, that is able to rank the quality of reports similarly to radiologists and better than existing metrics.","medRxiv",2022,"F. Yu,M. Endo,R. Krishnan,I. Pan,A. Tsai,E. P. Reis,E. Fonseca,H. M. H. Lee,Z. H. Abad,A. Y. Ng,C. Langlotz,V. Venugopal,P. Rajpurkar",1,33,0,"https://www.semanticscholar.org/paper/befde3e07ce97f02f12fe92ab27e99f23ccd17aa"
"0509c25103939d59ed4e27b1393e74ad5734c453",2,"How Readable is Model-generated Code? Examining Readability and Visual Inspection of GitHub Copilot","The results suggest that model generated code is comparable in complexity and readability to code written by human pair programmers, and eye tracking data suggests, to a statistically significant level, that programmers direct less visual attention to model generate code.","International Conference on Automated Software Engineering",2022,"N. A. Madi",1,28,0,"https://www.semanticscholar.org/paper/0509c25103939d59ed4e27b1393e74ad5734c453"
"6b5d1e50894b1f28e4798cf20e9ffa88b9ec011a",2,"How to Prompt? Opportunities and Challenges of Zero- and Few-Shot Learning for Human-AI Interaction in Creative Applications of Generative Models","This work discusses the key opportunities and challenges for interactive creative applications that use prompting as a new paradigm for Human-AI interaction and proposes four design goals for user interfaces that support prompting.","ArXiv",2022,"Hai Dang,Lukas Mecke,Florian Lehmann,Sven Goller,D. Buschek",1,22,0,"https://www.semanticscholar.org/paper/6b5d1e50894b1f28e4798cf20e9ffa88b9ec011a"
"363758e9e296adc9391ed731e834809cf5d4c19b",2,"Are machine programming systems using right source-code measures to select code repositories?","A framework to rank open-source repositories on quality, maintainability, and popularity by leveraging existing research on this topic is developed and some correlation between the quality measures used in GitRank and ControlFlag's performance is revealed, suggesting that some of the measures used by GitRank are applicable to ControlFlag.","MaLTeSQuE@ESEC/SIGSOFT FSE",2022,"N. Hasabnis",1,32,0,"https://www.semanticscholar.org/paper/363758e9e296adc9391ed731e834809cf5d4c19b"
"cd6496bc404e18a24f634e3dded2ed1cdca03e0f",2,"Learning to Learn with Generative Models of Neural Network Checkpoints","This model is a conditional diffusion transformer that, given an initial input parameter vector and a prompted loss, error, or return, predicts the distribution over parameter updates that achieve the desired metric.","ArXiv",2022,"William S. Peebles,Ilija Radosavovic,Tim Brooks,Alexei A. Efros,J. Malik",6,77,0,"https://www.semanticscholar.org/paper/cd6496bc404e18a24f634e3dded2ed1cdca03e0f"
"2a0456b0408cd4c33f2ff4400374e7be2497a362",2,"Repairing Bugs in Python Assignments Using Large Language Models","This work proposes to use a large language model trained on code, such as Codex, to build an APR system – MMAPR – for introductory Python programming assignments and finds that MM APR can produce more programs and produce smaller patches on average.","ArXiv",2022,"Jialu Zhang,J. Cambronero,Sumit Gulwani,Vu Le,R. Piskac,Gustavo Soares,Gust Verbruggen",2,49,1,"https://www.semanticscholar.org/paper/2a0456b0408cd4c33f2ff4400374e7be2497a362"
"55e3fe05598be7c3dd357d51166869f6571b824f",2,"Large Language Models are Pretty Good Zero-Shot Video Game Bug Detectors","This study explores the possibil-ity of leveraging the zero-shot capabilities of large language models for video game bug detection by formulating the bug detection problem as a question-answering task, and shows thatLarge language models can identify which event is buggy in a sequence of textual descriptions of events from a game.","ArXiv",2022,"Mohammad Reza Taesiri,F. Macklon,Yihe Wang,Hengshuo Shen,C. Bezemer",0,51,0,"https://www.semanticscholar.org/paper/55e3fe05598be7c3dd357d51166869f6571b824f"
"62f0db3a5ad5c795ec18fc7a6e7b01836809df57",2,"Language Models are Multilingual Chain-of-Thought Reasoners","It is shown that the multilingual reasoning abilities of language models extend to other tasks such as commonsense reasoning and word-in-context semantic judgment, and that models have strikingly strong mult bilingual reasoning abilities, even in underrepresented languages such as Bengali and Swahili.","ArXiv",2022,"Freda Shi,Mirac Suzgun,Markus Freitag,Xuezhi Wang,Suraj Srivats,Soroush Vosoughi,Hyung Won Chung,Yi Tay,Sebastian Ruder,Denny Zhou,Dipanjan Das,Jason Wei",12,50,1,"https://www.semanticscholar.org/paper/62f0db3a5ad5c795ec18fc7a6e7b01836809df57"
"259b7a01700c39d5669e88d1434873ea38a13528",2,"In-Context Policy Iteration","An algorithm, ICPI, that learns to perform RL tasks without expert demonstrations or gradients, and is presented as a policy-iteration method in which the prompt content is the entire locus of learning.","ArXiv",2022,"Ethan Brooks,Logan Walls,Richard L. Lewis,Satinder Singh",0,39,0,"https://www.semanticscholar.org/paper/259b7a01700c39d5669e88d1434873ea38a13528"
"825333b7efe2cade106eaf36c7e731f757974806",2,"How Readable is Model-generated Code? Examining Readability and Visual Inspection of GitHub Copilot","The results suggest that model generated code is comparable in complexity and readability to code written by human pair programmers, and eye tracking data suggests, to a statistically significant level, that programmers direct less visual attention to model generate code.","37th IEEE/ACM International Conference on Automated Software Engineering",2022,"Naser Al Madi",0,28,0,"https://www.semanticscholar.org/paper/825333b7efe2cade106eaf36c7e731f757974806"
"8ffe7b7eeddbd4c22d642b0a48379d17e61c3bab",2,"Soft-Labeled Contrastive Pre-training for Function-level Code Representation","SCodeR, a S oft-labeled contrastive pre-training framework with two positive sample construction methods to learn functional-level Code R epresentation, and results show that SCodeR achieves new state-of-the-art performance on all of them, which illustrates the effectiveness of the proposed pre- training method.","ArXiv",2022,"Xiaonan Li,Daya Guo,Yeyun Gong,Yun Lin,Yelong Shen,Xipeng Qiu,Daxin Jiang,Weizhu Chen,Nan Duan",1,42,0,"https://www.semanticscholar.org/paper/8ffe7b7eeddbd4c22d642b0a48379d17e61c3bab"
"4c2534f9b03ac2f3810c07abc398a11bcf47258e",2,"Transformers Learn Shortcuts to Automata","The theoretical results completely characterize shortcut solutions, whereby a shallow Transformer with only o(T ) layers can exactly replicate the computation of an automaton on an input sequence of length T .","ArXiv",2022,"Bingbin Liu,J. Ash,Surbhi Goel,A. Krishnamurthy,Cyril Zhang",3,104,0,"https://www.semanticscholar.org/paper/4c2534f9b03ac2f3810c07abc398a11bcf47258e"
"5484d228bfc50efbac6e86677bc2ec2ee4ede1a6",2,"Scaling Instruction-Finetuned Language Models","This result shows that instruction and UL2 continued pre-training are complementary compute-eﬃcient methods to improve the performance of language models without increasing model scale.","ArXiv",2022,"Hyung Won Chung,Le Hou,S. Longpre,Barret Zoph,Yi Tay,W. Fedus,Eric Li,Xuezhi Wang,M. Dehghani,Siddhartha Brahma,Albert Webson,S. Gu,Zhuyun Dai,Mirac Suzgun,Xinyun Chen,Aakanksha Chowdhery,Dasha Valter,Sharan Narang,Gaurav Mishra,A. Yu,Vincent Zhao,Yanping Huang,Andrew M. Dai,Hongkun Yu,Slav Petrov,E. Chi,J. Dean,Jacob Devlin,Adam Roberts,Denny Zhou,Quoc Le,Jason Wei",14,104,2,"https://www.semanticscholar.org/paper/5484d228bfc50efbac6e86677bc2ec2ee4ede1a6"
"d26f616699a122e5455a13189e276002ee4cf923",2,"Draft, Sketch, and Prove: Guiding Formal Theorem Provers with Informal Proofs","This work introduces Draft, Sketch, and Prove (DSP), a method that maps informal proofs to formal proof sketches, and uses the sketches to guide an automated prover by directing its search to easier sub-problems.","ArXiv",2022,"Albert Qiaochu Jiang,S. Welleck,J. Zhou,Wenda Li,Jiacheng Liu,M. Jamnik,Timothée Lacroix,Yuhuai Wu,Guillaume Lample",2,40,0,"https://www.semanticscholar.org/paper/d26f616699a122e5455a13189e276002ee4cf923"
"472d87be3dc298102e058be55a814cc6d2085b39",2,"Towards Deceptive Defense in Software Security with Chaff Bugs","A new defensive technique called chaff bugs is proposed, which instead targets the bug discovery and exploit creation stages of this process, and can serve as an effective deterrent against both human attackers and automated bug-finding tools.","International Symposium on Recent Advances in Intrusion Detection",2022,"Zhenghao Hu,Yu Hu,Brendan Dolan-Gavitt",0,47,0,"https://www.semanticscholar.org/paper/472d87be3dc298102e058be55a814cc6d2085b39"
"0566c1c3eeeef5c968fced6d80b77fe22d02bbd9",2,"Conversing with Copilot: Exploring Prompt Engineering for Solving CS1 Problems Using Natural Language","Evaluating the performance of Copilot on a publicly available dataset of 166 programming problems finds that it successfully solves around half of these problems on its very first attempt, and that it solves 60% of the remaining problems using only natural language changes to the problem description.","ArXiv",2022,"Paul Denny,Viraj Kumar,Nasser Giacaman",3,24,0,"https://www.semanticscholar.org/paper/0566c1c3eeeef5c968fced6d80b77fe22d02bbd9"
"2abed82162c47a0cc32cd62afcf46b0745541017",2,"Experiences from Using Code Explanations Generated by Large Language Models in a Web Software Development E-Book","The preliminary results show that all varieties of explanations were viewed by students and that the majority of students perceived the code explanations as helpful to them, however, student engagement appeared to vary by code snippet complexity, explanation type, and code snippet length.","ArXiv",2022,"S. MacNeil,Andrew Tran,Arto Hellas,Joanne Kim,Sami Sarsa,Paul Denny,Seth Bernstein,Juho Leinonen",1,45,0,"https://www.semanticscholar.org/paper/2abed82162c47a0cc32cd62afcf46b0745541017"
"ac3d7ae8b4acb137492d4a8d8bcff480b89fa000",2,"Programming Pedagogy and Assessment in the Era of AI/ML: A Position Paper","This work surveys recent research on automated systems for writing code, and examines the components of the code-writing task using a six-step framework proposed in the literature, and identifies the impact of automated systems at each step.","Compute",2022,"A. Raman,Viraj Kumar",0,39,0,"https://www.semanticscholar.org/paper/ac3d7ae8b4acb137492d4a8d8bcff480b89fa000"
"632ab7663e6d64578ceda1d1df9ec525b503bacb",2,"Steps towards prompt-based creation of virtual worlds","This work shows that prompt-based methods can both accelerate in-VR level editing, as well as can become part of gameplay rather than just part of game development.","ArXiv",2022,"Jasmine Roberts,Andrzej Banburski-Fahey,J. Lanier",0,41,0,"https://www.semanticscholar.org/paper/632ab7663e6d64578ceda1d1df9ec525b503bacb"
"048ed70192de0232086eb32a95ffb3be8d336c76",2,"Metaphors We Learn By","This essay relates parameter sharing (“weight sharing”) to analogy making and the school of thought of cognitive metaphor, and discusses how recurrent and auto-regressive models can be thought of as extending analogy making from static features to dynamic skills and procedures.","ArXiv",2022,"R. Memisevic",0,36,0,"https://www.semanticscholar.org/paper/048ed70192de0232086eb32a95ffb3be8d336c76"
"888dd5f5a617ac80bcad9a70005cce2bb1efcb81",2,"CLAWSAT: Towards Both Robust and Accurate Code Models","C LAW SAT is developed, a novel self-supervised learning (SSL) framework for code by integrating CL with adversarial views (C LAW ) with staggered adversarial training (SAT), which consistently yields the best robustness and accuracy.","ArXiv",2022,"Jinghan Jia,Shashank Srikant,Tamara Mitrovska,Chuang Gan,Shiyu Chang,Sijia Liu,Una-May O’Reilly",0,52,0,"https://www.semanticscholar.org/paper/888dd5f5a617ac80bcad9a70005cce2bb1efcb81"
"46d0a832fada6147bceb0bd4e39928e482733246",2,"How Important are Good Method Names in Neural Code Generation? A Model Robustness Perspective","The potential of benefiting from method names to enhance the performance of PCGMs, from a model robustness perspective, is studied and a novel approach is proposed, named RADAR (neuRAl coDe generAtor Robustifier).","ArXiv",2022,"Guang Yang,Yu Zhou,Wenhua Yang,Tao Yue,Xiang Chen,Taolue Chen",0,75,0,"https://www.semanticscholar.org/paper/46d0a832fada6147bceb0bd4e39928e482733246"
"5af1c817e9902b55afacba9722f3a4f2d5510b94",2,"Genetic Programming with Local Scoring","A method of local scoring assigning a score to each expression in a program, allowing to more preciselyify buggy code, and cyclic evolution in which programs evolve programs through phases of expansion and reduction are presented.","ArXiv",2022,"Max Vistrup",0,9,0,"https://www.semanticscholar.org/paper/5af1c817e9902b55afacba9722f3a4f2d5510b94"
"dca3bc28a7d404b28780a813ea7072eda809e6c0",2,"Programming Is Hard - Or at Least It Used to Be: Educational Opportunities And Challenges of AI Code Generation","It is argued that the community needs to act quickly in deciding what possible opportunities can and should be leveraged and how, while also working on how to overcome or otherwise mitigate the possible challenges.","ArXiv",2022,"Brett A. Becker,Paul Denny,James Finnie-Ansley,Andrew Luxton-Reilly,J. Prather,E. Santos",0,49,0,"https://www.semanticscholar.org/paper/dca3bc28a7d404b28780a813ea7072eda809e6c0"
"ae441f7305dc2cd58c708528b3ecee3501cc5c46",2,"Plansformer: Generating Symbolic Plans using Transformers","The use of LLMs for automated planning - a branch of AI concerned with the realization of action sequences (plans) to achieve a goal, typically executed by intelligent agents, autonomous robots, and unmanned vehicles are explored.","ArXiv",2022,"Vishal Pallagani,Bharath Muppasani,K. Murugesan,F. Rossi,L. Horesh,Biplav Srivastava,F. Fabiano,Andrea Loreggia",0,36,0,"https://www.semanticscholar.org/paper/ae441f7305dc2cd58c708528b3ecee3501cc5c46"
"42630c03d3817b1153d245f20742ad4b30a80b75",2,"JEMMA: An Extensible Java Dataset for ML4Code Applications","JEMMA is introduced, which is a largescale, diverse, and high-quality dataset targeted at ML4Code applications, and becomes a workbench that researchers can use to experiment with novel representations and tasks operating on source code.","ArXiv",2022,"Anjan Karmakar,Miltiadis Allamanis,R. Robbes",0,93,0,"https://www.semanticscholar.org/paper/42630c03d3817b1153d245f20742ad4b30a80b75"
"6756fcd998caeb7b23702e08559e63710179334c",2,"Reasoning with Language Model Prompting: A Survey","This paper provides a comprehensive survey of cutting-edge research on reasoning with language model prompting and introduces research works with comparisons and summaries and provides systematic resources to help beginners.","ArXiv",2022,"Shuofei Qiao,Yixin Ou,Ningyu Zhang,Xiang Chen,Yunzhi Yao,Shumin Deng,Chuanqi Tan,Fei Huang,Huajun Chen",3,150,0,"https://www.semanticscholar.org/paper/6756fcd998caeb7b23702e08559e63710179334c"
"d3a7a4543d83f568f79d1febe8379465ff0140c9",2,"A Survey of Deep Learning for Mathematical Reasoning","This survey paper reviews the key tasks, datasets, and methods at the intersec-tion of mathematical reasoning and deep learning over the past decade, and evaluates existing benchmarks and methods and discusses future research directions.","ArXiv",2022,"Pan Lu,Liang Qiu,Wenhao Yu,S. Welleck,Kai-Wei Chang",0,216,0,"https://www.semanticscholar.org/paper/d3a7a4543d83f568f79d1febe8379465ff0140c9"
"a8e0ba16346b72c3a04dd0b1da84bc5f28900174",2,"Using GitHub Copilot to Solve Simple Programming Problems","Evaluating Copilot, a natural language machine learning model trained on billions of lines of code, and looking qualitatively at the generated suggestions, to understand the limitations of Copilot.","",2023,"M. Wermelinger",0,15,0,"https://www.semanticscholar.org/paper/a8e0ba16346b72c3a04dd0b1da84bc5f28900174"
"490f1e8ff352bded30bcde01d5b4769d6c2d2dd5",2,"Adversarial Attacks on Neural Models of Code via Code Difference Reduction","This work proposes a novel adversarial attack technique, CODA, that uses the code differences between the target input and reference inputs to guide the generation of adversarial examples and considers both structure differences and identiﬁer differences to preserve the original semantics.","ArXiv",2023,"Zhao Tian,Junjie Chen,Zhi Jin",0,48,0,"https://www.semanticscholar.org/paper/490f1e8ff352bded30bcde01d5b4769d6c2d2dd5"
"468992bf970c37bd1fef58b78a6c2fcd8c018868",2,"Scaling Laws for Generative Mixed-Modal Language Models","New mixed-modal scaling laws that unify the contributions of individual modalities and the interactions between them are reported, and the optimal synergy and competition due to data and model size is explicitly model as an additive term to previous uni-modAL scaling laws.","ArXiv",2023,"Armen Aghajanyan,L. Yu,Alexis Conneau,Wei-Ning Hsu,Karen Hambardzumyan,Susan Zhang,Stephen Roller,Naman Goyal,Omer Levy,Luke Zettlemoyer",0,41,0,"https://www.semanticscholar.org/paper/468992bf970c37bd1fef58b78a6c2fcd8c018868"
"1f22de83d912176cb8857efa1c6d65b14d6a2f5c",2,"ChatGPT is not all you need. A State of the Art Review of large Generative AI models","This work consists on an attempt to describe in a concise way the main models are sectors that aresector that are aﬀected by generative AI and to provide a taxonomy of the main generative models published recently.","ArXiv",2023,"Roberto Gozalo-Brizuela,E.C. Garrido-Merchán",0,34,0,"https://www.semanticscholar.org/paper/1f22de83d912176cb8857efa1c6d65b14d6a2f5c"
"907a77639069bb7dd270f017068745706133cffc",2,"Inaccessible Neural Language Models Could Reinvigorate Linguistic Nativism","This work argues that this lack of accessibility could instill a nativist bias in researchers new to computational linguistics, and calls upon researchers to open source their LLM code wherever possible to allow both empircist and hybrid approaches to remain accessible.","ArXiv",2023,"Patrick Perrine",0,56,0,"https://www.semanticscholar.org/paper/907a77639069bb7dd270f017068745706133cffc"
"c532f1df90925e5c69789f0cd99248d8a2a2e5bc",2,"My AI Wants to Know if This Will Be on the Exam: Testing OpenAI’s Codex on CS2 Programming Exercises","This paper presents results detailing how Codex performs on more advanced CS2 exam questions taken from past exams, and compares these results to those of students who took the same exams under normal conditions, demonstrating that Codex outscores most students.","IFAC Symposium on Advances in Control Education",2023,"James Finnie-Ansley,Paul Denny,Andrew Luxton-Reilly,E. Santos,J. Prather,Brett A. Becker",0,27,0,"https://www.semanticscholar.org/paper/c532f1df90925e5c69789f0cd99248d8a2a2e5bc"
"43112f25190a9e19dc84cc7a0851318fdd1d9f71",1,"INTENT: Interactive Tensor Transformation Synthesis","INTENT, an interactive system that infers user intent and generates corresponding TensorFlow code on behalf of users, helps users understand and validate the semantics of generated code by rendering individual tensor transformation steps with intermediate results and element-wise data provenance.","ACM Symposium on User Interface Software and Technology",2022,"Zhanhui Zhou,Man To Tang,Qiping Pan,Shangyin Tan,Xinyu Wang,Tianyi Zhang",0,58,0,"https://www.semanticscholar.org/paper/43112f25190a9e19dc84cc7a0851318fdd1d9f71"
"6fe61d77b8a4a090899867b79e32efd658f848e7",1,"Explainable Natural Language to Bash Translation using Abstract Syntax Tree","This work proposes a novel transformer based solution by utilizing Bash Abstract Syntax Trees and manual pages that performs on par with the state of the art performance on Natural Language Context to Command task and performs better than fine-tuned T5 and Seq2Seq models.","Conference on Computational Natural Language Learning",2021,"Shikhar Bharadwaj,S. Shevade",4,21,0,"https://www.semanticscholar.org/paper/6fe61d77b8a4a090899867b79e32efd658f848e7"
"bd5d3022dc395ca85f72e346022ed6175e13a278",1,"A Transformer-based Approach for Translating Natural Language to Bash Commands","The approach presented in this paper is the best performing architecture on this problem to date and improves the current state-of-the-art accuracy on this translation task from 13.8% to 53.2%.","2021 20th IEEE International Conference on Machine Learning and Applications (ICMLA)",2021,"Quchen Fu,Zhongwei Teng,Jules White,Douglas C. Schmidt",4,53,0,"https://www.semanticscholar.org/paper/bd5d3022dc395ca85f72e346022ed6175e13a278"
"012d5d4346e84b6e158b252de9c87589dd62b16e",1,"Efficient Constituency Tree based Encoding for Natural Language to Bash Translation","A Segmented Invocation Transformer (SIT) that utilizes the information from the constituency parse tree of the natural language text and Bash command components is proposed that improves the performance of the model.","North American Chapter of the Association for Computational Linguistics",2022,"Shikhar Bharadwaj,S. Shevade",2,31,0,"https://www.semanticscholar.org/paper/012d5d4346e84b6e158b252de9c87589dd62b16e"
"94ac02f13ac3252a55b8740b7b310383cdf53445",1,"ShellFusion: Answer Generation for Shell Programming Tasks via Knowledge Fusion","This work proposes an approach, i.e., ShellFusion, to automatically generate comprehensive answers (including relevant shell commands, scripts, and explanations) for shell programming tasks, which significantly outperforms Magnum and DeepAns (a recent answer recommendation baseline).","International Conference on Software Engineering",2022,"Neng Zhang,Chao Liu,Xin Xia,Christoph Treude,Ying Zou,David Lo,Zibin Zheng",0,39,0,"https://www.semanticscholar.org/paper/94ac02f13ac3252a55b8740b7b310383cdf53445"
"988cb68d6510f3c4477b8c8ffe9cbdbea7971474",1,"Towards NLP-based Processing of Honeypot Logs","This work considers a widely used SSH/Telnet honeypot to record more than 200000 sessions, including 61000 unique shell scripts, some containing sequences of more than 100 Bash commands, to evaluate whether Natural Language Processing approaches can provide meaningful representations to find common traits in attackers' activity.","2022 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW)",2022,"Matteo Boffa,Giulia Milan,L. Vassio,I. Drago,M. Mellia,Zied Ben-Houidi",2,11,0,"https://www.semanticscholar.org/paper/988cb68d6510f3c4477b8c8ffe9cbdbea7971474"
"8e9d9bf41d69ca8643b67a280b96f886c64bd817",1,"Code2Snapshot: Using Code Snapshots for Learning Representations of Source Code","This paper investigates Code2Snapshot, a novel representation of the source code that is based on the snapshots of input programs, and evaluates several variations of this representation and compares its performance with state-of-the-art representations that utilize the rich syntactic and semantic features ofinput programs.","",2021,"Md Rafiqul Islam Rabin,Mohammad Amin Alipour",3,27,0,"https://www.semanticscholar.org/paper/8e9d9bf41d69ca8643b67a280b96f886c64bd817"
"6a3b6512de2caa712311feb876f1be599a7c0b68",1,"Encoding Program as Image: Evaluating Visual Representation of Source Code","This paper investigates Code2Snapshot, a novel representation of the source code that is based on the snapshots of input programs, and evaluates several variations of this representation and compares its performance with state-of-the-art representations that utilize the rich syntactic and semantic features ofinput programs.","ArXiv",2021,"Md Rafiqul Islam Rabin,Mohammad Amin Alipour",1,26,0,"https://www.semanticscholar.org/paper/6a3b6512de2caa712311feb876f1be599a7c0b68"
"87bb5593d04450bbbd29afc5b2ef395127d1ba6a",1,"Testing the Robustness of a BiLSTM-based Structural Story Classifier","This work examines the impact of noise on a state-of-the-art, structural model based on BiLSTM (Bidirectional Long-Short Term Model) for fake news detection, Hierarchical Discourse-level Structure for Fake News Detection by Karimi and Tang.","ArXiv",2022,"Aftab Hussain,Sai Durga Prasad Nanduri,Sneha Seenuvasavarathan",0,22,0,"https://www.semanticscholar.org/paper/87bb5593d04450bbbd29afc5b2ef395127d1ba6a"
"f0aacc7a0379883c4ab67d9a2d852c7bd99d9797",1,"Extracting Label-specific Key Input Features for Neural Code Intelligence Models","Extracting key input features from reduced programs reveals that the syntax-guided reduced programs contain more label-specific key input Features that may help to understand the reasoning of models’ prediction from different perspectives and increase the trustworthiness to correct classification given by CI models.","ArXiv",2022,"Md Rafiqul Islam Rabin",0,27,0,"https://www.semanticscholar.org/paper/f0aacc7a0379883c4ab67d9a2d852c7bd99d9797"
"b070d2c844d5b18d0c94fb6b20bef3946d60abfd",1,"Readle: A Formal Framework for Designing AI-based Edge Systems","A new systematic, extendable, manual approach, R EADLE, is proposed for creating representations of speciﬁcations in edge intelligent systems, capturing constraints in the edge system design space and constraint in the deep learning space in a coherent fashion.","ArXiv",2022,"Aftab Hussain",0,30,0,"https://www.semanticscholar.org/paper/b070d2c844d5b18d0c94fb6b20bef3946d60abfd"
"6042c51ccce53b94b84d1bdbcb33c3ab493323b4",1,"Syntax-guided program reduction for understanding neural code intelligence models","A syntax-guided program reduction technique that considers the grammar of the input programs during reduction that is faster and provides smaller sets of key tokens in reduced programs is applied.","MAPS@PLDI",2022,"Md Rafiqul Islam Rabin,Aftab Hussain,Mohammad Amin Alipour",3,29,0,"https://www.semanticscholar.org/paper/6042c51ccce53b94b84d1bdbcb33c3ab493323b4"
"22df866f9605d27d1e5cca9b3ab721f33673e158",1,"ProgramTransformer: A tool for generating semantically equivalent transformed programs","","Software Impacts",2022,"Md Rafiqul Islam Rabin,Mohammad Amin Alipour",0,26,0,"https://www.semanticscholar.org/paper/22df866f9605d27d1e5cca9b3ab721f33673e158"
"81ce2664e892fc5f71fa4f8d61e7b42314dccb5e",1,"FeatureExtractor: A tool for extracting key input features of code intelligence models","","Software Impacts",2022,"Md Rafiqul Islam Rabin,Mohammad Amin Alipour",1,18,0,"https://www.semanticscholar.org/paper/81ce2664e892fc5f71fa4f8d61e7b42314dccb5e"
"66eae7128c34dd7967d79224eb9dbc978773c3d0",1,"I2D2: Inductive Knowledge Distillation with NeuroLogic and Self-Imitation","The key intellectual question is whether it is possible, if at all, to design a learning algorithm that does not beneﬁt from scale, yet leads to a competitive level of commonsense acquisition.","ArXiv",2022,"Chandra Bhagavatula,Jena D. Hwang,Doug Downey,Ronan Le Bras,Ximing Lu,Keisuke Sakaguchi,Swabha Swayamdipta,Peter West,Yejin Choi",0,33,0,"https://www.semanticscholar.org/paper/66eae7128c34dd7967d79224eb9dbc978773c3d0"
"459176532c85ae72f8b5cb35589b72468401d844",1,"SelfAPR: Self-supervised Program Repair with Test Execution Diagnostics","SelfAPR correctly repairs 110 bugs from Defects4J, outperforming all the supervised learning repair approaches and executes all training samples and extracts and encodes test execution diagnostics into the input representation, steering the neural model to fix the kind of fault.","International Conference on Automated Software Engineering",2022,"He Ye,Matias Martinez,Xiapu Luo,Tao Zhang,Monperrus Martin",5,98,1,"https://www.semanticscholar.org/paper/459176532c85ae72f8b5cb35589b72468401d844"