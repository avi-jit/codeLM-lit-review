"id","score","title","summary","venue","year","authors","citationCount","referenceCount","influentialCitationCount","url"
"b2c4fdb49bdb23e6ad0ac3272029324157046ea7",7,"Automated Repair of Code from Language Models","The study revealed that automatically generated code shares common programming mistakes with human-crafted solutions, indicating APR techniques may have potential to auto-generated code, and given bug location information provided by a statistical fault localization approach, Codex edit mode is similar to or better than existing Java repair tools TBar and Recoder in correcting incorrect solutions.","",2022,"Zhiyu Fan,Xiang Gao,M. Mirchev,Abhik Roychoudhury,Shin Hwei Tan",0,49,0,"https://www.semanticscholar.org/paper/b2c4fdb49bdb23e6ad0ac3272029324157046ea7"
"0bcd59da541fdae66884afba8d25475a54a9da1a",7,"Automated Repair of Programs from Large Language Models","The study revealed that automatically generated code shares common programming mistakes with human-crafted solutions, indicating APR techniques may have potential to auto-generated code, and given bug location information provided by a statistical fault localization approach, Codex edit mode is similar to or better than existing Java repair tools TBar and Recoder in correcting incorrect solutions.","",2022,"Zhiyu Fan,Xiang Gao,M. Mirchev,Abhik Roychoudhury,Shin Hwei Tan",1,49,0,"https://www.semanticscholar.org/paper/0bcd59da541fdae66884afba8d25475a54a9da1a"
"e73a16490c29530c37b49f6a30592790e7caaaa4",6,"Don't Complete It! Preventing Unhelpful Code Completion for Productive and Sustainable Neural Code Completion Systems","An early-rejection mechanism to turn down low-return prompts by foretelling the code completion qualities without sending them to the codepletion system is proposed and a lightweight Transformer-based estimator is proposed to demonstrate the feasibility of the mechanism.","",2022,"Zhensu Sun,Xiaoning Du,Fu Song,Shangwen Wang,Mingze Ni,Li Li",0,33,0,"https://www.semanticscholar.org/paper/e73a16490c29530c37b49f6a30592790e7caaaa4"
"6074c7b75f27ca9adb6d74b080c07d5d079c3ea0",6,"Improving automatically generated code from Codex via Automated Program Repair","This study systematically study whether automated program repair (APR) techniques can fix the incorrect solutions produced by language models in LeetCode contests, revealing that automatically generated codes share some common programming mistakes with human-crafted solutions, indicating existing APR tools have the potential to fix auto-generated code.","ArXiv",2022,"Zhiyu Fan,Xiang Gao,Abhik Roychoudhury,Shin Hwei Tan",4,45,0,"https://www.semanticscholar.org/paper/6074c7b75f27ca9adb6d74b080c07d5d079c3ea0"
"1b4c19168410fb2690d285b205ab2281793db81a",6,"A Scalable and Extensible Approach to Benchmarking NL2Code for 18 Programming Languages","It is shown that on several languages, Codex matches and even exceeds its performance on Python, and a general approach is described for easily adding support for new benchmarks and languages to MultiPL-E, the first multi-language parallel benchmark for natural-language-to-code-generation.","ArXiv",2022,"Federico Cassano,John Gouwar,Daniel Nguyen,S. Nguyen,Luna Phipps-Costin,Donald Pinckney,Ming-Ho Yee,Yangtian Zi,Carolyn Jane Anderson,Molly Q. Feldman,Arjun Guha,M. Greenberg,Abhinav Jangda",4,27,1,"https://www.semanticscholar.org/paper/1b4c19168410fb2690d285b205ab2281793db81a"
"fba0b0817dbc8200b41a1de22654b54b778a11e9",6,"Recommending Root-Cause and Mitigation Steps for Cloud Incidents using Large Language Models","This work does the first large-scale study to evaluate the effectiveness of GPT-3.x models for helping engineers root cause and mitigate production incidents and compares several large language models in zero-shot, fine-tuned and multi-task setting using semantic and lexical metrics.","ArXiv",2023,"Toufique Ahmed,Supriyo Ghosh,Chetan Bansal,T. Zimmermann,Xuchao Zhang,S. Rajmohan",0,64,0,"https://www.semanticscholar.org/paper/fba0b0817dbc8200b41a1de22654b54b778a11e9"
"68edfd62d2619fb4af7c2469edb95b9e2fe4544a",6,"Execution-based Code Generation using Deep Reinforcement Learning","PPOCoder is a new framework for code generation that combines pretrained PL models with Proximal Policy Optimization (PPO) deep reinforcement learning and employs execution feedback as the external source of knowledge into the model optimization, which is transferable across different code generation tasks and PLs.","ArXiv",2023,"Parshin Shojaee,Aneesh Jain,S. Tipirneni,C. Reddy",0,45,0,"https://www.semanticscholar.org/paper/68edfd62d2619fb4af7c2469edb95b9e2fe4544a"
"3d5463a16d85d9d1d0d8ebb4117a31aca3c240ff",5,"Fooling MOSS Detection with Pretrained Language Models","It is found that a student using GPT-J can complete introductory level programming assignments without triggering suspicion from MOSS, a widely used software similarity and plagiarism detection tool.","International Conference on Information and Knowledge Management",2022,"Stella Rose Biderman,Edward Raff",2,70,0,"https://www.semanticscholar.org/paper/3d5463a16d85d9d1d0d8ebb4117a31aca3c240ff"
"6032212d5790b6a580d68d469a9895aad6238c89",5,"Diverse Title Generation for Stack Overflow Posts with Multiple Sampling Enhanced Transformer","A novel approach to automatically generate multiple post titles from the given code snippets, using the maximal marginal multiple nucleus sampling strategy to generate multiple high-quality and diverse title candidates at a time for the developers to choose from.","ArXiv",2022,"Fengji Zhang,Jin Liu,Yao Wan,Xiao Yu,Xiao Liu,J. Keung",0,56,0,"https://www.semanticscholar.org/paper/6032212d5790b6a580d68d469a9895aad6238c89"
"ebd4bec684808aff360b5f255d15c0d112ba13d3",5,"Explicit Knowledge Transfer for Weakly-Supervised Code Generation","This paper proposes explicit knowledge transfer (EKT), which uses the few-shot capabilities of a teacher LLM to create NL-code pairs that are filter for correctness and fine-tune the student on, and finds that EKT not only yields better performance than training with expert iteration, but also outperforms knowledge distillation, another form of knowledge transfer.","ArXiv",2022,"Zhangir Azerbayev,Ansong Ni,Hailey Schoelkopf,Dragomir R. Radev",0,29,0,"https://www.semanticscholar.org/paper/ebd4bec684808aff360b5f255d15c0d112ba13d3"
"d3a7a4543d83f568f79d1febe8379465ff0140c9",5,"A Survey of Deep Learning for Mathematical Reasoning","This survey paper reviews the key tasks, datasets, and methods at the intersec-tion of mathematical reasoning and deep learning over the past decade, and evaluates existing benchmarks and methods and discusses future research directions.","ArXiv",2022,"Pan Lu,Liang Qiu,Wenhao Yu,S. Welleck,Kai-Wei Chang",1,216,1,"https://www.semanticscholar.org/paper/d3a7a4543d83f568f79d1febe8379465ff0140c9"
"d8405996b4d08c304098636aedd9e1c1a1e262ee",5,"The Premature Obituary of Programming","Why deep learning will not replace programming and why deep learning should not be considered as a programming language.","Communications of the ACM",2023,"D. Yellin",0,23,0,"https://www.semanticscholar.org/paper/d8405996b4d08c304098636aedd9e1c1a1e262ee"
"1c8e15f15d67c5974445634bb971e2275e957aff",4,"Security Implications of Large Language Model Code Assistants: A User Study","A security-driven user study to assess code written by student programmers when assisted by LLMs and indicates that the security impact in this setting is small: AI-assisted users produce critical security bugs at a rate no greater than 10% more than the control.","ArXiv",2022,"Gustavo Sandoval,H. Pearce,Teo Nys,R. Karri,Brendan Dolan-Gavitt,S. Garg",4,53,0,"https://www.semanticscholar.org/paper/1c8e15f15d67c5974445634bb971e2275e957aff"
"a7435722d8ab595da5a9c70ac9160f57d0dcd75a",4,"Enabling Transformers to Understand Low-Level Programs","This work applies transfer learning to low-level (LLVM) programs and study how low- level programs can be made more amenable to Transformer models through various techniques, including preprocessing, infix/prefix operators, and information deduplication.","IEEE Conference on High Performance Extreme Computing",2022,"Zifan Carl Guo,William S. Moses",0,53,0,"https://www.semanticscholar.org/paper/a7435722d8ab595da5a9c70ac9160f57d0dcd75a"
"971e875e28f26240987d2c9470d1ee74ad204205",4,"Large Language Models are Few-shot Testers: Exploring LLM-based General Bug Reproduction","Results show L IBRO has the potential to enhance developerency by automatically generating tests from bug reports, and is proposed as a framework that uses Large Language Models (LLMs), which have been shown to be capable of performing code-related tasks.","ArXiv",2022,"Sungmin Kang,Juyeon Yoon,Shin Yoo",0,39,0,"https://www.semanticscholar.org/paper/971e875e28f26240987d2c9470d1ee74ad204205"
"825333b7efe2cade106eaf36c7e731f757974806",4,"How Readable is Model-generated Code? Examining Readability and Visual Inspection of GitHub Copilot","The results suggest that model generated code is comparable in complexity and readability to code written by human pair programmers, and eye tracking data suggests, to a statistically significant level, that programmers direct less visual attention to model generate code.","37th IEEE/ACM International Conference on Automated Software Engineering",2022,"Naser Al Madi",0,28,0,"https://www.semanticscholar.org/paper/825333b7efe2cade106eaf36c7e731f757974806"
"39e40821b7207125e54e6ed7112e55cd38c6f0c3",4,"Language Models of Code are Few-Shot Commonsense Learners","This paper shows that when this task is frame as code generation tasks, pre-trained LMs of code are better structured commonsense reasoners than L Ms of natural language, even when the downstream task does not involve source code at all.","Conference on Empirical Methods in Natural Language Processing",2022,"Aman Madaan,Shuyan Zhou,Uri Alon,Yiming Yang,Graham Neubig",11,38,1,"https://www.semanticscholar.org/paper/39e40821b7207125e54e6ed7112e55cd38c6f0c3"
"a6ef5bad716091fb1888bf365f6129628ab3a5ee",4,"ObSynth: An Interactive Synthesis System for Generating Object Models from Natural Language Specifications","ObSynth is introduced, an interactive system leveraging the domain knowledge em-bedded in large language models (LLMs) to help users design object models from high level natural language prompts, showing that it often synthesizes objects, methods, and methods users might have otherwise omitted.","ArXiv",2022,"Alex Gu,Tamara Mitrovska,D. Vélez,Jacob Andreas,Armando Solar-Lezama",0,29,0,"https://www.semanticscholar.org/paper/a6ef5bad716091fb1888bf365f6129628ab3a5ee"
"0566c1c3eeeef5c968fced6d80b77fe22d02bbd9",4,"Conversing with Copilot: Exploring Prompt Engineering for Solving CS1 Problems Using Natural Language","Evaluating the performance of Copilot on a publicly available dataset of 166 programming problems finds that it successfully solves around half of these problems on its very first attempt, and that it solves 60% of the remaining problems using only natural language changes to the problem description.","ArXiv",2022,"Paul Denny,Viraj Kumar,Nasser Giacaman",5,24,0,"https://www.semanticscholar.org/paper/0566c1c3eeeef5c968fced6d80b77fe22d02bbd9"
"ec7324a15009a9bd0b676f6b17762f759cf5dd9a",4,"Large Language Models Are Human-Level Prompt Engineers","It is shown that APE-engineered prompts can be applied to steer models toward truthfulness and/or informativeness, as well as to improve few-shot learning performance by simply prepending them to standard in-context learning prompts.","ArXiv",2022,"Yongchao Zhou,Andrei Ioan Muresanu,Ziwen Han,Keiran Paster,Silviu Pitis,Harris Chan,Jimmy Ba",12,51,2,"https://www.semanticscholar.org/paper/ec7324a15009a9bd0b676f6b17762f759cf5dd9a"
"71280dba5bda65c162f9deaffed7d3d20692ca0a",4,"SecurityEval dataset: mining vulnerability examples to evaluate machine learning-based code generation techniques","SecurityEval, an evaluation dataset that contains 130 samples for 75 vulnerability types, which are mapped to the Common Weakness Enumeration (CWE) and demonstrated using one open-source and one closed-source code generation model to evaluate.","",2022,"Mohammed Latif Siddiq,msiddiq",3,28,1,"https://www.semanticscholar.org/paper/71280dba5bda65c162f9deaffed7d3d20692ca0a"
"c192fb33f308f19ac8a5c4c2d623d56385b839be",4,"Systematic Literature Review on Solving Competitive Programming Problem with Artificial Intelligence (AI)","It can be concluded that the code auto-completion and code-generation tools that are available now still do not meet the necessary benchmark which is solving CP tasks, and AI still has a long way to go before competing at the highest level of CP.","2022 1st International Conference on Software Engineering and Information Technology (ICoSEIT)",2022,"Francis Alexander,Edwin Ario Abdiwijaya,Felix Pherry,A. A. Gunawan,Anderies",0,30,0,"https://www.semanticscholar.org/paper/c192fb33f308f19ac8a5c4c2d623d56385b839be"
"8175ce2cbb99b6a394bdac152ae39d413f4f1380",4,"Codex Hacks HackerRank: Memorization Issues and a Framework for Code Synthesis Evaluation","This work evaluates the code synthesis capabilities of the Codex model based on a set of 115 Python problem statements from a popular competitive programming portal: HackerRank, and proposes a framework for code-synthesis evaluation using variations of problem statements based on mutations.","ArXiv",2022,"Anjan Karmakar,Julian Aron Prenner,Marco D'Ambros,R. Robbes",1,37,0,"https://www.semanticscholar.org/paper/8175ce2cbb99b6a394bdac152ae39d413f4f1380"
"9e8f0d9ba4e7af673c8b214b3764e020706dd1f3",4,"Don't Generate, Discriminate: A Proposal for Grounding Language Models to Real-World Environments","Pangu is proposed, a generic framework for grounded language understanding that capitalizes on the discriminative ability of LMs instead of their generative ability, and enables, for the first time, effective few-shot in-context learning for KBQA with large LMs such as Codex.","ArXiv",2022,"Yu Gu,Xiang Deng,Yu Su",0,66,0,"https://www.semanticscholar.org/paper/9e8f0d9ba4e7af673c8b214b3764e020706dd1f3"
"12a4e62c43b829dabdb8afc60eee76aa80fa3f6e",4,"Fuzzing Deep-Learning Libraries via Large Language Models","LLMFuzz is the first automated approach to directly leveraging Large Pre-trained Language Models (LLMs) to generate input programs for fuzzing DL libraries, and is able to detect 65 bugs, with 41 already confirmed as previously unknown bugs.","ArXiv",2022,"Yinlin Deng,Chun Xia,Haoran Peng,Chenyuan Yang,Lingming Zhang",0,65,0,"https://www.semanticscholar.org/paper/12a4e62c43b829dabdb8afc60eee76aa80fa3f6e"
"c72ac81c4ac414314b52cf8f5b77370f8d0875d4",4,"Generating High-Precision Feedback for Programming Syntax Errors using Large Language Models","The key idea behind PyFiXV is to use a novel run-time validation mechanism to decide whether the generated feedback is suitable for sharing with the student; notably, this validation mechanism also provides a precision knob to educators.","ArXiv",2023,"Tung Phung,J. Cambronero,Sumit Gulwani,Tobias Kohn,R. Majumdar,A. Singla,Gustavo Soares",0,36,0,"https://www.semanticscholar.org/paper/c72ac81c4ac414314b52cf8f5b77370f8d0875d4"
"0885556b71b24a641b4ffe139afd4d2712228cff",4,"Beware of the Unexpected: Bimodal Taint Analysis","Fluffy is presented, a bimodal taint analysis that combines static analysis, which reasons about data flow, with machine learning, which probabilistically determines which flows are potentially problematic.","ArXiv",2023,"Yiu Wai Chow,Max Schäfer,Michael Pradel",0,54,0,"https://www.semanticscholar.org/paper/0885556b71b24a641b4ffe139afd4d2712228cff"
"e9a64e58855dbbc725203d0202ceb9e7f8b7bb36",3,"A Survey of Learning-based Automated Program Repair","This work presents a meta-modelling system that automates the very labor-intensive and therefore time-heavy and therefore expensive and expensive process of manually cataloging and cataloging individual neurons in the brain.","ArXiv",2023,"Quanjun Zhang,Chunrong Fang,Yuxiang Ma,Weisong Sun,Zhenyu Chen",1,185,0,"https://www.semanticscholar.org/paper/e9a64e58855dbbc725203d0202ceb9e7f8b7bb36"
"b1eebb2df3b9ff7ff2b00fb1a786f6ada2caebce",3,"Towards a Mathematics Formalisation Assistant using Large Language Models","The abilities of a large language model (Codex) to help with formalisation in the Lean theorem prover are explored, finding that with careful inputdependent prompt selection and postprocessing, Codex is able to formalise short mathematical statements at undergrad level with nearly 75% accuracy for 120 theorem statements.","ArXiv",2022,"Ayush Agrawal,Siddhartha Gadgil,Navin Goyal,Ashvni Narayanan,Anand Tadipatri",0,26,0,"https://www.semanticscholar.org/paper/b1eebb2df3b9ff7ff2b00fb1a786f6ada2caebce"
"4ddc26b3a5fe9044b97b408d163f7464d769ebbf",3,"CODEP: Grammatical Seq2Seq Model for General-Purpose Code Generation","This paper proposes CODEP, a grammatical Seq2Seq code generation framework equipped with a Pushdown automaton (PDA) module, and constructs the DPA for the most popular GPL Python and conducts extensive experiments to evaluate the effectiveness.","ArXiv",2022,"Yihong Dong,Ge Li,Zhi Jin",2,41,0,"https://www.semanticscholar.org/paper/4ddc26b3a5fe9044b97b408d163f7464d769ebbf"
"7497360b0f411a44aa6afbd8b830050c40ec8aed",3,"Dataset of Student Solutions to Algorithm and Data Structure Programming Assignments","This paper presents a dataset containing source code solutions to algorithmic programming exercises solved by hundreds of Bachelor-level students at the University of Hamburg, and plans to extend the dataset with tasks and solutions from upcoming courses.","International Conference on Language Resources and Evaluation",2022,"Fynn Petersen-Frey,Marcus Soll,Louis Kobras,Melf Johannsen,Peter Kling,Chris Biemann",0,18,0,"https://www.semanticscholar.org/paper/7497360b0f411a44aa6afbd8b830050c40ec8aed"
"4f278ab5ad629267e06196e273252262854c1c57",3,"BF++: a language for general-purpose program synthesis","A new programming language, BF ++ is proposed, designed speciﬁcally for automatic programming of agents in a Partially Observable Markov Decision Process (POMDP) setting and apply neural program synthesis to solve standard OpenAI Gym benchmarks.","",2021,"Vadim Liventsev,A. Harma,M. Petkovi'c",0,57,0,"https://www.semanticscholar.org/paper/4f278ab5ad629267e06196e273252262854c1c57"
"92173d081b15824d22a9ef070e118744ceee8052",3,"Show Your Work: Scratchpads for Intermediate Computation with Language Models","Surprisingly, large pre-trained language models are able to perform complex multistep computations—even in the few-shot regime—when asked to perform the operation “step by step”, showing the results of intermediate computations.","ArXiv",2021,"Maxwell Nye,Anders Andreassen,Guy Gur-Ari,H. Michalewski,Jacob Austin,David Bieber,David Dohan,Aitor Lewkowycz,Maarten Bosma,D. Luan,Charles Sutton,Augustus Odena",112,30,11,"https://www.semanticscholar.org/paper/92173d081b15824d22a9ef070e118744ceee8052"
"a5731122200fbb8b37f048010a1e1ca4474aa606",3,"Examining Zero-Shot Vulnerability Repair with Large Language Models","This work examines the use of large language models for code (such as OpenAI’s Codex and AI21's Jurassic J-1) for zero-shot vulnerability repair, and investigates challenges in the design of prompts that coax LLMs into generating repaired versions of insecure code.","",2021,"H. Pearce,B. Tan,Baleegh Ahmad,R. Karri,Brendan Dolan-Gavitt",7,56,0,"https://www.semanticscholar.org/paper/a5731122200fbb8b37f048010a1e1ca4474aa606"
"5ff9032d0f7f246d01ae7b2c231ab03469a7344a",3,"Can OpenAI Codex and Other Large Language Models Help Us Fix Security Bugs?","This work examines the use of large language models for code (such as OpenAI's Codex and AI21's Jurassic J-1) for zero-shot vulnerability repair, and investigates challenges in the design of prompts that coax LLMs into generating repaired versions of insecure code.","ArXiv",2021,"H. Pearce,B. Tan,Baleegh Ahmad,R. Karri,Brendan Dolan-Gavitt",20,56,1,"https://www.semanticscholar.org/paper/5ff9032d0f7f246d01ae7b2c231ab03469a7344a"
"9a2ca811882ed7513f83014b9de4fb3b4ab218c4",3,"C OMPOSITIONAL G ENERALIZATION AND D ECOMPOSITION IN N EURAL P ROGRAM S YNTHESIS","A suite of generalization tasks, which measure different types of compositional generalization that are desirable for program synthesis and are particularly difﬁcult for current sequence to sequence models, are proposed.","",,"",0,0,0,"https://www.semanticscholar.org/paper/9a2ca811882ed7513f83014b9de4fb3b4ab218c4"
"a2b6e1f7d8a7963d321f29fca7c01eeb1ebd7f0f",3,"P ATCH G ENERATION WITH L ANGUAGE M ODELS : F EASIBILITY AND S CALING B EHAVIOR","This work highlights a noticeable correlation of model size with test-passing accuracy and patch ranking quality, and the propensity for especially the largest models to generate candidate patches that closely resemble (if not exactly match), the original developer patch.","",2022,"Sophia Kolak,Ruben Martins,Claire Le Goues,V. Hellendoorn",0,23,0,"https://www.semanticscholar.org/paper/a2b6e1f7d8a7963d321f29fca7c01eeb1ebd7f0f"
"78863000eb70945cc8d791d45d4a3fe8a6521cb6",3,"Open-ended Knowledge Tracing for Computer Science Education","An initial solution to the OKT problem is developed, a student knowledge-guided code generation approach that combines program synthesis methods using language models with student knowledge tracing methods and a series of quantitative and qualitative experiments on a real-world student code dataset to validate and demonstrate the promise of OKT.","Conference on Empirical Methods in Natural Language Processing",2022,"Naiming Liu,Zichao Wang",0,55,0,"https://www.semanticscholar.org/paper/78863000eb70945cc8d791d45d4a3fe8a6521cb6"
"56e6d62c638a24411f12d15cdc8821a31fc495c8",3,"Source Code Generation from Descriptions in a Natural Language","This work introduces CodeFormer, a Python source code generator pretrained on a massive GitHub crawl consisting of 230M Python functions, and releases the resulting model, built on BART architecture, which generates Python functions based on descriptions in English.","",2022,"Bc. Jan Pašek",0,70,0,"https://www.semanticscholar.org/paper/56e6d62c638a24411f12d15cdc8821a31fc495c8"
"1aed58bd07026492194672adec494dc37c894a28",3,"Leveraging Automated Unit Tests for Unsupervised Code Translation","This work proposes to leverage an automated unit-testing system to filter out invalid translations, thereby creating a fully tested parallel corpus, and finds that fine-tuning an unsupervised model with this filtered data set significantly reduces the noise in the translations so-generated, comfortably outperforming the state of the art for all language pairs studied.","International Conference on Learning Representations",2021,"Baptiste Rozière,J Zhang,François Charton,M. Harman,Gabriel Synnaeve,Guillaume Lample",19,60,2,"https://www.semanticscholar.org/paper/1aed58bd07026492194672adec494dc37c894a28"
"52db8674337e5d86dcb96d013734befc8c3d4581",3,"Large Language Models are not Models of Natural Language: they are Corpus Models.","It is argued that the term language model is misleading because deep learning models are not theoretical models of language and proposed the adoption of corpus model instead, which better reflects the genesis and contents of the model.","IEEE Access",2021,"C. Veres",1,63,0,"https://www.semanticscholar.org/paper/52db8674337e5d86dcb96d013734befc8c3d4581"
"7b5aa186ca8abc585607c5ec91562e127a398601",3,"Open-Ended Knowledge Tracing","This paper develops an initial solution to the OKT problem, a student knowledge-guided code generation approach that combines program synthesis methods using language models with student knowledge tracing methods and conducts a series of quantitative and qualitative experiments on a real-world student code dataset to validate OKT and demonstrate its promise in educational applications.","ArXiv",2022,"Naiming Liu,Zichao Wang,Richard Baraniuk,Andrew S. Lan",0,64,0,"https://www.semanticscholar.org/paper/7b5aa186ca8abc585607c5ec91562e127a398601"
"1f11601f9eb8c0bee1d1d2cc7f4fa187e8c5e525",3,"The impact of lexical and grammatical processing on generating code from natural language","The paper highlights the importance of the lexical substitution component in the current natural language to code systems with a state-of-the-art architecture that relies on BERT encoder and a grammar-based decoder for which a formalization is provided.","Findings",2022,"Nathanael Beau,Benoit Crabb'e",4,19,2,"https://www.semanticscholar.org/paper/1f11601f9eb8c0bee1d1d2cc7f4fa187e8c5e525"
"771371fb288da26a9812f5808535847a0a9c9a80",3,"A Conversational Paradigm for Program Synthesis","This work proposes and trains C ODE G EN, an interactive code generation model for program synthesis, and suggests that the capacity of conversational program synthesis scales as a function of the model size and data size.","ArXiv",2022,"Erik Nijkamp,Bo Pang,Hiroaki Hayashi,Lifu Tu,Haiquan Wang,Yingbo Zhou,S. Savarese,Caiming Xiong",59,39,22,"https://www.semanticscholar.org/paper/771371fb288da26a9812f5808535847a0a9c9a80"
"094ff971d6a8b8ff870946c9b3ce5aa173617bfb",3,"PaLM: Scaling Language Modeling with Pathways","A 540-billion parameter, densely activated, Transformer language model, which is called PaLM achieves breakthrough performance, outperforming the state-of-the-art on a suite of multi-step reasoning tasks, and outperforming average human performance on the recently released BIG-bench benchmark.","ArXiv",2022,"Aakanksha Chowdhery,Sharan Narang,Jacob Devlin,Maarten Bosma,Gaurav Mishra,Adam Roberts,P. Barham,Hyung Won Chung,Charles Sutton,Sebastian Gehrmann,Parker Schuh,Kensen Shi,Sasha Tsvyashchenko,Joshua Maynez,Abhishek Rao,Parker Barnes,Yi Tay,Noam M. Shazeer,Vinodkumar Prabhakaran,Emily Reif,Nan Du,B. Hutchinson,Reiner Pope,James Bradbury,Jacob Austin,M. Isard,Guy Gur-Ari,Pengcheng Yin,Toju Duke,Anselm Levskaya,S. Ghemawat,Sunipa Dev,H. Michalewski,Xavier García,Vedant Misra,Kevin Robinson,L. Fedus,Denny Zhou,Daphne Ippolito,D. Luan,Hyeontaek Lim,Barret Zoph,A. Spiridonov,Ryan Sepassi,David Dohan,Shivani Agrawal,Mark Omernick,Andrew M. Dai,T. S. Pillai,Marie Pellat,Aitor Lewkowycz,Erica Moreira,Rewon Child,Oleksandr Polozov,Katherine Lee,Zongwei Zhou,Xuezhi Wang,Brennan Saeta,Mark Díaz,Orhan Firat,Michele Catasta,Jason Wei,K. Meier-Hellstern,D. Eck,J. Dean,Slav Petrov,Noah Fiedel",540,173,78,"https://www.semanticscholar.org/paper/094ff971d6a8b8ff870946c9b3ce5aa173617bfb"
"6a250b904965732840a75b6a13e35ac15f5cce4d",3,"Compositional Generalization and Decomposition in Neural Program Synthesis","A suite of generalization tasks, which measure different types of compositional generalization that are desirable for program synthesis and are particularly difﬁcult for current sequence to sequence models, are proposed.","ArXiv",2022,"Kensen Shi,Joey Hong,M. Zaheer,Pengcheng Yin,Charles Sutton",0,67,0,"https://www.semanticscholar.org/paper/6a250b904965732840a75b6a13e35ac15f5cce4d"
"1f87dc41bdf2c4c78e2dce9c5c8adfef5e25a70c",3,"Passport: Improving Automated Formal Verification Using Identifiers","Passport is a fully-automated proof-synthesis tool that encodes one additional aspect of that rich proof data: identifiers, suggesting that modeling identifiers can play a significant role in improving proof synthesis, leading to higher-quality software.","ArXiv",2022,"Alex Sanchez-Stern,E. First,Timothy Zhou,Zhanna Kaufman,Yuriy Brun,T. Ringer",4,73,0,"https://www.semanticscholar.org/paper/1f87dc41bdf2c4c78e2dce9c5c8adfef5e25a70c"
"f7820b52e3cdff6625e6bd0430a8d48ca66cca3f",3,"Self-Programming Artificial Intelligence Using Code-Generating Language Models","It is empirically show that a self-programming AI implemented using a code generation model can successfully modify its own source code to improve performance and program sub-models to perform auxiliary tasks.","",2022,"Alex Sheng,Shankar Padmanabhan",0,31,0,"https://www.semanticscholar.org/paper/f7820b52e3cdff6625e6bd0430a8d48ca66cca3f"
"9a7d4c2f4309a2a38ea8e5b23c6d616fa0952d44",3,"Neural language models for network configuration: Opportunities and reality check","Recent advances in deep learning applied to programming languages are surveyed, for the purpose of code veriﬁcation, synthesis and translation: in particularly, their training requirements and expected performance are reviewed, and qualitatively assess whether similar techniques can bene⬁t corresponding use-cases in networking.","Computer Communications",2022,"Zied Ben-Houidi,Dario Rossi",4,63,0,"https://www.semanticscholar.org/paper/9a7d4c2f4309a2a38ea8e5b23c6d616fa0952d44"
"0efa0441da820b1905572666ba1974a06a9663fb",3,"NaturalProver: Grounded Mathematical Proof Generation with Language Models","N ATURAL P ROVER is capable of proving some theorems that require short (2-6 step) proofs, and providing next-step suggestions that are rated as correct and useful over 40% of the time, which is to the authors' knowledge the first demonstration of these capabilities using neural language models.","ArXiv",2022,"S. Welleck,Jiacheng Liu,Ximing Lu,Hannaneh Hajishirzi,Yejin Choi",6,53,0,"https://www.semanticscholar.org/paper/0efa0441da820b1905572666ba1974a06a9663fb"
"0d08ffccc982781e310bb184397bbe64b9aef157",3,"Automatic Generation of Programming Exercises and Code Explanations Using Large Language Models","The analysis suggests that there is significant value in massive generative machine learning models as a tool for instructors, although there remains a need for some oversight to ensure the quality of the generated content before it is delivered to students.","International Computing Education Research Workshop",2022,"Sami Sarsa,Paul Denny,Arto Hellas,Juho Leinonen",19,99,1,"https://www.semanticscholar.org/paper/0d08ffccc982781e310bb184397bbe64b9aef157"
"2edc8efcda27c944a46f367acf6a5280b8f65525",3,"FixEval: Execution-based Evaluation of Program Fixes for Competitive Programming Problems","This work introduces F IX E VAL, a benchmark comprising of buggy code submissions to competitive programming problems and their respective ﬁxes, and believes it provides a step towards real-world automatic bugﬁxing and model-generated code evaluation.","ArXiv",2022,"Md. Mahim Anjum Haque,W. Ahmad,Ismini Lourentzou,Chris Brown",0,56,0,"https://www.semanticscholar.org/paper/2edc8efcda27c944a46f367acf6a5280b8f65525"
"ab0e3d3e4d42369de5933a3b4c237780b41c0d77",3,"Solving Quantitative Reasoning Problems with Language Models","","ArXiv",2022,"Aitor Lewkowycz,Anders Andreassen,David Dohan,Ethan Dyer,H. Michalewski,V. Ramasesh,Ambrose Slone,Cem Anil,Imanol Schlag,Theo Gutman-Solo,Yuhuai Wu,Behnam Neyshabur,Guy Gur-Ari,Vedant Misra",77,51,14,"https://www.semanticscholar.org/paper/ab0e3d3e4d42369de5933a3b4c237780b41c0d77"
"99f85119f113b5498517928eff74a904b69e37b7",3,"CCTEST: Testing and Repairing Code Completion Systems","This research proposes CCT EST, a framework to test and repair code completion systems in black-box settings, which features a set of novel mutation strategies, namely program structure-consistent (PSC) mutations, to generate mutated code completion inputs.","ArXiv",2022,"Zongjie Li,Chaozheng Wang,Zhibo Liu,Haoxuan Wang,Shuai Wang,Cuiyun Gao",1,81,0,"https://www.semanticscholar.org/paper/99f85119f113b5498517928eff74a904b69e37b7"
"95fa2b27ab7eb84738441ee16da97323538938f9",3,"I Speak, You Verify: Toward Trustworthy Neural Program Synthesis","An approach for improving the trustworthiness and overall accuracy of program synthesizers based on large language models for source code by analyzing the agreement between programs and predicates to judge both which program is most likely to be correct and whether the language model is able to solve the programming problem in the first place.","ArXiv",2022,"Darren Key,Wen-Ding Li,Kevin Ellis",0,34,0,"https://www.semanticscholar.org/paper/95fa2b27ab7eb84738441ee16da97323538938f9"
"0b8772b7790c69f40897b5eb7f8fd57f24138f3d",3,"ContraGen: Effective Contrastive Learning For Causal Language Model","It is shown that C ONTRA G EN can effectively enhance both uniformity and discrimination of the representations and lead to the desired improvement on various language understanding tasks where discriminative representations are crucial for attaining good performance.","ArXiv",2022,"Nihal Jain,Dejiao Zhang,Wasi Uddin Ahmad,Zijian Wang,Feng Nan,Xiaopeng Li,M. Tan,Ramesh Nallapati,Baishakhi Ray,Parminder Bhatia,Xiaofei Ma,Bing Xiang",0,66,0,"https://www.semanticscholar.org/paper/0b8772b7790c69f40897b5eb7f8fd57f24138f3d"
"0c78a473e33a81246d5c0fbbda7e7de168814c18",3,"FlexType: A Plug-and-Play Framework for Type Inference Models","This work introduces FlexType, an IDE extension that can be used on both JavaScript and TypeScript to infer types in an interactive or automatic fashion and believes the interactive Visual Studio Code extension is inherently useful in both TypeScript and JavaScript especially when resolving types is taxing for the developer.","International Conference on Automated Software Engineering",2022,"Sivani Voruganti,Kevin Jesse,Prem Devanbu",0,39,0,"https://www.semanticscholar.org/paper/0c78a473e33a81246d5c0fbbda7e7de168814c18"
"663a41c866d49ce052801fbc88947d39764cad29",3,"Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them","It is found that applying chain-of-thought (CoT) prompting to BBH tasks enables PaLM to surpass the average human-rater performance on 10 of the 23 tasks, and Codex to surpass it on 17 of the23 tasks.","ArXiv",2022,"Mirac Suzgun,Nathan Scales,Nathanael Scharli,Sebastian Gehrmann,Yi Tay,Hyung Won Chung,Aakanksha Chowdhery,Quoc V. Le,E. Chi,Denny Zhou,Jason Wei",23,55,5,"https://www.semanticscholar.org/paper/663a41c866d49ce052801fbc88947d39764cad29"
"8ffe7b7eeddbd4c22d642b0a48379d17e61c3bab",3,"Soft-Labeled Contrastive Pre-training for Function-level Code Representation","This paper presents SCodeR, aoft-labeled contrastive pre-training framework with two positive sample construction methods to learn functional-level code representation and shows the effectiveness of the proposed pre- training method.","Conference on Empirical Methods in Natural Language Processing",2022,"Xiaonan Li,Daya Guo,Yeyun Gong,Yun Lin,Yelong Shen,Xipeng Qiu,Daxin Jiang,Weizhu Chen,Nan Duan",2,42,0,"https://www.semanticscholar.org/paper/8ffe7b7eeddbd4c22d642b0a48379d17e61c3bab"
"4c2534f9b03ac2f3810c07abc398a11bcf47258e",3,"Transformers Learn Shortcuts to Automata","The theoretical results completely characterize shortcut solutions, whereby a shallow Transformer with only o(T ) layers can exactly replicate the computation of an automaton on an input sequence of length T .","ArXiv",2022,"Bingbin Liu,J. Ash,Surbhi Goel,A. Krishnamurthy,Cyril Zhang",4,104,0,"https://www.semanticscholar.org/paper/4c2534f9b03ac2f3810c07abc398a11bcf47258e"
"f031ba42cf82f106200bb03fbb91dd5671a59b9c",3,"Practical Program Repair in the Era of Large Pre-trained Language Models","This study demonstrates that directly applying state-of-the-art PLMs can already substantially outperform all existing APR techniques on all the authors' datasets and shows that PLM-based APR can be further substantially boosted via: increasing the sample size, and incorporating inﬁx template information.","ArXiv",2022,"Chun Xia,Yuxiang Wei,Lingming Zhang",4,69,0,"https://www.semanticscholar.org/paper/f031ba42cf82f106200bb03fbb91dd5671a59b9c"
"621009f1c30951b7c952c65c45ef0064a204e91e",3,"Early Experience with Transformer-Based Similarity Analysis for DataRaceBench","The challenges and the solutions when applying transformer-based similarity analysis to new source codes which are unseen by pre-trained transformers are explored, and comparative experiments of different variants of similarity analysis are used to comment on the strengths and limitations of the transformer- based approach and point out future research directions.","International Workshop on Software Correctness for HPC Applications",2022,"Winson X. Chen,T. Vanderbruggen,Pei-Hung Lin,C. Liao,M. Emani",0,38,0,"https://www.semanticscholar.org/paper/621009f1c30951b7c952c65c45ef0064a204e91e"
"2abed82162c47a0cc32cd62afcf46b0745541017",3,"Experiences from Using Code Explanations Generated by Large Language Models in a Web Software Development E-Book","The preliminary results show that all varieties of explanations were viewed by students and that the majority of students perceived the code explanations as helpful to them, however, student engagement appeared to vary by code snippet complexity, explanation type, and code snippet length.","ArXiv",2022,"S. MacNeil,Andrew Tran,Arto Hellas,Joanne Kim,Sami Sarsa,Paul Denny,Seth Bernstein,Juho Leinonen",3,45,0,"https://www.semanticscholar.org/paper/2abed82162c47a0cc32cd62afcf46b0745541017"
"327f1561b544b0a3b9d8d5d0e6d82c2a5911fca9",3,"BLOOM: A 176B-Parameter Open-Access Multilingual Language Model","BLOOM is a 176B-parameter open-access language model designed and built thanks to a collaboration of hundreds of researchers and achieves competitive performance on a wide variety of benchmarks, with stronger results after undergoing multitask prompted finetuning.","ArXiv",2022,"Teven Le Scao,Angela Fan,Christopher Akiki,Elizabeth-Jane Pavlick,Suzana Ili'c,Daniel Hesslow,Roman Castagn'e,A. Luccioni,Franccois Yvon,Matthias Gallé,J. Tow,Alexander M. Rush,Stella Rose Biderman,Albert Webson,Pawan Sasanka Ammanamanchi,Thomas Wang,Benoît Sagot,Niklas Muennighoff,Albert Villanova del Moral,Olatunji Ruwase,Rachel Bawden,Stas Bekman,Angelina McMillan-Major,Iz Beltagy,Huu Nguyen,Lucile Saulnier,Samson Tan,Pedro Ortiz Suarez,Victor Sanh,Hugo Laurenccon,Yacine Jernite,Julien Launay,Margaret Mitchell,Colin Raffel,Aaron Gokaslan,Adi Simhi,Aitor Soroa Etxabe,Alham Fikri Aji,Amit Alfassy,Anna Rogers,Ariel Kreisberg Nitzav,Canwen Xu,Chenghao Mou,Chris C. Emezue,Christopher Klamm,Colin Leong,Daniel Alexander van Strien,David Ifeoluwa Adelani,Dragomir R. Radev,Eduardo G. Ponferrada,Efrat Levkovizh,Ethan Kim,E. Natan,F. Toni,Gérard Dupont,Germán Kruszewski,Giada Pistilli,Hady ElSahar,Hamza Benyamina,Hieu Tran,Ian Yu,Idris Abdulmumin,Isaac Johnson,Itziar Gonzalez-Dios,Javier de la Rosa,Jenny Chim,Jesse Dodge,Jian Zhu,Jonathan Chang,Jorg Frohberg,Josephine L. Tobing,J. Bhattacharjee,Khalid Almubarak,Kimbo Chen,Kyle Lo,Leandro von Werra,Leon Weber,Long Phan,Loubna Ben Allal,Ludovic Tanguy,Manan Dey,M. Muñoz,Maraim Masoud,Mar'ia Grandury,Mario vSavsko,Max Huang,Maximin Coavoux,Mayank Singh,Mike Tian-Jian Jiang,Minh Chien Vu,M. A. Jauhar,Mustafa Ghaleb,Nishant Subramani,Nora Kassner,Nurulaqilla Khamis,Olivier Nguyen,Omar Espejel,Ona de Gibert,Paulo Villegas,Peter Henderson,Pierre Colombo,Priscilla Amuok,Quentin Lhoest,Rheza Harliman,Rishi Bommasani,R. L'opez,Rui Ribeiro,Salomey Osei,Sampo Pyysalo,Sebastian Nagel,Shamik Bose,Shamsuddeen Hassan Muhammad,Shanya Sharma,S. Longpre,Somaieh Nikpoor,Stanislav Silberberg,S. Pai,S. Zink,Tiago Timponi Torrent,Timo Schick,Tristan Thrush,V. Danchev,Vassilina Nikoulina,Veronika Laippala,Violette Lepercq,V. Prabhu,Zaid Alyafeai,Zeerak Talat,Arun Raja,Benjamin Heinzerling,Chenglei Si,Elizabeth Salesky,Sabrina J. Mielke,Wilson Y. Lee,Abheesht Sharma,Andrea Santilli,Antoine Chaffin,Arnaud Stiegler,Debajyoti Datta,Eliza Szczechla,Gunjan Chhablani,Han Wang,Harshit Pandey,Hendrik Strobelt,Jason Alan Fries,Jos Rozen,Leo Gao,Lintang Sutawika,M Saiful Bari,Maged S. Al-shaibani,Matteo Manica,Nihal V. Nayak,Ryan Teehan,Samuel Albanie,Sheng Shen,Srulik Ben-David,Stephen H. Bach,Taewoon Kim,T. Bers,Thibault Févry,Trishala Neeraj,Urmish Thakker,Vikas Raunak,Xiang Tang,Zheng Xin Yong,Zhiqing Sun,Shaked Brody,Y. Uri,Hadar Tojarieh,Adam Roberts,Hyung Won Chung,Jaesung Tae,Jason Phang,Ofir Press,Conglong Li,D. Narayanan,Hatim Bourfoune,J. Casper,Jeff Rasley,Max Ryabinin,Mayank Mishra,Minjia Zhang,M. Shoeybi,Myriam Peyrounette,N. Patry,Nouamane Tazi,Omar Sanseviero,Patrick von Platen,Pierre Cornette,Pierre Franccois Lavall'ee,R. Lacroix,Samyam Rajbhandari,Sanchit Gandhi,Shaden Smith,S. Requena,Suraj Patil,Tim Dettmers,Ahmed Baruwa,Amanpreet Singh,Anastasia Cheveleva,Anne-Laure Ligozat,Arjun Subramonian,Aur'elie N'ev'eol,Charles Lovering,Daniel H Garrette,D. Tunuguntla,Ehud Reiter,Ekaterina Taktasheva,E. Voloshina,Eli Bogdanov,Genta Indra Winata,Hailey Schoelkopf,Jan-Christoph Kalo,Jekaterina Novikova,J. Forde,Jordan Clive,Jungo Kasai,Ken Kawamura,Liam Hazan,Marine Carpuat,Miruna Clinciu,Najoung Kim,Newton Cheng,Oleg Serikov,Omer Antverg,Oskar van der Wal,Rui Zhang,Ruochen Zhang,Sebastian Gehrmann,S. Pais,Tatiana Shavrina,Thomas Scialom,Tian Yun,Tomasz Limisiewicz,Verena Rieser,Vitaly Protasov,V. Mikhailov,Yada Pruksachatkun,Yonatan Belinkov,Zachary Bamberger,Zdenvek Kasner,Alice Rueda,Amanda Pestana,A. Feizpour,Ammar Khan,Amy Faranak,A. Santos,A. Hevia,Antigona Unldreaj,Arash Aghagol,Arezoo Abdollahi,A. Tammour,Azadeh HajiHosseini,Bahareh Behroozi,B. Ajibade,B. Saxena,Carlos Muñoz Ferrandis,Danish Contractor,D. Lansky,Davis David,Douwe Kiela,D. A. Nguyen,Edward Tan,Emily Baylor,Ezinwanne Ozoani,Fatim T Mirza,Frankline Ononiwu,Habib Rezanejad,H.A. Jones,Indrani Bhattacharya,Irene Solaiman,Irina Sedenko,I. Nejadgholi,J. Passmore,Joshua Seltzer,Julio Bonis Sanz,Karen Fort,L. Dutra,Mairon Samagaio,Maraim Elbadri,M. Mieskes,Marissa Gerchick,Martha Akinlolu,Michael McKenna,Mike Qiu,M. Ghauri,Mykola Burynok,Nafis Abrar,Nazneen Rajani,Nour Elkott,N. Fahmy,O. Samuel,Ran An,R. Kromann,Ryan Hao,S. Alizadeh,Sarmad Shubber,Silas L. Wang,Sourav Roy,S. Viguier,Thanh-Cong Le,Tobi Oyebade,T. Le,Yoyo Yang,Z. Nguyen,Abhinav Ramesh Kashyap,Alfredo Palasciano,A. Callahan,Anima Shukla,Antonio Miranda-Escalada,A. Singh,Benjamin Beilharz,Bo Wang,C. Brito,Chenxi Zhou,Chirag Jain,Chuxin Xu,Clémentine Fourrier,Daniel Le'on Perin'an,Daniel Molano,Dian Yu,Enrique Manjavacas,Fabio Barth,Florian Fuhrimann,Gabriel Altay,Giyaseddin Bayrak,Gully A. Burns,Helena U. Vrabec,I. Bello,Isha Dash,J. Kang,John Giorgi,J. Golde,J. Posada,Karthi Sivaraman,Lokesh Bulchandani,Lu Liu,Luisa Shinzato,Madeleine Hahn de Bykhovetz,Maiko Takeuchi,Marc Pàmies,M. A. Castillo,Marianna Nezhurina,Mario Sanger,M. Samwald,Michael Cullan,Michael Weinberg,M. Wolf,Mina Mihaljcic,Minna Liu,M. Freidank,Myungsun Kang,Natasha Seelam,N. Dahlberg,N. Broad,N. Muellner,Pascale Fung,Patricia Haller,R. Chandrasekhar,R. Eisenberg,Robert Martin,Rodrigo L. Canalli,Rosaline Su,Ruisi Su,Samuel Cahyawijaya,Samuele Garda,Shlok S Deshmukh,Shubhanshu Mishra,Sid Kiblawi,Simon Ott,Sinee Sang-aroonsiri,Srishti Kumar,Stefan Schweter,S. Bharati,T. A. Laud,Th'eo Gigant,Tomoya Kainuma,Wojciech Kusa,Yanis Labrak,Yashasvi Bajaj,Y. Venkatraman,Yifan Xu,Ying Xu,Yun-chao Xu,Z. Tan,Zhongli Xie,Zifan Ye,M. Bras,Younes Belkada,Thomas Wolf",53,157,9,"https://www.semanticscholar.org/paper/327f1561b544b0a3b9d8d5d0e6d82c2a5911fca9"
"a4bdc300db297756f36bedee2859b62df8e268c2",3,"Follow the Wisdom of the Crowd: Effective Text Generation via Minimum Bayes Risk Decoding","This work presents crowd sampling, a family of decoding methods based on Bayesian risk minimization, to ad-dress this diversity-quality trade-off in open-ended natural-language generation.","ArXiv",2022,"Mirac Suzgun,Luke Melas-Kyriazi,Dan Jurafsky",3,83,0,"https://www.semanticscholar.org/paper/a4bdc300db297756f36bedee2859b62df8e268c2"
"20b60fb3993d2e9a5af04611f7bdf248e5a3a736",3,"Programming by Example and Text-to-Code Translation for Conversational Code Generation","Modular Programs for Text-guided Hierarchical Synthesis (MPaTHS), a method for integrating Programming by Example and text-to-code systems which uses an accessible natural language interface for synthesizing general programs, is proposed.","ArXiv",2022,"Eli Whitehouse,William Gerard,Yauhen Klimovich,Marc Franco-Salvador",0,21,0,"https://www.semanticscholar.org/paper/20b60fb3993d2e9a5af04611f7bdf248e5a3a736"
"30624a18720bf93a85dc3efe570df271a8c9f4c3",3,"Program Repair","Keeping intermediate rules, instead of producing the most generalized rule by generalizing all concrete transformations, enables us to apply the most suitable rule to transform a given code.","ArXiv",2022,"Xiang Gao,Yannic Noller,Abhik Roychoudhury",2,105,0,"https://www.semanticscholar.org/paper/30624a18720bf93a85dc3efe570df271a8c9f4c3"
"dca3bc28a7d404b28780a813ea7072eda809e6c0",3,"Programming Is Hard - Or at Least It Used to Be: Educational Opportunities And Challenges of AI Code Generation","It is argued that the community needs to act quickly in deciding what possible opportunities can and should be leveraged and how, while also working on how to overcome or otherwise mitigate the possible challenges.","ArXiv",2022,"Brett A. Becker,Paul Denny,James Finnie-Ansley,Andrew Luxton-Reilly,J. Prather,E. Santos",0,49,0,"https://www.semanticscholar.org/paper/dca3bc28a7d404b28780a813ea7072eda809e6c0"
"42630c03d3817b1153d245f20742ad4b30a80b75",3,"JEMMA: An Extensible Java Dataset for ML4Code Applications","JEMMA is introduced, which is a largescale, diverse, and high-quality dataset targeted at ML4Code applications, and becomes a workbench that researchers can use to experiment with novel representations and tasks operating on source code.","ArXiv",2022,"Anjan Karmakar,Miltiadis Allamanis,R. Robbes",0,93,0,"https://www.semanticscholar.org/paper/42630c03d3817b1153d245f20742ad4b30a80b75"
"bf5fbd690f24f873df86d1b0a06579cf42f7dc36",3,"Dialog2API: Task-Oriented Dialogue with API Description and Example Programs","An approach tailored for the Dialog2API, where the dialogue states are represented by a stack of programs, with most recently mentioned program on the top of the stack, is proposed.","ArXiv",2022,"Raphael Shu,Elman Mansimov,Tamer Alkhouli,Nikolaos Pappas,Salvatore Romeo,Arshit Gupta,Saab Mansour,Yi Zhang,D. Roth",0,32,0,"https://www.semanticscholar.org/paper/bf5fbd690f24f873df86d1b0a06579cf42f7dc36"
"c532f1df90925e5c69789f0cd99248d8a2a2e5bc",3,"My AI Wants to Know if This Will Be on the Exam: Testing OpenAI’s Codex on CS2 Programming Exercises","This paper presents results detailing how Codex performs on more advanced CS2 exam questions taken from past exams, and compares these results to those of students who took the same exams under normal conditions, demonstrating that Codex outscores most students.","IFAC Symposium on Advances in Control Education",2023,"James Finnie-Ansley,Paul Denny,Andrew Luxton-Reilly,E. Santos,J. Prather,Brett A. Becker",1,27,0,"https://www.semanticscholar.org/paper/c532f1df90925e5c69789f0cd99248d8a2a2e5bc"
"63396fceb84286b02796dc58e55c07ec1095c4dc",3,"FLAME: A small language model for spreadsheet formulas","This work presents FLAME, a T5-based model trained on Excel formulas that leverages domain insights to achieve competitive performance with a substantially smaller model (60M parameters) and two orders of magnitude less training data.","ArXiv",2023,"Harshit Joshi,Abishai Ebenezer,J. Cambronero,Sumit Gulwani,Aditya Kanade,Vu Le,Ivan Radivcek,Gust Verbruggen",0,46,0,"https://www.semanticscholar.org/paper/63396fceb84286b02796dc58e55c07ec1095c4dc"
"782f3d43b37790a83c98d5fd3ef142b296f20616",3,"CrossCodeBench: Benchmarking Cross-Task Generalization of Source Code Models","A large-scale benchmark that includes 216 existing code-related tasks is proposed and it is demonstrated that the cross-task generalization of models can be largely improved by in-context learning methods such as few-shot learning and learning from task instructions, which shows the promising prospects of conducting cross- task learning research on this benchmark.","ArXiv",2023,"Changan Niu,Chuanyi Li,Vincent Ng,Bin Luo",0,76,0,"https://www.semanticscholar.org/paper/782f3d43b37790a83c98d5fd3ef142b296f20616"
"b0335eb2b9a1684fc16ff79234f0b206b30da169",2,"A Study of Editor Features in a Creative Coding Classroom","An experimental editor is implemented and used to teach a sequence of college and high-school creative coding courses to identify opportunities to improve creativity- and novice-focused IDEs and highlight ten-sions in their design.","ArXiv",2023,"Andrew M. McNutt,Anton Outkine,Ravi Chugh",0,107,0,"https://www.semanticscholar.org/paper/b0335eb2b9a1684fc16ff79234f0b206b30da169"
"0bc2753f59e653de718b5c7a2a0a7e00d13778c7",2,"NL2CMD: An Updated Workflow for Natural Language to Bash Commands Translation","A state-of-the-art translation model used to generate Bash Commands from the corresponding English text is described and a new NL2CMD dataset is introduced that is automatically generated, involves minimal human intervention, and is over six times larger than prior datasets.","",2022,"Quchen Fu,Zhongwei Teng,Marco Georgaklis,Jules White,Douglas,C. Schmidt",0,77,0,"https://www.semanticscholar.org/paper/0bc2753f59e653de718b5c7a2a0a7e00d13778c7"
"d388b3cbc820975da21c57c9fb9cef2d9c6d08f0",2,"CodeRetriever: Large-scale Contrastive Pre-training for Code Search","","",2022,"Xiaonan Li,Yeyun Gong,Yelong Shen,Xipeng Qiu,Hang Zhang,Bolun Yao,Weizhen Qi,Daxin Jiang,Weizhu Chen,Nan Duan",0,43,0,"https://www.semanticscholar.org/paper/d388b3cbc820975da21c57c9fb9cef2d9c6d08f0"
"22df866f9605d27d1e5cca9b3ab721f33673e158",2,"ProgramTransformer: A tool for generating semantically equivalent transformed programs","","Softw. Impacts",2022,"Md Rafiqul Islam Rabin,Mohammad Amin Alipour",0,26,0,"https://www.semanticscholar.org/paper/22df866f9605d27d1e5cca9b3ab721f33673e158"
"862c0b672c9defded3111924310a07760cfa27ff",2,"Can NMT Understand Me? Towards Perturbation-based Evaluation of NMT Models for Code Generation","This work identifies a set of perturbations and metrics tailored for the robustness assessment of NMT models, and presents a preliminary experimental evaluation, showing what type of perturbedations affect the model the most and deriving useful insights for future directions.","2022 IEEE/ACM 1st International Workshop on Natural Language-Based Software Engineering (NLBSE)",2022,"Pietro Liguori,Cristina Improta,S. D. Vivo,R. Natella,B. Cukic,Domenico Cotroneo",1,58,0,"https://www.semanticscholar.org/paper/862c0b672c9defded3111924310a07760cfa27ff"
"24c5450d8fa785e5f85d9427d2d65cf66476ac3a",2,"Toward General Design Principles for Generative AI Applications","","ArXiv",2023,"Justin D. Weisz,Michael J. Muller,Jessica He,Stephanie Houde",0,115,0,"https://www.semanticscholar.org/paper/24c5450d8fa785e5f85d9427d2d65cf66476ac3a"
"2ad6b59ff14d6bec3f14d8b6480025bbebc50e46",2,"Optimal Neural Program Synthesis from Multimodal Specifications","The experimental results on a multimodal synthesis dataset show that the proposed optimal neural synthesis approach substantially outperforms prior state-of-the-art techniques in terms of accuracy %, finds model-optimal programs more frequently, and explores fewer states during search.","Conference on Empirical Methods in Natural Language Processing",2020,"Xi Ye,Qiaochu Chen,Işil Dillig,Greg Durrett",8,48,0,"https://www.semanticscholar.org/paper/2ad6b59ff14d6bec3f14d8b6480025bbebc50e46"
"6df98ac2300c6e9c232440147ba976b4f501ca67",2,"C ODEX HACKS H ACKER R ANK : B ENEFITS AND R ISKS OF L ARGE -S CALE S OURCE C ODE M ODELS","These studies evaluate Codex on code synthesis, similar to the approach, but their evaluation efforts remain limited to math problems.","",2022,"",0,56,0,"https://www.semanticscholar.org/paper/6df98ac2300c6e9c232440147ba976b4f501ca67"
"8bfc22de7fe66286ad9ae705d677246757fbf8a8",2,"Large Language Models Can Be Easily Distracted by Irrelevant Context","This work investigates the distractibility of large language models, i.e., how the model problem-solving accuracy can be influenced by irrelevant context, and introduces Grade-School Math with Irrelevant Context (GSM-IC), an arithmetic reasoning dataset with irrelevant information in the problem description.","ArXiv",2023,"Freda Shi,Xinyun Chen,Kanishka Misra,Nathan Scales,David Dohan,E. Chi,Nathanael Scharli,Denny Zhou",1,57,0,"https://www.semanticscholar.org/paper/8bfc22de7fe66286ad9ae705d677246757fbf8a8"
"cc80244d69c2c5bb7fe79fc6ca2561f2bed830ca",2,"Learning to Represent Programs with Heterogeneous Graphs","This paper proposes the heterogeneous program graph (HPG), which provides the types of the nodes and the edges explicitly, and employs the heterogeneity transformer (HGT) architecture to generate representations based on HPG, considering the type of information during processing.","IEEE International Conference on Program Comprehension",2020,"Wenhan Wang,Kechi Zhang,Ge Li,Zhi Jin",15,70,3,"https://www.semanticscholar.org/paper/cc80244d69c2c5bb7fe79fc6ca2561f2bed830ca"
"c125b0be73c8493ebc27beb572f6c1b21d6b4ae4",2,"Static Prediction of Runtime Errors by Learning to Execute Programs with External Resource Descriptions","Surprisingly, it is shown that the model can also predict the location of the error, despite being trained only on labels indicating the presence/absence and kind of error.","ArXiv",2022,"David Bieber,Rishab Goel,Daniel Zheng,H. Larochelle,Daniel Tarlow",2,36,0,"https://www.semanticscholar.org/paper/c125b0be73c8493ebc27beb572f6c1b21d6b4ae4"
"703f79763d534dbf9674132cec890f432dcc19ec",2,"A Survey of Deep Learning Models for Structural Code Understanding","This survey presents a comprehensive overview of the structures formed from code data, categorizing the models for understanding code in recent years into two groups: sequence-based and graph-based models, and makes some suggestions for future research in structural code understanding field.","ArXiv",2022,"Ruoting Wu,Yu-xin Zhang,Qibiao Peng,Liang Chen,Zibin Zheng",1,180,0,"https://www.semanticscholar.org/paper/703f79763d534dbf9674132cec890f432dcc19ec"
"713bd2971116098211ef06336dfbe91a69854404",2,"Probing Semantic Grounding in Language Models of Code with Representational Similarity Analysis","This paper probes representations from the CodeBERT model for semantic grounding by using the data from the IBM CodeNet dataset, and shows that using bimodalinputs over unimodal inputs gives better semantic grounding and sample eﬃciency during semantic ﬁne-tuning.","International Conference on Advanced Data Mining and Applications",2022,"Shounak Naik,Rajaswa Patil,Swati Agarwal,V. Baths",0,18,0,"https://www.semanticscholar.org/paper/713bd2971116098211ef06336dfbe91a69854404"
"27e3ca4fd7b8290a0e12ca4fd2b7ad5bcd5900f2",2,"Are Transformers All That Karel Needs?","By changing the base architecture to a transformer based one, speciﬁcally GPT2, this work is able to apply simple execution guidance on top to achieve a generalization accurary of 89.64%, which is within 2.36 percentage points of the current state-of-the-art on Karel which uses ensembling.","",2021,"Abhay Garg,Anand Sriraman,Kunal Pagarey,S. Karande",0,37,0,"https://www.semanticscholar.org/paper/27e3ca4fd7b8290a0e12ca4fd2b7ad5bcd5900f2"
"27d16a7f2ce8f2b787b34ff1f9b4fece079700c3",2,"Figuring out Figures: Using Textual References to Caption Scientific Figures","This work uses the S CI C AP datasets curated by Hsu et al. and uses a variant of a CLIP+GPT-2 encoder-decoder model with cross-attention to generate captions conditioned on the image, and uses SciBERT to encode the textual metadata and uses this encoding alongside the figure embedding.","",2022,"Stanley Cao,Kevin Liu",0,25,0,"https://www.semanticscholar.org/paper/27d16a7f2ce8f2b787b34ff1f9b4fece079700c3"
"317208b423d24d52ba04221cfb46956962364e22",2,"Extracting Meaningful Attention on Source Code: An Empirical Study of Developer and Neural Model Code Exploration","This work empirically evaluates attention-agnostic heuris-tics and ten attention-based post processing approaches of the attention signal against the ground truth of developers exploring code, including the novel concept of follow-up attention which exhibits the highest agreement.","ArXiv",2022,"Matteo Paltenghi,Rahul Pandita,Austin Z. Henley,Albert Ziegler",0,42,0,"https://www.semanticscholar.org/paper/317208b423d24d52ba04221cfb46956962364e22"
"e5993b3afe6384b5e6f90093989773ad1f868f71",2,"Towards Top-Down Deep Code Generation in Limited Scopes","A semantic pyramid framework (SPF) is proposed as the approach, focusing on softwares of high modularity and low complexity, and introduces a three-layer semantic pyramid (SP) to associate text data and code data.","ArXiv",2022,"Jian Gu,H. Gall",0,38,0,"https://www.semanticscholar.org/paper/e5993b3afe6384b5e6f90093989773ad1f868f71"
"bab6893ee48d168d27c227c3b0867f6d471fbea8",2,"Language Models are not Models of Language","It is argued that the term language model is misleading because deep learning models are not theoretical models of language and proposed the adoption of corpus model instead, which better reflects the genesis and contents of the model.","ArXiv",2021,"C. Veres",0,58,0,"https://www.semanticscholar.org/paper/bab6893ee48d168d27c227c3b0867f6d471fbea8"
"57d1e7ac339e783898f2c3b1af55737cbeee9fc5",2,"Measuring Mathematical Problem Solving With the MATH Dataset","This work introduces MATH, a new dataset of 12, 500 challenging competition mathematics problems which can be used to teach models to generate answer derivations and explanations, and shows that accuracy remains relatively low, even with enormous Transformer models.","NeurIPS Datasets and Benchmarks",2021,"Dan Hendrycks,Collin Burns,Saurav Kadavath,Akul Arora,Steven Basart,Eric Tang,D. Song,J. Steinhardt",91,65,20,"https://www.semanticscholar.org/paper/57d1e7ac339e783898f2c3b1af55737cbeee9fc5"
"98485ce6532d69f34a8ec67de6b09a39532bd221",2,"Communicating Natural Programs to Humans and Machines","LARC, the Language-complete ARC is presented, a collection of natural language descriptions by a group of human participants who instruct each other on how to solve ARC tasks using language alone, which contains successful instructions for 88% of the ARC tasks.","ArXiv",2021,"Samuel Acquaviva,Yewen Pu,Marta Kryven,Catherine Wong,Gabrielle Ecanow,Maxwell Nye,Theo Sechopoulos,Michael Henry Tessler,J. Tenenbaum",8,87,0,"https://www.semanticscholar.org/paper/98485ce6532d69f34a8ec67de6b09a39532bd221"
"58a6ca2ae28a618126f71a07262cb958a8c37904",2,"Latent Execution for Neural Program Synthesis","LaSynth learns the latent representation to approximate the execution of partially generated programs, even if they are incomplete in syntax, and significantly improves the performance of next token prediction over existing approaches, facilitating search.","",2021,"Xinyun Chen,D. Song,Yuandong Tian",2,60,0,"https://www.semanticscholar.org/paper/58a6ca2ae28a618126f71a07262cb958a8c37904"
"5436193122dff271796bca07df7cecb7a8d6dea6",2,"Natural language-guided programming","The key idea is to adapt code autocompletion tools such that they take into account not only the developer’s already-written code but also the intent of the task the developer is trying to achieve next, formulated in plain natural language.","SIGPLAN symposium on New ideas, new paradigms, and reflections on programming and software",2021,"Geert Heyman,Rafael Huysegems,P. Justen,Tom Van Cutsem",6,53,1,"https://www.semanticscholar.org/paper/5436193122dff271796bca07df7cecb7a8d6dea6"
"4885e616e85d420576196b2578525cbc501137ec",2,"Programming and execution models for next generation code intelligence systems (keynote)","","ESEC/SIGSOFT FSE",2021,"M. Mezini",0,22,0,"https://www.semanticscholar.org/paper/4885e616e85d420576196b2578525cbc501137ec"
"3f97c2067cde9377e50b3160bbd7982c94abd88a",2,"An Empirical Cybersecurity Evaluation of GitHub Copilot's Code Contributions","This work systematically investigates the prevalence and conditions that can cause GitHub Copilot to recommend insecure code, and explores Copilot’s performance on three distinct code generation axes—examining how it performs given diversity of weaknesses, diversity of prompts, and diversity of domains.","ArXiv",2021,"H. Pearce,Baleegh Ahmad,Benjamin Tan,Brendan Dolan-Gavitt,R. Karri",21,29,1,"https://www.semanticscholar.org/paper/3f97c2067cde9377e50b3160bbd7982c94abd88a"
"a176b0de62840f7118006277d94bbc1547162a4d",2,"Learning to Synthesize Programs as Interpretable and Generalizable Policies","Experimental results demonstrate that the proposed framework not only learns to reliably synthesize task-solving programs but also outperforms DRL and program synthesis baselines while producing interpretable and more generalizable policies.","Neural Information Processing Systems",2021,"Dweep Trivedi,Jesse Zhang,Shao-Hua Sun,Joseph J. Lim",15,131,2,"https://www.semanticscholar.org/paper/a176b0de62840f7118006277d94bbc1547162a4d"
"a8863de15a5ee8eed98107f423138a1a8f5a2ba8",2,"Multi-modal program inference: a marriage of pre-trained language models and component-based synthesis","This work presents an approach that combines PTMs with component-based synthesis (CBS): PTMs are used to generate candidates programs from the natural language description of the task, which are then used to guide the CBS procedure to find the program that matches the precise examples-based specification.","Proc. ACM Program. Lang.",2021,"Kia Rahmani,Mohammad Raza,Sumit Gulwani,Vu Le,Daniel Morris,Arjun Radhakrishna,Gustavo Soares,A. Tiwari",17,77,0,"https://www.semanticscholar.org/paper/a8863de15a5ee8eed98107f423138a1a8f5a2ba8"
"bc9598dc4ed0472d8b59b87ed3a139f8347d40ee",2,"Towards A Measure Of General Machine Intelligence","A common language of instruction is proposed, a programming language that allows the expression of programs in the form of directed acyclic graphs across a wide variety of real-world domains and computing platforms and evaluates the suitability of some well-known models as general intelligence systems by calculating their g-index scores.","ArXiv",2021,"Gautham Venkatasubramanian,Sibesh Kar,Abhimanyu Singh,Shubham Mishra,Dushyant Yadav,Shreyansh Chandak",0,71,0,"https://www.semanticscholar.org/paper/bc9598dc4ed0472d8b59b87ed3a139f8347d40ee"
"05c2e1ee203be217f100d2da05bdcc52004f00b6",2,"Unsolved Problems in ML Safety","This work provides a new roadmap for ML Safety and presents four problems ready for research, namely withstanding hazards, identifying hazards, steering ML systems, and reducing deployment hazards.","ArXiv",2021,"Dan Hendrycks,Nicholas Carlini,J. Schulman,J. Steinhardt",62,217,5,"https://www.semanticscholar.org/paper/05c2e1ee203be217f100d2da05bdcc52004f00b6"
"6c2d43e71e240e354b5790a38da78a291ceffe7c",2,"Learning to Superoptimize Real-world Programs","A framework to learn to superoptimize real-world programs by using neural sequence-to-sequence models, and an approach to implement and outperforms a standard policy gradient learning approach on this dataset.","ArXiv",2021,"Alex Shypula,P. Yin,Jeremy Lacomis,Claire Le Goues,E. Schwartz,Graham Neubig",2,37,0,"https://www.semanticscholar.org/paper/6c2d43e71e240e354b5790a38da78a291ceffe7c"
"dace03e57056d736f9e24937bdf486e894f8e866",2,"Is neural machine translation approach accurate enough for coding assistance?","A transcompiler-based back-translation, a data augmentation method that generates parallel corpora from numerous source code repositories and the resulting BLEU indicates that the proposed model is accurate enough to allow coding assistance in the future.","BCNC@SPLASH",2021,"Yuka Akinobu,Momoka Obara,Teruno Kajiura,Shiho Takano,Miyu Tamura,Mayu Tomioka,Kimio Kuramitsu",2,20,1,"https://www.semanticscholar.org/paper/dace03e57056d736f9e24937bdf486e894f8e866"
"21e8e76386aaaa00e0971af70ce84a8a544e1aa1",2,"Cascaded Fast and Slow Models for Efficient Semantic Code Search","An efficient and accurate semantic code search framework with cascaded fast and slow models, in which a fast transformer encoder model is learned to optimize a scalable index for fast retrieval followed by learning a slow classification-based re-ranking model to improve the performance of the top K results from the fast retrieval.","ArXiv",2021,"Akhilesh Deepak Gotmare,Junnan Li,Shafiq R. Joty,S. Hoi",4,24,0,"https://www.semanticscholar.org/paper/21e8e76386aaaa00e0971af70ce84a8a544e1aa1"
"570a6a5b8ec2827c3f33bb1b1bd027190a0d3e07",2,"Neural Program Generation Modulo Static Analysis","The neurosymbolic method allows a deep generative model to symbolically compute, using calls to a static-analysis tool, long-distance semantic relationships in the code that it has already generated, and learns to generate programs conditioned on them.","Neural Information Processing Systems",2021,"Rohan Mukherjee,Yeming Wen,Dipak Chaudhari,T. Reps,Swarat Chaudhuri,C. Jermaine",11,56,0,"https://www.semanticscholar.org/paper/570a6a5b8ec2827c3f33bb1b1bd027190a0d3e07"
"091fa84bdc07dcb22a34060c3996d8c58d71cd20",2,"Towards Neural Functional Program Evaluation","A new program generation mechanism is introduced that allows control over syntactic sugar for semantically equivalent programs in transformer-based language models for program evaluation of simple functional programming languages.","ArXiv",2021,"Torsten Scholak,Jonathan Pilault,Joey Velez-Ginorio",0,19,0,"https://www.semanticscholar.org/paper/091fa84bdc07dcb22a34060c3996d8c58d71cd20"
"75c8f2916a2067f7549cf58ea8c9061565eb1dab",2,"C ROSS B EAM : L EARNING TO S EARCH IN B OTTOM -U P P ROGRAM S YNTHESIS","This work uses a neural model to learn a hands-on search policy for bottom-up synthesis, instead of relying on a combinatorial search algorithm, and observes that CROSSBEAM learns to search efficiently, exploring much smaller portions of the program space compared to the state-of-the-art.","",2022,"H. Dai,Kevin Ellis,Charles Sutton",0,49,0,"https://www.semanticscholar.org/paper/75c8f2916a2067f7549cf58ea8c9061565eb1dab"
"9bf75110ea0923bbed49256b5491f1ec284019ec",2,"From BERT to GPT-3 Codex: Harnessing the Potential of Very Large Language Models for Data Management","The goal of the tutorial is to introduce database researchers to the latest generation of language models, and to their use cases in the domain of data management.","Proceedings of the VLDB Endowment",2022,"Immanuel Trummer",0,35,0,"https://www.semanticscholar.org/paper/9bf75110ea0923bbed49256b5491f1ec284019ec"
"ddab94478a7647ee136b1f6b5076417db3074d0f",2,"Machine Programming: Turning Data into Programmer Productivity","An introduction to machine programming is introduced introducing its three pillars: intention, invention, and adaptation, and an overview of the data ecosystem central to all machine programming systems is provided, highlighting challenges and novel opportunities relevant to the data systems community.","Proceedings of the VLDB Endowment",2022,"A. Wasay,Nesime Tatbul,Justin Emile Gottschlich",0,39,0,"https://www.semanticscholar.org/paper/ddab94478a7647ee136b1f6b5076417db3074d0f"
"2443179d421e1faf7474add557b45add554723c7",2,"Formal Premise Selection With Language Models","This work provides a solution to the problem of selecting a useful premise to prove a new theorem by combining a premise selection model with a language model, and shows that this retrieval-augmented prover achieves significant improvements in proof rates compared to the language model alone.","",2022,"Szymon Tworkowski,Maciej Miku la,Tomasz Odrzygóźdź,K. Czechowski,Szymon Antoniak,Albert Qiaochu Jiang,Christian Szegedy,Lukasz Kucinski,Piotr Mi loś,Yuhuai Wu",0,34,0,"https://www.semanticscholar.org/paper/2443179d421e1faf7474add557b45add554723c7"
"b98d6fe8f0ef02ec0d1bb2bcfb924c8f01feb7d4",2,"Convergent Representations of Computer Programs in Human and Artificial Neural Networks","Analysis of brain recordings derived from functional magnetic resonance imaging studies of programmers comprehending Python code suggests at least two distinct neural mechanisms mediating computer program comprehension and evaluation, prompting the design of code model objectives that go beyond static language modeling.","",2022,"Shashank Srikant,Benjamin Lipkin,Anna A. Ivanova,Evelina Fedorenko,Una-May O’Reilly",0,79,0,"https://www.semanticscholar.org/paper/b98d6fe8f0ef02ec0d1bb2bcfb924c8f01feb7d4"
"15ef2d1b88f54fa32a32927463a7116219b89529",2,"L EARNING TO S UPEROPTIMIZE R EAL - WORLD P ROGRAMS","","",,"",0,0,0,"https://www.semanticscholar.org/paper/15ef2d1b88f54fa32a32927463a7116219b89529"
"4797e960f8e7a2b47ae0d95c7071ef84fa5d4b5b",2,"Code Generation Using Machine Learning: A Systematic Review","This review provides a broad and detailed overview of studies for code generation using ML, and summarizes the applications, models, datasets, results, limitations, and future work of 37 publications.","IEEE Access",2022,"Enrique Dehaerne,Bappaditya Dey,Sandip Halder,S. De Gendt,Wannes Meert",0,117,0,"https://www.semanticscholar.org/paper/4797e960f8e7a2b47ae0d95c7071ef84fa5d4b5b"
"660ca9e15e19409903a0605f0584d0f263c35c67",2,"S YNCHROMESH : R ELIABLE C ODE G ENERATION FROM P RE - TRAINED L ANGUAGE M ODELS","A framework for substantially improving the reliability of pre-trained models for code generation and observing substantial complementary gains from CSD and TST in prediction accuracy and in effectively preventing run-time errors is proposed.","",2022,"Gabriel Poesia,A. Tiwari,Gustavo Soares,Christopher Meek",0,29,0,"https://www.semanticscholar.org/paper/660ca9e15e19409903a0605f0584d0f263c35c67"
"ba5d21b7c65c6598c7bd39a5d992308c205df374",2,"A S YSTEMATIC E VALUATION OF L ARGE L ANGUAGE M ODELS OF C ODE","It is found that existing open-source models do achieve close results in some programming languages, although targeted mainly for natural language modeling, and a new model, PolyCoder, is released that was trained on 249GB of code across 12 programming languages on a single machine.","",2022,"Graham Neubig,V. Hellendoorn",0,33,0,"https://www.semanticscholar.org/paper/ba5d21b7c65c6598c7bd39a5d992308c205df374"
"6e5eb6167d9766fbb4d14611d15cf95d7b75fb9d",2,"Asleep at the Keyboard? Assessing the Security of GitHub Copilot’s Code Contributions","This work systematically investigates the prevalence and conditions that can cause GitHub Copilot to recommend insecure code, and explores Copilot’s performance on three distinct code generation axes—examining how it performs given diversity of weaknesses, diversity of prompts, and diversity of domains.","IEEE Symposium on Security and Privacy",2021,"H. Pearce,Baleegh Ahmad,Benjamin Tan,Brendan Dolan-Gavitt,R. Karri",34,35,6,"https://www.semanticscholar.org/paper/6e5eb6167d9766fbb4d14611d15cf95d7b75fb9d"
"ff0b2681d7b05e16c46dfb71d980cc2f605907cd",2,"Finetuned Language Models Are Zero-Shot Learners","It is shown that instruction tuning —ﬁnetuning language models on a collection of datasets described via instructions—substantially improves zero-shot performance on unseen tasks and outperforms few-shot GPT-3 by a large margin on ANLI, RTE, BoolQ, AI2-ARC, OpenbookQA, and StoryCloze.","International Conference on Learning Representations",2021,"Jason Wei,Maarten Bosma,Vincent Zhao,Kelvin Guu,A. Yu,Brian Lester,Nan Du,Andrew M. Dai,Quoc V. Le",349,167,82,"https://www.semanticscholar.org/paper/ff0b2681d7b05e16c46dfb71d980cc2f605907cd"
"6e8f8e2d2c73c91d1c9198eb802f1c64b860ea4a",2,"Few-Shot Semantic Parsing with Language Models Trained on Code","This paper evaluates OpenAI Codex on Overnight and SMCalFlow and finds that unlike GPT-3, Codex performs similarly when targeting meaning representations directly, perhaps because meaning representations are structured similar to code in these datasets.","North American Chapter of the Association for Computational Linguistics",2021,"Richard Shin,Benjamin Van Durme",19,18,3,"https://www.semanticscholar.org/paper/6e8f8e2d2c73c91d1c9198eb802f1c64b860ea4a"
"53c0abe83fe9b4fdaf2208295d8504fcf5241694",2,"UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding with Text-to-Text Language Models","The UnifiedSKG framework is proposed, which unifies 21 SKG tasks into a text-to-text format, aiming to promote systematic SKG research, instead of being exclusive to a single task, domain, or dataset.","Conference on Empirical Methods in Natural Language Processing",2022,"Tianbao Xie,Chen Henry Wu,Peng Shi,Ruiqi Zhong,Torsten Scholak,Michihiro Yasunaga,Chien-Sheng Wu,Ming Zhong,Pengcheng Yin,Sida I. Wang,Victor Zhong,Bailin Wang,Chengzu Li,Connor Boyle,Ansong Ni,Ziyu Yao,Dragomir R. Radev,Caiming Xiong,Lingpeng Kong,Rui Zhang,Noah A. Smith,Luke Zettlemoyer,Tao Yu",90,118,12,"https://www.semanticscholar.org/paper/53c0abe83fe9b4fdaf2208295d8504fcf5241694"
"92a8f7f09f3705cb5a6009a42220a6f01ea084e8",2,"Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents","This paper investigates the possibility of grounding high-level tasks, expressed in natural language, to a chosen set of actionable steps and proposes a procedure that conditions on existing demonstrations and semantically translates the plans to admissible actions.","International Conference on Machine Learning",2022,"Wenlong Huang,P. Abbeel,Deepak Pathak,Igor Mordatch",92,55,13,"https://www.semanticscholar.org/paper/92a8f7f09f3705cb5a6009a42220a6f01ea084e8"
"b62d63580b81a2cbb20c3c1593dd62d118e4cb07",2,"Synchromesh: Reliable code generation from pre-trained language models","A framework for substantially improving the reliability of pre-trained models for code generation and observing substantial complementary gains from CSD and TST in prediction accuracy and in effectively preventing run-time errors is proposed.","International Conference on Learning Representations",2022,"Gabriel Poesia,Oleksandr Polozov,Vu Le,A. Tiwari,Gustavo Soares,Christopher Meek,Sumit Gulwani",32,31,4,"https://www.semanticscholar.org/paper/b62d63580b81a2cbb20c3c1593dd62d118e4cb07"
"7428f9b16a82839e2cb6e6c7a77c1ffeab898813",2,"HEAT: Hyperedge Attention Networks","This work presents HEAT, a neural model capable of representing typed and qualified hypergraphs, where each hyperedge explicitly qualifies how participating nodes con-tribute is treated, which can be viewed as a generalization of both message passing neural networks and Transformers.","ArXiv",2022,"Dobrik Georgiev,Marc Brockschmidt,Miltiadis Allamanis",3,39,0,"https://www.semanticscholar.org/paper/7428f9b16a82839e2cb6e6c7a77c1ffeab898813"
"1b6e810ce0afd0dd093f789d2b2742d047e316d5",2,"Chain of Thought Prompting Elicits Reasoning in Large Language Models","Experiments on three large language models show that chain-of-thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks.","ArXiv",2022,"Jason Wei,Xuezhi Wang,Dale Schuurmans,Maarten Bosma,E. Chi,Quoc Le,Denny Zhou",338,103,92,"https://www.semanticscholar.org/paper/1b6e810ce0afd0dd093f789d2b2742d047e316d5"
"763792c655e591c5d61f67d7ac9cbecbcb5f4508",2,"Pop Quiz! Can a Large Language Model Help With Reverse Engineering?","An extensive quantitative analysis of the measured performance of the language model on a set of program purpose identification and information extraction tasks shows that LLMs are not yet ready for zero-shot reverse engineering.","ArXiv",2022,"H. Pearce,B. Tan,P. Krishnamurthy,F. Khorrami,R. Karri,Brendan Dolan-Gavitt",4,27,0,"https://www.semanticscholar.org/paper/763792c655e591c5d61f67d7ac9cbecbcb5f4508"
"9ac5e1ffa8f837671a89354d4e298b1adeb08d79",2,"Enabling Automatic Repair of Source Code Vulnerabilities Using Data-Driven Methods","This work proposes ways to improve code representations for vulnerability repair from three perspectives: input data type, data-driven models, and downstream tasks.","2022 IEEE/ACM 44th International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)",2022,"Anastasiia Grishina",0,39,0,"https://www.semanticscholar.org/paper/9ac5e1ffa8f837671a89354d4e298b1adeb08d79"
"9cbc044e315cdefe9a255119037ac7c23e9abdd5",2,"Predictability and Surprise in Large Generative Models","This paper highlights a counterintuitive property of large-scale generative models, which have a paradoxical combination of predictable loss on a broad training distribution, and unpredictable specific capabilities, inputs, and outputs, and analyzed how these conflicting properties combine to give model developers various motivations for deploying these models, and challenges that can hinder deployment.","Conference on Fairness, Accountability and Transparency",2022,"Deep Ganguli,Danny Hernandez,Liane Lovitt,Nova DasSarma,T. Henighan,Andy Jones,Nicholas Joseph,John Kernion,Benjamin Mann,Amanda Askell,Yuntao Bai,Anna Chen,Tom Conerly,Dawn Drain,Nelson Elhage,Sheer El Showk,Stanislav Fort,Zac Hatfield-Dodds,Scott Johnston,S. Kravec,Neel Nanda,Kamal Ndousse,Catherine Olsson,Daniela Amodei,Dario Amodei,Tom B. Brown,Jared Kaplan,Sam McCandlish,C. Olah,Jack Clark",27,92,2,"https://www.semanticscholar.org/paper/9cbc044e315cdefe9a255119037ac7c23e9abdd5"
"76f023c3a819fc58989a064a1b50825b11fce95d",2,"Capturing Failures of Large Language Models via Human Cognitive Biases","The results indicate that experimental methodology from cognitive science can help characterize how machine learning systems behave, and draw inspiration from human cognitive biases as motivation to generate hypotheses for problems that models may have and develop experiments that elicit these problems.","ArXiv",2022,"Erik Jones,J. Steinhardt",7,54,0,"https://www.semanticscholar.org/paper/76f023c3a819fc58989a064a1b50825b11fce95d"
"d26fe2a7a7cc940d8485488e97460b144dc7d69e",2,"From Natural Language to Simulations: Applying GPT-3 Codex to Automate Simulation Modeling of Logistics Systems","This work demonstrated that the framework built on top of the GPT-3 Codex, a Transformer-based language model, could produce functionally valid simulations of queuing and inventory control systems given the verbal description.","SSRN Electronic Journal",2022,"I. Jackson,M. J. Sáenz",1,60,0,"https://www.semanticscholar.org/paper/d26fe2a7a7cc940d8485488e97460b144dc7d69e"
"2b556fcf2ac634f03c1fb0ace5e602e829418e65",2,"ReACC: A Retrieval-Augmented Code Completion Framework","This work proposes a retrieval-augmented code completion framework, leveraging both lexical copying and referring to code with similar semantics by retrieval, and adopts a stage-wise training approach that combines a source code retriever and an auto-regressive language model for programming language.","Annual Meeting of the Association for Computational Linguistics",2022,"Shuai Lu,Nan Duan,Hojae Han,Daya Guo,Seung-won Hwang,Alexey Svyatkovskiy",15,70,2,"https://www.semanticscholar.org/paper/2b556fcf2ac634f03c1fb0ace5e602e829418e65"
"c347093e2dca530ce347526380b0b7aedf03a6b2",2,"CrossBeam: Learning to Search in Bottom-Up Program Synthesis","This work uses a neural model to learn a hands-on search policy for bottom-up synthesis, instead of relying on a combinatorial search algorithm, and observes that CROSSBEAM learns to search efficiently, exploring much smaller portions of the program space compared to the state-of-the-art.","International Conference on Learning Representations",2022,"Kensen Shi,H. Dai,Kevin Ellis,Charles Sutton",5,56,0,"https://www.semanticscholar.org/paper/c347093e2dca530ce347526380b0b7aedf03a6b2"
"fb5c11bbf63884f75d2da615fbf37a3bcfa2bd20",2,"Wordcraft: Story Writing With Large Language Models","This work built Wordcraft, a text editor in which users collaborate with a generative language model to write a story, and shows that large language models enable novel co-writing experiences.","International Conference on Intelligent User Interfaces",2022,"Ann Yuan,Andy Coenen,Emily Reif,Daphne Ippolito",16,41,1,"https://www.semanticscholar.org/paper/fb5c11bbf63884f75d2da615fbf37a3bcfa2bd20"
"237f5ca6fcccef2b77a2212b34fb06a1dbd09b72",2,"Evaluating Prompts Across Multiple Choice Tasks In a Zero-Shot Setting","Collect and standardize prompts from a diverse range of tasks for use with tasks they were not designed for and evaluate these prompts across multiple choice datasets for a quantitative analysis of how certain attributes of a prompt affect performance.","ArXiv",2022,"Gabriel Orlanski",0,47,0,"https://www.semanticscholar.org/paper/237f5ca6fcccef2b77a2212b34fb06a1dbd09b72"
"2ba7104f7b93d77940312664f3467b8f090d6d16",2,"On Distribution Shift in Learning-based Bug Detectors","This work proposes to train a bug detector in two phases, first on a synthetic bug distribution to adapt the model to the bug detection domain, and then on a real bug distributionTo drive the model towards the real distribution, which leverage a multi-task hierarchy, focal loss, and contrastive learning to further boost performance.","International Conference on Machine Learning",2022,"Jingxuan He,Luca Beurer-Kellner,Martin T. Vechev",5,49,1,"https://www.semanticscholar.org/paper/2ba7104f7b93d77940312664f3467b8f090d6d16"
"6050454e0446a3068617f73b0301453f3f67844d",2,"Stylette: Styling the Web with Natural Language","Stylette is a browser extension that enables users to change the style of websites by expressing goals in natural language, and shows that Stylette lowered the learning curve, helping participants perform styling changes 35% faster than those using developer tools.","International Conference on Human Factors in Computing Systems",2022,"Tae Soo Kim,Yoonseo Choi,D. Choi,Juho Kim",1,65,0,"https://www.semanticscholar.org/paper/6050454e0446a3068617f73b0301453f3f67844d"
"4054fc9e8776dc0324cfc215462d606eb75916c0",2,"Expectation vs. Experience: Evaluating the Usability of Code Generation Tools Powered by Large Language Models","It was found that, while Copilot did not necessarily improve the task completion time or success rate, most participants preferred to use Copilot in daily programming tasks, since Copilot often provided a useful starting point and saved the effort of searching online.","CHI Extended Abstracts",2022,"Ganesha Upadhyaya,Anastasia Reinhardt,Hridesh Rajan,Miryung Kim,Elena L. Glassman,B. Hartmann,Joseph Pinedo",38,53,5,"https://www.semanticscholar.org/paper/4054fc9e8776dc0324cfc215462d606eb75916c0"
"4bc040835fbff57ce6612306d794b8c6c8226086",2,"Discovering the Syntax and Strategies of Natural Language Programming with Generative Language Models","A natural language code synthesis tool, GenLine, backed by a large generative language model and a set of task-specific prompts that create or change code is presented, indicating that while naturallanguage code synthesis can sometimes provide a magical experience, participants still faced challenges.","International Conference on Human Factors in Computing Systems",2022,"Ellen Jiang,Edwin Toh,A. Molina,Kristen Olson,Claire Kayacik,Aaron Donsbach,Carrie J. Cai,Michael Terry",11,36,2,"https://www.semanticscholar.org/paper/4bc040835fbff57ce6612306d794b8c6c8226086"
"f8aa0cab09bc0668276e2cb5690bae47fa50d350",2,"An Initial Look at Self-Reprogramming Artificial Intelligence","This paper develops and experimentally validate the first fully self-reprogramming AI system with the ability to continuously modify and rewrite its own neural network source code.","ArXiv",2022,"Alex Sheng",0,14,0,"https://www.semanticscholar.org/paper/f8aa0cab09bc0668276e2cb5690bae47fa50d350"
"1f3a97d255a6d0b2d5535af75737ed43b1e96fc4",2,"Is GitHub Copilot a Substitute for Human Pair-programming? An Empirical Study","The results suggest that although Copilot increases productivity as measured by Lines of code added, the quality of code produced is inferior by having more lines of code deleted in the subsequent trial.","2022 IEEE/ACM 44th International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)",2022,"Saki Imai",10,11,0,"https://www.semanticscholar.org/paper/1f3a97d255a6d0b2d5535af75737ed43b1e96fc4"
"cdfe9580f63070f311151444f9df32818cc858bf",2,"An Empirical Evaluation of GitHub Copilot's Code Suggestions","Overall, Copilot's suggestions have low complexity with no notable differences between the programming languages and some potential Copilot shortcomings are found.","IEEE Working Conference on Mining Software Repositories",2022,"N. Nguyen,Sarah Nadi",22,29,3,"https://www.semanticscholar.org/paper/cdfe9580f63070f311151444f9df32818cc858bf"
"5922f437512158970c417f4413bface021df5f78",2,"A Generalist Agent","","ArXiv",2022,"S. Reed,Konrad Zolna,Emilio Parisotto,Sergio Gomez Colmenarejo,Alexander Novikov,Gabriel Barth-Maron,Mai Gimenez,Yury Sulsky,Jackie Kay,J. T. Springenberg,Tom Eccles,Jake Bruce,Ali Razavi,Ashley D. Edwards,N. Heess,Yutian Chen,R. Hadsell,Oriol Vinyals,Mahyar Bordbar,N. D. Freitas",133,102,19,"https://www.semanticscholar.org/paper/5922f437512158970c417f4413bface021df5f78"
"c61ce808818308566124df2c8725c98d6bd38dc3",2,"A Precis of Language Models are not Models of Language","It is shown that despite their many successes at performing linguistic tasks, Large Neural Language Models are ill suited as comprehensive models of natural language.","ArXiv",2022,"C. Veres",0,16,0,"https://www.semanticscholar.org/paper/c61ce808818308566124df2c8725c98d6bd38dc3"
"58aacb967cc7fc25cfc9d51b7ad3e57ac00d119b",2,"Can Foundation Models Wrangle Your Data?","It is found that large FMs generalize and achieve SoTA performance on data cleaning and integration tasks, even though they are not trained for these data tasks.","Proceedings of the VLDB Endowment",2022,"A. Narayan,Ines Chami,Laurel J. Orr,Christopher R'e",7,91,1,"https://www.semanticscholar.org/paper/58aacb967cc7fc25cfc9d51b7ad3e57ac00d119b"
"636f854b1a3a983e6803eae0277179596cc2cb95",2,"Summarize and Generate to Back-translate: Unsupervised Translation of Programming Languages","This work proposes a method for performing back-translation via code summarization and generation of natural language summaries given code snippets that performs competitively with state-of-the-art methods.","ArXiv",2022,"Wasi Uddin Ahmad,Saikat Chakraborty,Baishakhi Ray,Kai-Wei Chang",1,53,0,"https://www.semanticscholar.org/paper/636f854b1a3a983e6803eae0277179596cc2cb95"
"f1b6b34b4440a77ba86493f7062e8974062508c5",2,"Applying genetic programming to PSB2: the next generation program synthesis benchmark suite","25 new general program synthesis benchmark problems that make up PSB2, a new benchmark suite curated from a variety of sources, including programming katas and college courses are described.","Genetic Programming and Evolvable Machines",2022,"Thomas Helmuth,Peter Kelly",1,62,0,"https://www.semanticscholar.org/paper/f1b6b34b4440a77ba86493f7062e8974062508c5"
"8c7fd98b6bc4f32772e76471afe8babc323f10d3",2,"CitySpec: An Intelligent Assistant System for Requirement Specification in Smart Cities","This work builds CitySpec, the first intelligent assistant system for requirement specification in smart cities, and builds a translation model and enhance it through requirement synthesis and develops a novel online learning framework with validation under uncertainty.","International Conference on Smart Computing",2022,"Zirong Chen,Isaac Li,Haoxiang Zhang,S. Preum,J. Stankovic,Meiyi Ma",2,18,0,"https://www.semanticscholar.org/paper/8c7fd98b6bc4f32772e76471afe8babc323f10d3"
"40edfa97cd02268fccff75eb9c693b11c1a968b2",2,"Formal Specifications from Natural Language","These experiments show that language models maintain their generalization capabilities from pre-trained knowledge of natural language to generalize, e.g., to new variable names or operator descriptions, and achieve competitive performance, and even outperform the state-of-the-art for translating into regular expressions.","ArXiv",2022,"Christopher Hahn,Frederik Schmitt,Julia J. Tillman,Niklas Metzger,Julian Siber,B. Finkbeiner",1,97,0,"https://www.semanticscholar.org/paper/40edfa97cd02268fccff75eb9c693b11c1a968b2"
"a64871352f8ac7f8aa226fda5cce70251a18a4fc",2,"Assessing Project-Level Fine-Tuning of ML4SE Models","It is shown that per-project fine-tuning can greatly improve the models’ quality as they capture the project’s domain and naming conventions.","ArXiv",2022,"Egor Bogomolov,Sergey Zhuravlev,Egor Spirin,T. Bryksin",0,39,0,"https://www.semanticscholar.org/paper/a64871352f8ac7f8aa226fda5cce70251a18a4fc"
"9aed848be4e9e401b0e61a2e5d60dbdafa0c6cc1",2,"A Dataset and Benchmark for Automatically Answering and Generating Machine Learning Final Exams","A student survey comparing the quality, appropriateness, andulty of machine- generated questions with human-written questions shows that across multiple aspects, machine-generated questions are indistinguishable from human-generated Questions and are suitable for ﬁnal exams.","ArXiv",2022,"Sarah Zhang,Reece Shuttleworth,Derek Austin,Yann Hicke,Leonard Tang,Sathwik Karnik,Darnell Granberry,Iddo Drori",2,15,1,"https://www.semanticscholar.org/paper/9aed848be4e9e401b0e61a2e5d60dbdafa0c6cc1"
"52ca0f589fdcde1c45fd6dfb1b72248d4ecaefc0",2,"Code Translation with Compiler Representations","This paper proposes to augment code translation with IRs, speciﬁcally LLVM IR, with results on the C++, Java, Rust, and Go languages, and improves upon the state of the art for unsupervised code translation.","ArXiv",2022,"Marc Szafraniec,Baptiste Rozière,Hugh Leather Francois Charton,Patrick Labatut,Gabriel Synnaeve",2,43,0,"https://www.semanticscholar.org/paper/52ca0f589fdcde1c45fd6dfb1b72248d4ecaefc0"
"53661ff6fdbfb8557c5b19895fad151792c62da7",2,"Few-shot training LLMs for project-specific code-summarization","This paper investigates the use few-shot training with the very large GPT (Generative Pre-trained Transformer) Codex model, and finds evidence suggesting that one can significantly surpass state-of-the-art models for code-summarization, leveraging project-specific training.","International Conference on Automated Software Engineering",2022,"Toufique Ahmed,Prem Devanbu",2,25,0,"https://www.semanticscholar.org/paper/53661ff6fdbfb8557c5b19895fad151792c62da7"
"f843233f76a5dff07bfa93a71a1cf13d8aa6a94a",2,"Exploring Length Generalization in Large Language Models","It is shown that combining pretrained large language models’ in-context learning abilities with scratchpad prompting results in a dramatic improvement in length generalization, and is run to identify common sources of mistakes that highlight opportunities in equipping language models with the ability to generalize to longer problems.","ArXiv",2022,"Cem Anil,Yuhuai Wu,Anders Andreassen,Aitor Lewkowycz,Vedant Misra,V. Ramasesh,Ambrose Slone,Guy Gur-Ari,Ethan Dyer,Behnam Neyshabur",19,32,5,"https://www.semanticscholar.org/paper/f843233f76a5dff07bfa93a71a1cf13d8aa6a94a"
"e37155d21818513bd40d64ee212099aac82bd6f8",2,"Less training, more repairing please: revisiting automated program repair via zero-shot learning","This paper proposesAlphaRepair, the first cloze-style (or infilling-style) APR approach to directly leveraging large pre-trained code models for APR without any fine-tuning/retraining on historical bug fixes, and implements AlphaRepair as a practical multilingual APR tool based on the recent CodeBERT model.","ESEC/SIGSOFT FSE",2022,"Chun Xia,Lingming Zhang",9,77,1,"https://www.semanticscholar.org/paper/e37155d21818513bd40d64ee212099aac82bd6f8"
"2f2750b48a6f958ff12cba90e99695123d1e2f47",2,"Using pre-trained language models to resolve textual and semantic merge conflicts (experience paper)","The feasibility of automatically repairing merge conflicts using k-shot learning with pre-trained large neural language models (LM) such as GPT-3 is explored, and LMs provide the state-of-the-art (SOTA) performance on semantic merge conflict resolution for Edge compared to earlier symbolic approaches.","International Symposium on Software Testing and Analysis",2022,"Jialu Zhang,Todd Mytkowicz,Mike Kaufman,R. Piskac,Shuvendu K. Lahiri",2,29,0,"https://www.semanticscholar.org/paper/2f2750b48a6f958ff12cba90e99695123d1e2f47"
"1e3ec5709b2ca43233c566cd77dbabbd6892bfa6",2,"Neurosymbolic repair for low-code formula languages","LaMirage, a LAst-MIle RepAir-engine GEnerator that combines symbolic and neural techniques to perform last-mile repair in low-code formula languages, is developed and compared to state-of-the-art neural and symbolic approaches on 400 real Excel and Power Fx formulas, where LaMirage outperforms all baselines.","Proc. ACM Program. Lang.",2022,"Rohan Bavishi,Harshit Joshi,Jos'e Pablo Cambronero S'anchez,Anna Fariha,Sumit Gulwani,Vu Le,Ivan Radicek,A. Tiwari",3,69,0,"https://www.semanticscholar.org/paper/1e3ec5709b2ca43233c566cd77dbabbd6892bfa6"
"ec4c8d99eb1c028c43af6d8bbf727392d351cb59",2,"Efficient Training of Language Models to Fill in the Middle","There is extensive evidence that training models with a large fraction of data transformed in this way does not harm the original left-to-right generative capability, as measured by perplexity and sampling evaluations across a wide range of scales.","ArXiv",2022,"Mohammad Bavarian,Heewoo Jun,N. Tezak,J. Schulman,C. McLeavey,Jerry Tworek,Mark Chen",14,60,1,"https://www.semanticscholar.org/paper/ec4c8d99eb1c028c43af6d8bbf727392d351cb59"
"def2e28863338cb20782eb2015a39d32df697ed6",2,"Learning to Improve Code Efficiency","","ArXiv",2022,"Bing Chen,Daniel Tarlow,Kevin Swersky,M. Maas,P. Heiber,Ashish Naik,Milad Hashemi,P. Ranganathan",1,35,0,"https://www.semanticscholar.org/paper/def2e28863338cb20782eb2015a39d32df697ed6"
"8c2d9d2aa891e3b53bbd9166c1b804a0741fc44a",2,"Finding Reusable Machine Learning Components to Build Programming Language Processing Pipelines","To improve theability, accessibility, interoperability and reusability (FAIRness) of machine learning components, a set of representative papers in the domain of machineLearning-based PLP are collected and analyzed.","ArXiv",2022,"Patrick Flynn,T. Vanderbruggen,C. Liao,Pei-Hung Lin,M. Emani,Xipeng Shen",1,32,0,"https://www.semanticscholar.org/paper/8c2d9d2aa891e3b53bbd9166c1b804a0741fc44a"
"9b61de7038290751377b64293baaf42f3e7cf441",2,"An Empirical Evaluation of Competitive Programming AI: A Case Study of AlphaCode","An empirical study to find code similarities and performance differences between AlphaCode-generated codes and human codes shows that the generated codes are similar to human codes and the generated code performs on par with or worse than the human code in terms of execution time and memory usage.","International Workshop on Software Clones",2022,"Sila Lertbanjongngam,Bodin Chinthanet,T. Ishio,R. Kula,P. Leelaprute,Bundit Manaskasemsak,A. Rungsawang,Kenichi Matsumoto",1,35,0,"https://www.semanticscholar.org/paper/9b61de7038290751377b64293baaf42f3e7cf441"
"befde3e07ce97f02f12fe92ab27e99f23ccd17aa",2,"Evaluating Progress in Automatic Chest X-Ray Radiology Report Generation","This study quantitatively examines the correlation between automated metrics and the scoring of reports by radiologists, and proposes a composite metric, called RadCliQ, that is able to rank the quality of reports similarly to radiologists and better than existing metrics.","medRxiv",2022,"F. Yu,M. Endo,R. Krishnan,I. Pan,A. Tsai,E. P. Reis,E. Fonseca,H. M. H. Lee,Z. H. Abad,A. Y. Ng,C. Langlotz,V. Venugopal,P. Rajpurkar",1,33,0,"https://www.semanticscholar.org/paper/befde3e07ce97f02f12fe92ab27e99f23ccd17aa"
"6b5d1e50894b1f28e4798cf20e9ffa88b9ec011a",2,"How to Prompt? Opportunities and Challenges of Zero- and Few-Shot Learning for Human-AI Interaction in Creative Applications of Generative Models","This work discusses the key opportunities and challenges for interactive creative applications that use prompting as a new paradigm for Human-AI interaction and proposes four design goals for user interfaces that support prompting.","ArXiv",2022,"Hai Dang,Lukas Mecke,Florian Lehmann,Sven Goller,D. Buschek",2,22,0,"https://www.semanticscholar.org/paper/6b5d1e50894b1f28e4798cf20e9ffa88b9ec011a"
"9360390b02b9a09ece9a2486055b17e18dc5d3f6",2,"Automatic Code Documentation Generation Using GPT-3","Codec is a GPT-3 based model pre-trained on both natural and programming languages that outperforms existing techniques even with basic settings like one-shot learning and achieves an overall BLEU score of 20.6 for six different programming languages.","International Conference on Automated Software Engineering",2022,"Junaed Younus Khan,Gias Uddin",0,60,0,"https://www.semanticscholar.org/paper/9360390b02b9a09ece9a2486055b17e18dc5d3f6"
"363758e9e296adc9391ed731e834809cf5d4c19b",2,"Are machine programming systems using right source-code measures to select code repositories?","A framework to rank open-source repositories on quality, maintainability, and popularity by leveraging existing research on this topic is developed and some correlation between the quality measures used in GitRank and ControlFlag's performance is revealed, suggesting that some of the measures used by GitRank are applicable to ControlFlag.","MaLTeSQuE@ESEC/SIGSOFT FSE",2022,"N. Hasabnis",1,32,0,"https://www.semanticscholar.org/paper/363758e9e296adc9391ed731e834809cf5d4c19b"
"cd6496bc404e18a24f634e3dded2ed1cdca03e0f",2,"Learning to Learn with Generative Models of Neural Network Checkpoints","This model is a conditional diffusion transformer that, given an initial input parameter vector and a prompted loss, error, or return, predicts the distribution over parameter updates that achieve the desired metric.","ArXiv",2022,"William S. Peebles,Ilija Radosavovic,Tim Brooks,Alexei A. Efros,J. Malik",8,77,0,"https://www.semanticscholar.org/paper/cd6496bc404e18a24f634e3dded2ed1cdca03e0f"
"55e3fe05598be7c3dd357d51166869f6571b824f",2,"Large Language Models are Pretty Good Zero-Shot Video Game Bug Detectors","This study explores the possibil-ity of leveraging the zero-shot capabilities of large language models for video game bug detection by formulating the bug detection problem as a question-answering task, and shows thatLarge language models can identify which event is buggy in a sequence of textual descriptions of events from a game.","ArXiv",2022,"Mohammad Reza Taesiri,F. Macklon,Yihe Wang,Hengshuo Shen,C. Bezemer",0,51,0,"https://www.semanticscholar.org/paper/55e3fe05598be7c3dd357d51166869f6571b824f"
"62f0db3a5ad5c795ec18fc7a6e7b01836809df57",2,"Language Models are Multilingual Chain-of-Thought Reasoners","It is shown that the multilingual reasoning abilities of language models extend to other tasks such as commonsense reasoning and word-in-context semantic judgment, and that models have strikingly strong mult bilingual reasoning abilities, even in underrepresented languages such as Bengali and Swahili.","ArXiv",2022,"Freda Shi,Mirac Suzgun,Markus Freitag,Xuezhi Wang,Suraj Srivats,Soroush Vosoughi,Hyung Won Chung,Yi Tay,Sebastian Ruder,Denny Zhou,Dipanjan Das,Jason Wei",17,50,1,"https://www.semanticscholar.org/paper/62f0db3a5ad5c795ec18fc7a6e7b01836809df57"
"259b7a01700c39d5669e88d1434873ea38a13528",2,"In-Context Policy Iteration","An algorithm, ICPI, that learns to perform RL tasks without expert demonstrations or gradients, and is presented as a policy-iteration method in which the prompt content is the entire locus of learning.","ArXiv",2022,"Ethan Brooks,Logan Walls,Richard L. Lewis,Satinder Singh",0,39,0,"https://www.semanticscholar.org/paper/259b7a01700c39d5669e88d1434873ea38a13528"
"5484d228bfc50efbac6e86677bc2ec2ee4ede1a6",2,"Scaling Instruction-Finetuned Language Models","This result shows that instruction and UL2 continued pre-training are complementary compute-eﬃcient methods to improve the performance of language models without increasing model scale.","ArXiv",2022,"Hyung Won Chung,Le Hou,S. Longpre,Barret Zoph,Yi Tay,W. Fedus,Eric Li,Xuezhi Wang,M. Dehghani,Siddhartha Brahma,Albert Webson,S. Gu,Zhuyun Dai,Mirac Suzgun,Xinyun Chen,Aakanksha Chowdhery,Dasha Valter,Sharan Narang,Gaurav Mishra,A. Yu,Vincent Zhao,Yanping Huang,Andrew M. Dai,Hongkun Yu,Slav Petrov,E. Chi,J. Dean,Jacob Devlin,Adam Roberts,Denny Zhou,Quoc Le,Jason Wei",36,104,10,"https://www.semanticscholar.org/paper/5484d228bfc50efbac6e86677bc2ec2ee4ede1a6"
"d26f616699a122e5455a13189e276002ee4cf923",2,"Draft, Sketch, and Prove: Guiding Formal Theorem Provers with Informal Proofs","This work introduces Draft, Sketch, and Prove (DSP), a method that maps informal proofs to formal proof sketches, and uses the sketches to guide an automated prover by directing its search to easier sub-problems.","ArXiv",2022,"Albert Qiaochu Jiang,S. Welleck,J. Zhou,Wenda Li,Jiacheng Liu,M. Jamnik,Timothée Lacroix,Yuhuai Wu,Guillaume Lample",2,40,0,"https://www.semanticscholar.org/paper/d26f616699a122e5455a13189e276002ee4cf923"
"472d87be3dc298102e058be55a814cc6d2085b39",2,"Towards Deceptive Defense in Software Security with Chaff Bugs","A new defensive technique called chaff bugs is proposed, which instead targets the bug discovery and exploit creation stages of this process, and can serve as an effective deterrent against both human attackers and automated bug-finding tools.","International Symposium on Recent Advances in Intrusion Detection",2022,"Zhenghao Hu,Yu Hu,Brendan Dolan-Gavitt",0,47,0,"https://www.semanticscholar.org/paper/472d87be3dc298102e058be55a814cc6d2085b39"
"ac3d7ae8b4acb137492d4a8d8bcff480b89fa000",2,"Programming Pedagogy and Assessment in the Era of AI/ML: A Position Paper","This work surveys recent research on automated systems for writing code, and examines the components of the code-writing task using a six-step framework proposed in the literature, and identifies the impact of automated systems at each step.","Compute",2022,"A. Raman,Viraj Kumar",0,39,0,"https://www.semanticscholar.org/paper/ac3d7ae8b4acb137492d4a8d8bcff480b89fa000"
"632ab7663e6d64578ceda1d1df9ec525b503bacb",2,"Steps towards prompt-based creation of virtual worlds","This work shows that prompt-based methods can both accelerate in-VR level editing, as well as can become part of gameplay rather than just part of game development.","ArXiv",2022,"Jasmine Roberts,Andrzej Banburski-Fahey,J. Lanier",0,41,0,"https://www.semanticscholar.org/paper/632ab7663e6d64578ceda1d1df9ec525b503bacb"
"048ed70192de0232086eb32a95ffb3be8d336c76",2,"Metaphors We Learn By","This essay relates parameter sharing (“weight sharing”) to analogy making and the school of thought of cognitive metaphor, and discusses how recurrent and auto-regressive models can be thought of as extending analogy making from static features to dynamic skills and procedures.","ArXiv",2022,"R. Memisevic",0,36,0,"https://www.semanticscholar.org/paper/048ed70192de0232086eb32a95ffb3be8d336c76"
"403028df4fe52786f1748f1c314b6eb2cf867197",2,"CLAWSAT: Towards Both Robust and Accurate Code Models","This is the first systematic study to explore and exploit the robustness and accuracy benefits of (multi-view) code obfuscations in code models and demonstrate the effectiveness of adversarial learning in CLAW.","ArXiv",2022,"Jinghan Jia,Shashank Srikant,Tamara Mitrovska,Chuang Gan,Shiyu Chang,Sijia Liu,Una-May O’Reilly",0,54,0,"https://www.semanticscholar.org/paper/403028df4fe52786f1748f1c314b6eb2cf867197"
"477d0b2abf07ee92732698f9aeb3c784f28ffa88",2,"On the Security Vulnerabilities of Text-to-SQL Models","Vulnerability tests on Text-to-SQL, a technique that builds natural language interfaces for databases, showed that the Text- to-SQL modules of two commercial black boxes can be manipulated to produce malicious code, potentially leading to data breaches and Denial of Service.","ArXiv",2022,"Xutan Peng,Yipeng Zhang,Jingfeng Yang,Mark Stevenson",0,71,0,"https://www.semanticscholar.org/paper/477d0b2abf07ee92732698f9aeb3c784f28ffa88"
"6d4a12ea469ff08634eeb24c47b265a7dca2fce2",2,"PADL: Language-Directed Physics-Based Character Control","PADL, which leverages recent innovations in NLP in order to take steps towards developing language-directed controllers for physics-based character animation, is presented and it is shown that the framework can be applied to effectively direct a simulated humanoid character to perform a diverse array of complex motor skills.","ACM SIGGRAPH Conference and Exhibition on Computer Graphics and Interactive Techniques in Asia",2022,"Jordan Juravsky,Yunrong Guo,S. Fidler,X. B. Peng",0,71,0,"https://www.semanticscholar.org/paper/6d4a12ea469ff08634eeb24c47b265a7dca2fce2"
"ea55ae4c82b45e3857f37406c94e9f642a2b3d84",2,"Genetic Programming with Local Scoring","New techniques for synthesizing programs through se-quences of mutations, including a method of local scoring assigning a score to each expression in a program, and cyclic evolution in which programs evolve programs through phases of expansion and reduction are presented.","ArXiv",2022,"Max Vistrup",0,9,0,"https://www.semanticscholar.org/paper/ea55ae4c82b45e3857f37406c94e9f642a2b3d84"
"4290a70025f29d7054c550c75ae6b24c38a79d12",2,"SE Factual Knowledge in Frozen Giant Code Model: A Study on FQN and its Retrieval","This work conducts the first systematic study on the SE factual knowledge in the state-of-the-art PCM CoPilot, focusing on APIs’ Fully Qualiﬁed Names (FQNs), the fundamental knowledge for effective code analysis, search and reuse.","ArXiv",2022,"Qing Huang,Dianshu Liao,Zhenchang Xing,Zhiqiang Yuan,Qinghua Lu,Xiwei Xu,Jiaxing Lu",0,74,0,"https://www.semanticscholar.org/paper/4290a70025f29d7054c550c75ae6b24c38a79d12"
"ae441f7305dc2cd58c708528b3ecee3501cc5c46",2,"Plansformer: Generating Symbolic Plans using Transformers","The use of LLMs for automated planning - a branch of AI concerned with the realization of action sequences (plans) to achieve a goal, typically executed by intelligent agents, autonomous robots, and unmanned vehicles are explored.","ArXiv",2022,"Vishal Pallagani,Bharath Muppasani,K. Murugesan,F. Rossi,L. Horesh,Biplav Srivastava,F. Fabiano,Andrea Loreggia",1,36,0,"https://www.semanticscholar.org/paper/ae441f7305dc2cd58c708528b3ecee3501cc5c46"
"3b8ccc7ec80b8775de603e248ac1ca2b919d6b70",2,"Chatbots in a Botnet World","Questions-and-answer formats provide a novel experimental platform for investigating cybersecurity questions and illustrate cases that support the broad gain of functionality, including self-replication and self-modification, evasion, and strategic understanding of complex cybersecurity goals.","ArXiv",2022,"Forrest McKee,David Noever",2,29,0,"https://www.semanticscholar.org/paper/3b8ccc7ec80b8775de603e248ac1ca2b919d6b70"
"6756fcd998caeb7b23702e08559e63710179334c",2,"Reasoning with Language Model Prompting: A Survey","This paper provides a comprehensive survey of cutting-edge research on reasoning with language model prompting and introduces research works with comparisons and summaries and provides systematic resources to help beginners.","ArXiv",2022,"Shuofei Qiao,Yixin Ou,Ningyu Zhang,Xiang Chen,Yunzhi Yao,Shumin Deng,Chuanqi Tan,Fei Huang,Huajun Chen",5,150,0,"https://www.semanticscholar.org/paper/6756fcd998caeb7b23702e08559e63710179334c"
"a8e0ba16346b72c3a04dd0b1da84bc5f28900174",2,"Using GitHub Copilot to Solve Simple Programming Problems","Evaluating Copilot, a natural language machine learning model trained on billions of lines of code, and looking qualitatively at the generated suggestions, to understand the limitations of Copilot.","",2023,"M. Wermelinger",1,15,1,"https://www.semanticscholar.org/paper/a8e0ba16346b72c3a04dd0b1da84bc5f28900174"
"490f1e8ff352bded30bcde01d5b4769d6c2d2dd5",2,"Adversarial Attacks on Neural Models of Code via Code Difference Reduction","This work proposes a novel adversarial attack technique, CODA, that uses the code differences between the target input and reference inputs to guide the generation of adversarial examples and considers both structure differences and identiﬁer differences to preserve the original semantics.","ArXiv",2023,"Zhao Tian,Junjie Chen,Zhi Jin",0,48,0,"https://www.semanticscholar.org/paper/490f1e8ff352bded30bcde01d5b4769d6c2d2dd5"
"468992bf970c37bd1fef58b78a6c2fcd8c018868",2,"Scaling Laws for Generative Mixed-Modal Language Models","New mixed-modal scaling laws that unify the contributions of individual modalities and the interactions between them are reported, and the optimal synergy and competition due to data and model size is explicitly model as an additive term to previous uni-modAL scaling laws.","ArXiv",2023,"Armen Aghajanyan,L. Yu,Alexis Conneau,Wei-Ning Hsu,Karen Hambardzumyan,Susan Zhang,Stephen Roller,Naman Goyal,Omer Levy,Luke Zettlemoyer",1,41,0,"https://www.semanticscholar.org/paper/468992bf970c37bd1fef58b78a6c2fcd8c018868"
"1f22de83d912176cb8857efa1c6d65b14d6a2f5c",2,"ChatGPT is not all you need. A State of the Art Review of large Generative AI models","This work consists on an attempt to describe in a concise way the main models are sectors that aresector that are aﬀected by generative AI and to provide a taxonomy of the main generative models published recently.","ArXiv",2023,"Roberto Gozalo-Brizuela,E.C. Garrido-Merchán",5,34,0,"https://www.semanticscholar.org/paper/1f22de83d912176cb8857efa1c6d65b14d6a2f5c"
"907a77639069bb7dd270f017068745706133cffc",2,"Inaccessible Neural Language Models Could Reinvigorate Linguistic Nativism","This work argues that this lack of accessibility could instill a nativist bias in researchers new to computational linguistics, and calls upon researchers to open source their LLM code wherever possible to allow both empircist and hybrid approaches to remain accessible.","ArXiv",2023,"Patrick Perrine",0,56,0,"https://www.semanticscholar.org/paper/907a77639069bb7dd270f017068745706133cffc"
"a20875e70a38cb053cd34e170038c4746f85dac9",2,"A Case Study in Engineering a Conversational Programming Assistant's Persona","The Programmer’s Assistant is an experimental prototype software development environment that integrates a chatbot with a code editor that establishes a conversational interaction pattern, a set of conventions.","ArXiv",2023,"Steven I. Ross,Michael J. Muller,Fernando Martinez,Stephanie Houde,Justin D. Weisz",0,22,0,"https://www.semanticscholar.org/paper/a20875e70a38cb053cd34e170038c4746f85dac9"
"074baf835aec44a100990178859b35451975f339",2,"Navigating Complexity in Software Engineering: A Prototype for Comparing GPT-n Solutions","A work-in-progress prototype “GPTC OMPARE” is presented, which allows programmers to visually compare multiple source code solutions generated by GPT-n models for the same programming- related query by highlighting their similarities and differences.","ArXiv",2023,"Christoph Treude",0,27,0,"https://www.semanticscholar.org/paper/074baf835aec44a100990178859b35451975f339"
"1d34b6cffe67077cdd4df41950b1195f09ae0cb8",2,"Hierarchical Programmatic Reinforcement Learning via Learning to Compose Programs","This work proposes to learn a meta-policy that composes a series of programs sampled from the learned program embedding space that can produce program policies that describe out-of-distributionally complex behaviors and directly assign credits to programs that induce desired behaviors.","ArXiv",2023,"Guanhui. Liu,En-Pei Hu,Pu-Jen Cheng,Hung-yi Lee,Shao-Hua Sun",0,51,0,"https://www.semanticscholar.org/paper/1d34b6cffe67077cdd4df41950b1195f09ae0cb8"
"861916af6428277a3ce2e18034e4b40dc6616eb9",2,"On the Robustness of Code Generation Techniques: An Empirical Study on GitHub Copilot","This paper presents an empirical study in which it is aimed at understanding whether different but semantically equivalent natural language descriptions result in the same recommended function, and investigates the extent to which predictions generated by Copilot changed.","ArXiv",2023,"A. Mastropaolo,L. Pascarella,Emanuela Guglielmi,Matteo Ciniselli,Simone Scalabrino,R. Oliveto,G. Bavota",0,60,0,"https://www.semanticscholar.org/paper/861916af6428277a3ce2e18034e4b40dc6616eb9"
"2af6a21a1b682ceb585165359d3605e89f4cf6b0",2,"Fixing Hardware Security Bugs with Large Language Models","The results show that LLMs can repair hardware security bugs and the framework designed and implemented are an important step towards the ultimate goal of an automated end-to-end bug repair framework.","ArXiv",2023,"Baleegh Ahmad,Shailja Thakur,B. Tan,R. Karri,H. Pearce",0,47,0,"https://www.semanticscholar.org/paper/2af6a21a1b682ceb585165359d3605e89f4cf6b0"
"d79e0cb459ba751e719889fbb9ae9398d35c37fb",2,"KNOD: Domain Knowledge Distilled Tree Decoder for Automated Program Repair","KNOD is proposed, which incorporates domain knowledge to guide patch generation in a direct and comprehensive way and is evaluated on three widely-used benchmarks, outperforming all existing APR tools.","ArXiv",2023,"Nan Jiang,Thibaud Lutellier,Yiling Lou,Lin Tan,Dan Goldwasser,Xiangyu Zhang",1,63,0,"https://www.semanticscholar.org/paper/d79e0cb459ba751e719889fbb9ae9398d35c37fb"
"fb243dfd1234b8f76dfda740a62402663da74085",2,"Exploring Data Augmentation for Code Generation Tasks","Focusing on data utilization for downstream tasks, this work proposes and adapt augmentation methods that yield consistent improvements in code translation and summarization by up to 6.9% and 7.5% respectively.","ArXiv",2023,"Pinzhen Chen,Gerasimos Lampouras",0,24,0,"https://www.semanticscholar.org/paper/fb243dfd1234b8f76dfda740a62402663da74085"
"8927db4ee890bf42608752bb840bc9d7db556da1",2,"ChatGPT and Software Testing Education: Promises & Perils","How well ChatGPT performs when tasked with solving common questions in a popular software testing curriculum is examined, and the potential promise, and dangers related to the use ofChatGPT by students and instructors are discussed.","ArXiv",2023,"Sajed Jalil,Suzzana Rafi,Thomas D. LaToza,Kevin Moran,Wing Lam",0,25,0,"https://www.semanticscholar.org/paper/8927db4ee890bf42608752bb840bc9d7db556da1"
"1586dd245ae4cca00ea519fb35f27e2a0980476d",1,"Teaching Structured Vision&Language Concepts to Vision&Language Models","Various techniques based on language structure understanding can be used to manipulate the textual part of off-the-shelf paired VL datasets that makes more effective use of existing VL pre-training datasets and does not require any additional data.","ArXiv",2022,"Sivan Doveh,Assaf Arbelle,Sivan Harary,R. Panda,Roei Herzig,Eli Schwartz,Donghyun Kim,R. Giryes,R. Feris,S. Ullman,Leonid Karlinsky",0,83,0,"https://www.semanticscholar.org/paper/1586dd245ae4cca00ea519fb35f27e2a0980476d"
"6d4e540e1bed26679097139bf90c8652919e4e5c",1,"Explanation Regeneration via Information Bottleneck","This work develops an information bottleneck method EIB that regenerates the free-text explanation by polishing the single-pass output from the pretrained language model but retaining the information that supports the contents being explained.","ArXiv",2022,"Qintong Li,Zhiyong Wu,Lingpeng Kong,Wei Bi",0,57,0,"https://www.semanticscholar.org/paper/6d4e540e1bed26679097139bf90c8652919e4e5c"
"6db13f58ff662eefa823a660fa86faf8ddf75533",1,"Controllable Text Generation with Language Constraints","A solution to leverage a language model’s own internal knowledge to guide generation and propose three forms of guidance (binary veriﬁer, top-k token, textual example), and employ pre-tuning approaches to distill the guidance to tackle diverse natural language constraints.","ArXiv",2022,"Howard Chen,Huihan Li,Danqi Chen,Karthik Narasimhan",0,38,0,"https://www.semanticscholar.org/paper/6db13f58ff662eefa823a660fa86faf8ddf75533"
"bbe93c90b7b87939cd064c805858feca61a3234d",1,"Self-Instruct: Aligning Language Model with Self Generated Instructions","S ELF -I NSTRUCT provides an almost annotation-free method for aligning pre-trained language models with instructions, and is released to facili-tate future studies on instruction tuning.","ArXiv",2022,"Yizhong Wang,Yeganeh Kordi,Swaroop Mishra,Alisa Liu,Noah A. Smith,Daniel Khashabi,Hannaneh Hajishirzi",4,54,2,"https://www.semanticscholar.org/paper/bbe93c90b7b87939cd064c805858feca61a3234d"
"430aaacce4147faef7940d1908cf715c3938e51f",1,"Using Language Models to Convert Between Natural Language and Game Commands","This paper looks at enhancing a Discord Bot called Avrae that is developed by D&D Beyond to help with online play, and uses GPT-3’s few shot learning and fine tuning capabilities to achieve 64% accuracy.","",,"Stefan Papazov,W. Gill,Marta Garcia Ferreiro,Andrew Zhu,Lara J. Martin,Chris Callison-Burch",0,13,0,"https://www.semanticscholar.org/paper/430aaacce4147faef7940d1908cf715c3938e51f"
"134a83d99b4913af4ed265310dfaa670e2689ce0",1,"Translating Natural Language to Bash Commands using Deep Neural Networks","It was found that while cross-entropy loss decreased steadily for all models, only T5 was able to continue learning the structure of Bash commands, and after post-processing, all models improved, but only T4 and BART exceeded the performance of the GPT-3 baseline model.","",2022,"Daniel Jenson,Yingxiao Liu",0,9,0,"https://www.semanticscholar.org/paper/134a83d99b4913af4ed265310dfaa670e2689ce0"
"9ed21b38ed48773048a6749c48748d3b88974a17",1,"A large-scale empirical study of commit message generation: models, datasets and evaluation","This paper conducts a systematic and in-depth analysis of the state-of-the-art models and datasets for automatic commit message generation and collects a large-scale, information-rich, multi-programming-language, MCMD.","Empirical Software Engineering",2022,"Wei Tao,Yanlin Wang,Ensheng Shi,Lun Du,Shi Han,Hongyu Zhang,Dongmei Zhang,Wenqiang Zhang",1,67,0,"https://www.semanticscholar.org/paper/9ed21b38ed48773048a6749c48748d3b88974a17"
"e772bf6ad9b87a333291f427d328e24cc57f23a1",1,"Human perceiving behavior modeling in evaluation of code generation models","A 5-level Likert scale assessment of the model output using a perceiving model based on the Theory of Planned Behavior (TPB) shows an extension of model assessment as well as a deeper understanding of the quality and applicability of generated code for practical question answering.","IEEE Games Entertainment Media Conference",2022,"S. Kovalchuk,Vadim Lomshakov,Artem Aliev",0,14,0,"https://www.semanticscholar.org/paper/e772bf6ad9b87a333291f427d328e24cc57f23a1"
"1ad47393da793fbf866c3ed071c088aa540359ac",1,"Who Evaluates the Evaluators? On Automatic Metrics for Assessing AI-based Offensive Code Generators","This practical experience report analyzes a large set of output similarity metrics on offensive code generators using two state-of-the-art NMT models using two datasets containing offensive assembly and Python code with their de- scriptions in the English language.","ArXiv",2022,"Cristina Improta,Pietro Liguori,R. Natella,B. Cukic,Domenico Cotroneo",0,49,0,"https://www.semanticscholar.org/paper/1ad47393da793fbf866c3ed071c088aa540359ac"
"cbbacf9ba52942fd6a43588295385e2ab39545b0",1,"Interacting with next-phrase suggestions: How suggestion systems aid and influence the cognitive processes of writing","","",2022,"Advait Bhat,Saaket Agashe,Niharika Mohile,Parth Oberoi,R. Jangir,Anirudha N. Joshi",1,49,0,"https://www.semanticscholar.org/paper/cbbacf9ba52942fd6a43588295385e2ab39545b0"
"1b13cf2971199d48722192b8c290d4c4eb63ca80",1,"Semi-Supervised Code Generation by Editing Intents","This work proposes a deep generative model to rewrite and augment utterances such as StackOverflow questions into an acceptable form by adding variable names and other important information.","",2018,"Edgar Chen",0,15,0,"https://www.semanticscholar.org/paper/1b13cf2971199d48722192b8c290d4c4eb63ca80"
"a9d240d911e338e6083cee83570c10af6f9dafb8",1,"A Comprehensive Study of StaQC for Deep Code Summarization","StaQC is described, a large-scale and high-quality dataset of <NL, code> pairs in Python and SQL domain, systematically mined from the Stack Overflow forum (SO), showing that StaQC helps achieve substantially better results.","",2018,"Jayavardhan Reddy Peddamail,Ziyu Yao,Zhen Wang,Huan Sun",3,51,0,"https://www.semanticscholar.org/paper/a9d240d911e338e6083cee83570c10af6f9dafb8"
"8e773b1840b894603c06b677a0f15ebcf0f26378",1,"Spider: A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-to-SQL Task","This work defines a new complex and cross-domain semantic parsing and text-to-SQL task so that different complicated SQL queries and databases appear in train and test sets and experiments with various state-of-the-art models show that Spider presents a strong challenge for future research.","Conference on Empirical Methods in Natural Language Processing",2018,"Tao Yu,Rui Zhang,Kai-Chou Yang,Michihiro Yasunaga,Dongxu Wang,Zifan Li,James Ma,Irene Z Li,Qingning Yao,Shanelle Roman,Zilin Zhang,Dragomir R. Radev",427,45,114,"https://www.semanticscholar.org/paper/8e773b1840b894603c06b677a0f15ebcf0f26378"
"e6b035ff8d839810593769b96edb18dd188c118c",1,"Reinforcing Diversity Company Policies: Insights from StackOverflow Developers Survey","This work is interested in understanding the pain points in software engineering regarding diversity and provide insights to support the attraction, hiring and retention policies for more diverse software engineering environments and proposes a discussion about the unconscious bias, stereotypes, and impostor syndrome.","International Conference on Enterprise Information Systems",2019,"K. Silveira,S. Musse,I. Manssour,R. Vieira,R. Prikladnicki",2,29,0,"https://www.semanticscholar.org/paper/e6b035ff8d839810593769b96edb18dd188c118c"
"970d34f38106023cfdacfb0bf59b7f3f64dcc4c3",1,"A Multi-Modal Intelligent Agent that Learns from Demonstrations and Natural Language Instructions","The preliminary lab usability evaluation results showed that the prototype of SUGILITE allowed users with little or no programming expertise to successfully teach the agent common smartphone tasks, as well as the appropriate conditionals for triggering these actions and the relevant concepts for determining these conditions.","",2019,"Toby Jia-Jun Li",0,146,0,"https://www.semanticscholar.org/paper/970d34f38106023cfdacfb0bf59b7f3f64dcc4c3"
"8cd26c197ad9635bd7508f01bdad67b6562099dd",1,"Deep Code-Comment Understanding and Assessment","This paper converts the quality assessment of code comments into a classification problem based on the multi-input neural network and concatenates the code vectors as the input of the Multiple-Layer Perceptron classifier for the comment quality assessment.","IEEE Access",2019,"Deze Wang,Yong Guo,Wei Dong,Zhiming Wang,Haoran Liu,Shanshan Li",4,29,0,"https://www.semanticscholar.org/paper/8cd26c197ad9635bd7508f01bdad67b6562099dd"
"4fbddbe0f23f76bd779f8d1e524374d6bf1bea81",1,"Learning to Map Natural Language to General Purpose Source Code","This dissertation presents efficient deep learning models and training paradigms to map language to general purpose source code that will enable numerous applications for non-expert users as well as developers.","",2019,"Srini Iyer",0,161,0,"https://www.semanticscholar.org/paper/4fbddbe0f23f76bd779f8d1e524374d6bf1bea81"
"4fdbf9af4058ff17c31db8bc8ca751d69b90ae43",1,"Semantic Parser and Natural Language Generator via Dual Information Maximization","This paper proposes the method of dual information maximization (DIM) to regularize the learning process, where DIM empirically maximizes the variational lower bounds of expected joint distributions of NL and MRs.","",2019,"Hai Ye",0,50,0,"https://www.semanticscholar.org/paper/4fdbf9af4058ff17c31db8bc8ca751d69b90ae43"
"3092325d55f6aa9ba28b0841bdcfd61991a38d48",1,"A Neural Model for Generating Natural Language Summaries of Program Subroutines","This paper presents a neural model that combines words from code with code structure from an AST, which allows the model to learn code structure independent of the text in code.","International Conference on Software Engineering",2019,"Alexander LeClair,Siyuan Jiang,Collin McMillan",169,59,40,"https://www.semanticscholar.org/paper/3092325d55f6aa9ba28b0841bdcfd61991a38d48"
"f44ceb54fa773920b767c1e93ea0bc8725f248df",1,"Automatic Acquisition of Annotated Training Corpora for Test-Code Generation","The experiments show that a neural MT model trained on a generated dataset can generate syntactically correct and semantically relevant short Java functions from quasi-natural language descriptions of functionality.","Inf.",2019,"Magdalena Kacmajor,John D. Kelleher",0,24,0,"https://www.semanticscholar.org/paper/f44ceb54fa773920b767c1e93ea0bc8725f248df"
"dfd252415b37208617da78d09cfd87480b9800eb",1,"Modeling Vocabulary for Big Code Machine Learning","It is shown that a subset of decisions have decisive characteristics, allowing to train accurate Neural Language Models quickly on a large corpus of 10,106 projects.","ArXiv",2019,"Hlib Babii,A. Janes,R. Robbes",22,80,1,"https://www.semanticscholar.org/paper/dfd252415b37208617da78d09cfd87480b9800eb"
"a57131646a16445df5ddbc86da917fb497cc27da",1,"Cleaning StackOverflow for Machine Translation","This paper cleans StackOverflow, one of the most popular online discussion forums for programmers, to generate a parallel English-Code corpus from Android posts, and creates a simple maximum likelihood MT model to show that English words in the corpus map to a small number of specific code elements.","IEEE Working Conference on Mining Software Repositories",2019,"Musfiqur Rahman,Peter C. Rigby,Dharani Palani,T. Nguyen",4,44,1,"https://www.semanticscholar.org/paper/a57131646a16445df5ddbc86da917fb497cc27da"
"1fbaed00dbda975a6209761857dd1a78618c6585",1,"Jointly Learning Semantic Parser and Natural Language Generator via Dual Information Maximization","A novel method of dual information maximization (DIM) is proposed to regularize the learning process, where DIM empirically maximizes the variational lower bounds of expected joint distributions of NL and MRs.","Annual Meeting of the Association for Computational Linguistics",2019,"Hai Ye,Wenjie Li,Lu Wang",19,50,1,"https://www.semanticscholar.org/paper/1fbaed00dbda975a6209761857dd1a78618c6585"
"735ce0447e459e13f89ae751b19323d76a2af786",1,"Program Synthesis and Semantic Parsing with Learned Code Idioms","PATOIS is a system that allows a neural program synthesizer to explicitly interleave high-level and low-level reasoning at every generation step, and it accomplishes this by automatically mining common code idioms from a given corpus and incorporating them into the underlying language for neural synthesis.","Neural Information Processing Systems",2019,"Richard Shin,Miltiadis Allamanis,Marc Brockschmidt,Oleksandr Polozov",58,43,7,"https://www.semanticscholar.org/paper/735ce0447e459e13f89ae751b19323d76a2af786"
"3b3a5a9c7352b74e8377ce3182ea646b0bed5b4c",1,"Reranking for Neural Semantic Parsing","This paper presents a simple approach to quickly iterate and improve the performance of an existing neural semantic parser by reranking an n-best list of predicted MRs, using features that are designed to fix observed problems with baseline models.","Annual Meeting of the Association for Computational Linguistics",2019,"Pengcheng Yin,Graham Neubig",45,31,10,"https://www.semanticscholar.org/paper/3b3a5a9c7352b74e8377ce3182ea646b0bed5b4c"
"561b279dd17a232f7466a5dda89d879f75a2bf3b",1,"Identifying Algorithm Names in Code Comments","This paper proposes an automatic method of algorithm name identification by extracting important N-gram words containing the word `algorithm' in the last from active FLOSS projects written in seven programming languages.","ArXiv",2019,"Jakapong Klainongsuang,Yusuf Sulistyo Nugroho,Hideaki Hata,Bundit Manaskasemsak,A. Rungsawang,P. Leelaprute,Ken-ichi Matsumoto",2,18,0,"https://www.semanticscholar.org/paper/561b279dd17a232f7466a5dda89d879f75a2bf3b"
"98ec93df77d6f672b4f682cbe315fedf0e2d4ee7",1,"PUMICE: A Multi-Modal Agent that Learns Concepts and Conditionals from Natural Language and Demonstrations","A new multi-modal domain-independent approach that combines natural language programming and programming-by-demonstration to allow users to first naturally describe tasks and associated conditions at a high level, and then collaborate with the agent to recursively resolve any ambiguities or vagueness through conversations and demonstrations is described.","ACM Symposium on User Interface Software and Technology",2019,"Toby Jia-Jun Li,Marissa Radensky,Justin Jia,Kirielle Singarajah,Tom Michael Mitchell,B. Myers",50,64,6,"https://www.semanticscholar.org/paper/98ec93df77d6f672b4f682cbe315fedf0e2d4ee7"
"fa5b139b08ef9ce0529d68c929f786412edc2898",1,"JuICe: A Large Scale Distantly Supervised Dataset for Open Domain Context-based Code Generation","To study code generation conditioned on a long context history, JuICe is presented, a corpus of 1.5 million examples with a curated test set of 3.7K instances based on online programming assignments that provides refined human-curated data, open-domain code, and an order of magnitude more training data.","Conference on Empirical Methods in Natural Language Processing",2019,"R. Agashe,Srini Iyer,Luke Zettlemoyer",34,33,9,"https://www.semanticscholar.org/paper/fa5b139b08ef9ce0529d68c929f786412edc2898"
"5ad7ce7810964bde2c86e07d63156270e0b17e0b",1,"Extracting Code-relevant Description Sentences Based on Structural Similarity","To quantify the relevance between code line and natural language sentence, the authors represent them with structure trees and calculate their structural similarity.","Asia-Pacific Symposium on Internetware",2019,"Yingkui Cao,Yanzhen Zou,Bing Xie",0,49,0,"https://www.semanticscholar.org/paper/5ad7ce7810964bde2c86e07d63156270e0b17e0b"
"539268757e7d29201a13e5ca90454eb151d3d022",1,"Abstraction, Generalization, and Embodiment in Neural Program Synthesis","This paper presents a meta-modelling framework that automates the very labor-intensive and therefore time-heavy and expensive process of designing and implementing neural program Synthesis systems.","",2020,"Richard Shin",0,129,0,"https://www.semanticscholar.org/paper/539268757e7d29201a13e5ca90454eb151d3d022"
"fd551f9b634b43b4b6be6fbda8369f95868ae94a",1,"POSIT: Simultaneously TaggingNatural and Programming Languages","This paper borrows code-switching techniques from Natural Language Processing and adapt them to apply to mixed text to solve two problems: language identification and token tagging, and develops POSIT, a technique that improves the state-of-the-art on language identification by 10.6% and PoS/AST tagging by 23.7% in accuracy.","",2020,"Profir-Petru Pârt",0,35,0,"https://www.semanticscholar.org/paper/fd551f9b634b43b4b6be6fbda8369f95868ae94a"
"d6fef46fd53c3bb13dc2cd32d8b8050b3f67058c",1,"Neural Semantic Parsing for Syntax-Aware Code Generation","This thesis presents an efficient neural semantic parser that exploits the underlying grammar of logical forms to enforce well-formed expressions and shows that the proposed model outperforms the standard encoder-decoder model across datasets and is competitive with comparable grammar-guided semantic parsing approaches.","",2020,"Artur Baranowski",0,68,0,"https://www.semanticscholar.org/paper/d6fef46fd53c3bb13dc2cd32d8b8050b3f67058c"
"1f8885c1dea94b97be0d0a89afe642c37ebfbc55",1,"Learning Based Methods for Code Runtime Complexity Prediction","This work model this problem as a machine learning task and check its feasibility with thorough analysis, establishing baselines using two different approaches: feature engineering and code embeddings, to achieve state of the art results and compare their performances.","European Conference on Information Retrieval",2019,"Jagriti Sikka,K. Satya,Yaman Kumar Singla,Shagun Uppal,R. Shah,Roger Zimmermann",2,17,0,"https://www.semanticscholar.org/paper/1f8885c1dea94b97be0d0a89afe642c37ebfbc55"
"a470dfc3dd30e4a27c8480d6fb817ece6a11d813",1,"Associating Natural Language Comment and Source Code Entities","A binary classifier and a sequence labeling model is developed by crafting a rich feature set which encompasses various aspects of code, comments, and the relationships between them and shows that these systems outperform several baselines learning from the proposed supervision.","AAAI Conference on Artificial Intelligence",2019,"Sheena Panthaplackel,Miloš Gligorić,R. Mooney,Junyi Jessy Li",14,39,0,"https://www.semanticscholar.org/paper/a470dfc3dd30e4a27c8480d6fb817ece6a11d813"
"b68f2d939ea3acaf4bee6a487522c27ef7d04cee",1,"Are the Code Snippets What We Are Searching for? A Benchmark and an Empirical Study on Code Search with Natural-Language Queries","This paper builds CosBench, a dataset that consists of 1000 projects, 52 code-independent natural-language queries with ground truths, and a set of scripts for calculating four metrics on code research results, and evaluated four IR (Information Retrieval)-based and two DL (Deep Learning)-based code search methods on CosBench.","IEEE International Conference on Software Analysis, Evolution, and Reengineering",2020,"Shuhan Yan,Hang Yu,Yuting Chen,Beijun Shen,Lingxiao Jiang",29,51,1,"https://www.semanticscholar.org/paper/b68f2d939ea3acaf4bee6a487522c27ef7d04cee"
"0dfe706526e5234338411489e1826b4060acc4e8",1,"CC2Vec: Distributed Representations of Code Changes","This work proposed CC2Vec, a neural network model that learns a representation of code changes guided by their accompanying log messages, which represent the semantic intent of the code changes, which outperform the state-of-the-art techniques.","International Conference on Software Engineering",2020,"Thong Hoang,Hong Jin Kang,J. Lawall,David Lo",77,70,18,"https://www.semanticscholar.org/paper/0dfe706526e5234338411489e1826b4060acc4e8"
"3944354c42ddfff7414ad06022f96c72858d5fa6",1,"Big Code != Big Vocabulary: Open-Vocabulary Models for Source Code","This paper presents an open vocabulary source code NLM that can scale to such a corpus, 100 times larger than in previous work; and shows that such models outperform the state of the art on three distinct code corpora (Java, C, Python).","International Conference on Software Engineering",2020,"Rafael-Michael Karampatsis,Hlib Babii,R. Robbes,Charles Sutton,A. Janes",149,95,27,"https://www.semanticscholar.org/paper/3944354c42ddfff7414ad06022f96c72858d5fa6"
"5e9b611a476e993f03c90424847311cd84e36a06",1,"Optimising the fit of stack overflow code snippets into existing code","An automated code reuse tool for the Eclipse IDE, NLP2TestableCode, which can not only search for Java code snippets using natural language tasks, but also evaluate code snippets based on a user's existing code, modify snippets to improve fit and correct errors, before presenting the user with the best snippet, all without leaving the editor.","GECCO Companion",2020,"Brittany Reid,Christoph Treude,Markus Wagner",6,25,0,"https://www.semanticscholar.org/paper/5e9b611a476e993f03c90424847311cd84e36a06"
"77910e51a40d17157fc798325d06edfa6cff18d6",1,"Incorporating External Knowledge through Pre-training for Natural Language to Code Generation","Evaluations show that combining the two sources with data augmentation and retrieval-based data re-sampling improves the current state-of-the-art by up to 2.2% absolute BLEU score on the code generation testbed CoNaLa.","Annual Meeting of the Association for Computational Linguistics",2020,"Frank F. Xu,Zhengbao Jiang,Pengcheng Yin,Bogdan Vasilescu,Graham Neubig",50,31,9,"https://www.semanticscholar.org/paper/77910e51a40d17157fc798325d06edfa6cff18d6"
"57348a5e75b89c1d3e8d5b85027872c35ebc6d36",1,"Relevance Transformer: Generating Concise Code Snippets with Relevance Feedback","The Relevance Transformer model shows the potential of Transformer-based architectures for code generation and introduces a method of incorporating pseudo-relevance feedback during inference, shown over state-of-the-art methods based on BLEU evaluation.","Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",2020,"Carlos Gemmell,Federico Rossetto,Jeffrey Dalton",8,21,2,"https://www.semanticscholar.org/paper/57348a5e75b89c1d3e8d5b85027872c35ebc6d36"
"a266b37f98928f27fddd863d11b38a5563043315",1,"Learning to Update Natural Language Comments Based on Code Changes","This work proposes an approach that learns to correlate changes across two distinct language representations, to generate a sequence of edits that are applied to the existing comment to reflect the source code modifications.","Annual Meeting of the Association for Computational Linguistics",2020,"Sheena Panthaplackel,Pengyu Nie,Miloš Gligorić,Junyi Jessy Li,R. Mooney",40,42,4,"https://www.semanticscholar.org/paper/a266b37f98928f27fddd863d11b38a5563043315"
"037aa837d95b5f0edef494a2392b1788dc840a47",1,"A Multi-Perspective Architecture for Semantic Code Search","A novel multi-perspective cross-lingual neural framework for code–text matching is proposed, inspired in part by a previous model for monolingual text-to-text matching, to capture both global and local similarities.","Annual Meeting of the Association for Computational Linguistics",2020,"Rajarshi Haldar,Lingfei Wu,Jinjun Xiong,J. Hockenmaier",23,13,3,"https://www.semanticscholar.org/paper/037aa837d95b5f0edef494a2392b1788dc840a47"
"eccd7060c4f81e92d65601f5c7ac7cade2f68807",1,"TAG : Type Auxiliary Guiding for Code Comment Generation","A Type Auxiliary Guiding encoder-decoder framework for the code comment generation task which considers the source code as an N-ary tree with type information associated with each node and a hierarchical reinforcement learning method to resolve the training difficulties of this proposed framework.","Annual Meeting of the Association for Computational Linguistics",2020,"Ruichu Cai,Zhihao Liang,Boyan Xu,Zijian Li,Yuexing Hao,Yao Chen",14,40,2,"https://www.semanticscholar.org/paper/eccd7060c4f81e92d65601f5c7ac7cade2f68807"
"c9aac0037e8abe2da081490cc9d10610aa8fdb3f",1,"Semantic code search using Code2Vec: A bag-of-paths model","This thesis uses Code2Vec, a model that learns distributed representations of source code called code embeddings, to evaluate its performance against the task of semantically searching code snippets to create a hybrid model that outperforms previous benchmark baseline models developed in the CodeSearchNet challenge.","",2020,"Lakshmanan Arumugam",4,46,0,"https://www.semanticscholar.org/paper/c9aac0037e8abe2da081490cc9d10610aa8fdb3f"
"0a01de6020e43db362e92664d1832a488d4a4c5b",1,"Improving Quality of a Post’s Set of Answers in Stack Overflow","An approach to automate the identification process of deficient posts on Stack Overflow and boost their set of answers, utilizing the help of related experts, and develops an Eclipse plugin named SOPI and integrated the prediction model in the plugin to link these deficient posts to related developers and help them improve the answer set.","EUROMICRO Conference on Software Engineering and Advanced Applications",2020,"M. Tavakoli,M. Izadi,A. Heydarnoori",4,19,0,"https://www.semanticscholar.org/paper/0a01de6020e43db362e92664d1832a488d4a4c5b"
"4e0daa62e8467c46123bc957f0068f7901e1e94f",1,"Mining API usage scenarios from stack overflow","A framework to automatically mine API usage scenarios from Stack Overflow, supported by three novel algorithms is proposed and implemented and deployed in the proof-of-concept online tool, Opiner.","Information and Software Technology",2020,"Gias Uddin,F. Khomh,C. Roy",23,108,0,"https://www.semanticscholar.org/paper/4e0daa62e8467c46123bc957f0068f7901e1e94f"
"eeb37b1b3019a03669b9b8b8173efbbd7c236184",1,"POSIT: Simultaneously Tagging Natural and Programming Languages","This paper borrows code-switching techniques from Natural Language Processing and adapt them to apply to mixed text to solve two problems: language identification and token tagging, and produces POSIT, which improves the state-of-the-art on language identification by 10.6% and PoS/Ast tagging by 23.7% in accuracy.","International Conference on Software Engineering",2020,"Profir-Petru Pârtachi,S. K. Dash,Christoph Treude,Earl T. Barr",7,35,0,"https://www.semanticscholar.org/paper/eeb37b1b3019a03669b9b8b8173efbbd7c236184"
"4a7e7b24389d190d20f214054156e43dc269e595",1,"POSIT","","Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering",2020,"Profir-Petru Pârtachi,S. K. Dash,Christoph Treude,Earl T. Barr",1,17,0,"https://www.semanticscholar.org/paper/4a7e7b24389d190d20f214054156e43dc269e595"
"8fbb41e21a8ba6072de60980d3c96e5e50c8e8fa",1,"CC2Vec","","Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering",2020,"Thong Hoang,Hong Jin Kang,D. Lo,Julia L. Lawall",1,35,0,"https://www.semanticscholar.org/paper/8fbb41e21a8ba6072de60980d3c96e5e50c8e8fa"
"ca0810e7658b72cdce6ea807d2ed0ed39ca70d4e",1,"Bug severity prediction using question-and-answer pairs from Stack Overflow","This paper extracts all the posts related to bug repositories from Stack Overflow and combines them with bug reports to obtain enhanced versions of bug reports and achieves severity prediction on three popular open source projects with Naive Bayesian, k-Nearest Neighbor algorithm (KNN), and Long Short-Term Memory (LSTM).","Journal of Systems and Software",2020,"Youshuai Tan,Sijie Xu,Zhaowei Wang,Tao Zhang,Zhou Xu,Xiapu Luo",26,41,1,"https://www.semanticscholar.org/paper/ca0810e7658b72cdce6ea807d2ed0ed39ca70d4e"
"7c41e58832f3af5fd9e09674924d6b5f822e8eac",1,"Exploring Unexplored Generalization Challenges for Cross-Database Semantic Parsing","This work re-purpose eight semantic parsing datasets that have been well-studied in the setting where in-domain training data is available, and instead use them as additional evaluation data for XSP systems instead, to uncovers several generalization challenges for cross-database semantic parsing.","Annual Meeting of the Association for Computational Linguistics",2020,"Alane Suhr,Ming-Wei Chang,Peter Shaw,Kenton Lee",52,62,17,"https://www.semanticscholar.org/paper/7c41e58832f3af5fd9e09674924d6b5f822e8eac"
"f30a7e6a1f7bbaf34493586fa61972a4789f7594",1,"Hierarchical Embedding for Code Search in Software Q&A Sites","A novel deep neural network named HECS 1 (Hierarchical embedding for code search), which can understand the difference between positive and negative samples more accurately and achieves state-of-the-art performance.","IEEE International Joint Conference on Neural Network",2020,"Ruitong Li,Gang Hu,Min Peng",0,35,0,"https://www.semanticscholar.org/paper/f30a7e6a1f7bbaf34493586fa61972a4789f7594"
"b5b9ed1e6d3cd2e51d155831cdfae39f2e0f4578",1,"Synergy between Machine/Deep Learning and Software Engineering: How Far Are We?","A 10-year Systematic Literature Review on 906 ML/DL-related SE papers published between 2009 and 2018 demonstrated the mutual impacts that ML/ DL and SE have had on each other and identified five factors that influence their replicability and reproducibility.","ArXiv",2020,"Simin Wang,LiGuo Huang,Jidong Ge,Tengfei Zhang,Haitao Feng,Ming Li,He Zhang,Vincent Ng",3,155,0,"https://www.semanticscholar.org/paper/b5b9ed1e6d3cd2e51d155831cdfae39f2e0f4578"
"2dc59238ad0f010f505238fcd0dd0695681200ef",1,"Neural Code Search Revisited: Enhancing Code Snippet Retrieval through Natural Language Intent","A domain-specific retrieval model for code annotated with a natural language description is created that yields significantly more relevant search results compared to state-of-the-art code retrieval methods that do not use descriptions.","ArXiv",2020,"Geert Heyman,T. V. Cutsem",15,31,3,"https://www.semanticscholar.org/paper/2dc59238ad0f010f505238fcd0dd0695681200ef"
"d944bf7942297f5670192c5cd33191c26a87973e",1,"Code to Comment “Translation”: Data, Metrics, Baselining & Evaluation","It is argued that fairly naive information retrieval methods do well enough at this task to be considered a reasonable baseline, and some suggestions on how the findings might be used in future research in this area are made.","International Conference on Automated Software Engineering",2020,"David Gros,Hariharan Sezhiyan,Prem Devanbu,Zhou Yu",38,64,2,"https://www.semanticscholar.org/paper/d944bf7942297f5670192c5cd33191c26a87973e"
"179076fe7aad3d5f085535b37bae85cbbae3c240",1,"CROKAGE: effective solution recommendation for programming tasks by leveraging crowd knowledge","The proposed CROKAGE (CrowdKnowledge Answer Generator), a tool that takes the description of a programming task as input and delivers a comprehensible solution for the task, outperforms the state-of-art tool in terms of relevance of the suggested code examples, benefit of the code explanations and the overall solution quality.","Empirical Software Engineering",2020,"R. F. Silva,C. Roy,M. M. Rahman,Kevin A. Schneider,K. V. R. Paixão,C. E. Dantas,M. Maia",7,75,1,"https://www.semanticscholar.org/paper/179076fe7aad3d5f085535b37bae85cbbae3c240"
"c6f608a3731a1fde355835a0e10a65ac71f80643",1,"Towards Full-line Code Completion with Neural Language Models","This paper conducts experiments on two real-world python corpora and evaluates existing neural models based on source code tokens or syntactical actions and shows that neural language models can achieve acceptable results on the authors' tasks, with significant room for improvements.","ArXiv",2020,"Wenhan Wang,Sijie Shen,Ge Li,Zhi Jin",7,26,0,"https://www.semanticscholar.org/paper/c6f608a3731a1fde355835a0e10a65ac71f80643"
"e6e8a2c56243847b77b604259cde9e10a2daccb8",1,"Semantic Evaluation for Text-to-SQL with Distilled Test Suite","This work proposes test suite accuracy to approximate semantic accuracy for Text-to-SQL models by distilling a small test suite of databases that achieves high code coverage for the gold query from a large number of randomly generated databases.","Conference on Empirical Methods in Natural Language Processing",2020,"Ruiqi Zhong,Tao Yu,D. Klein",26,44,3,"https://www.semanticscholar.org/paper/e6e8a2c56243847b77b604259cde9e10a2daccb8"
"3421e608d478161146d795752b6bcd222ed4c106",1,"When Does it Pay Off to Learn a New Skill? Revealing the Complementary Benefit of Cross-Skilling","The results indicate that the added economic value of learning a new skill strongly depends on the already existing skill bundle but that acquiring a skill from a different domain is often beneficial.","SSRN Electronic Journal",2020,"F. Stephany",6,113,0,"https://www.semanticscholar.org/paper/3421e608d478161146d795752b6bcd222ed4c106"
"f0a9ff1391bdefaf6d712e5c27e747d7d710bb40",1,"AlgoLabel: A Large Dataset for Multi-Label Classification of Algorithmic Challenges","This work proposes a large multi-modal dataset of text and code pairs consisting of algorithmic challenges and their solutions, called AlgoLabel and proposes a dual text-code neural model for detecting the algorithmic solution type for a programming challenge.","Mathematics",2020,"R. Iacob,V. Monea,D. Radulescu,Andrei-Florin Ceapă,Traian Rebedea,Stefan Trausan-Matu",1,52,0,"https://www.semanticscholar.org/paper/f0a9ff1391bdefaf6d712e5c27e747d7d710bb40"
"2df83c8604ac9260a77d85241b9da0539b29effa",1,"Statistical machine translation outperforms neural machine translation in software engineering: why and how","This work provides a hypothesis that SE corpus has inherent characteristics that NMT will confront challenges compared to the state-of-the-art translation engine based on Statistical Machine Translation, and implements and optimize the original SMT and NMT to mitigate those challenges.","",2020,"H. Phan,A. Jannesari",7,48,0,"https://www.semanticscholar.org/paper/2df83c8604ac9260a77d85241b9da0539b29effa"
"35f0482b4eadd92d5cd00932a729f00c64ce9e76",1,"Neural joint attention code search over structure embeddings for software Q&A sites","NJDACS is a novel two-way attention-based neural network for retrieving code fragments in software Q&A sites, which aligns and focuses the more structure informative parts of source codes to natural query.","Journal of Systems and Software",2020,"Gang Hu,Min Peng,Yihan Zhang,Qianqian Xie,Mengting Yuan",5,84,0,"https://www.semanticscholar.org/paper/35f0482b4eadd92d5cd00932a729f00c64ce9e76"
"b28ca9fb2056c8fd3f37e066f7809e7af27ef9b0",1,"BF++: a language for general-purpose neural program synthesis","A new programming language, BF++, is proposed, designed specifically for neural program synthesis in a Partially Observable Markov Decision Process (POMDP) setting and generate programs for a number of standard OpenAI Gym benchmarks.","ArXiv",2021,"Vadim Liventsev,Aki Härmä,M. Petkovic",2,47,0,"https://www.semanticscholar.org/paper/b28ca9fb2056c8fd3f37e066f7809e7af27ef9b0"
"ed2a639dd4a6b3abdcc0040733a264cb1dbcd7d4",1,"PlotCoder: Hierarchical Decoding for Synthesizing Visualization Code in Programmatic Context","This paper introduces PlotCoder, a new hierarchical encoder-decoder architecture that models both the code context and the input utterance and uses it to first determine the template of the visualization code, followed by predicting the data to be plotted.","Annual Meeting of the Association for Computational Linguistics",2021,"Xinyun Chen,Linyuan Gong,Alvin Cheung,D. Song",10,42,5,"https://www.semanticscholar.org/paper/ed2a639dd4a6b3abdcc0040733a264cb1dbcd7d4"
"e13d317fe0178a8b8b67f4af995e7fac12c35014",1,"Analysis of Tree-Structured Architectures for Code Generation","This work presents an empirical analysis of the significance of input parse trees for code generation, and finds that structure-aware encodings are better at modelling inputs with multiple variables and capturing long-range dependencies for codegeneration.","Findings",2021,"Samip Dahal,A. Maharana,Mohit Bansal",3,35,1,"https://www.semanticscholar.org/paper/e13d317fe0178a8b8b67f4af995e7fac12c35014"
"8e5b4aad131263457a38adbbffebe1b252802f1e",1,"Text2PyCode: Machine Translation of Natural Language Intent to Python Source Code","","International Cross-Domain Conference on Machine Learning and Knowledge Extraction",2021,"Sridevi Bonthu,S. R. Sree,M. K. Prasad",3,2,1,"https://www.semanticscholar.org/paper/8e5b4aad131263457a38adbbffebe1b252802f1e"
"62aceee1eca236841fddbad25833802750a92656",1,"Institutional Knowledge at Singapore Management University Institutional Knowledge at Singapore Management University CC2Vec: Distributed representations of code changes CC2Vec: Distributed representations of code changes","This work proposed CC2Vec, a neural network model that learns a representation of code changes guided by their accompanying log messages, which represent the semantic intent of the code changes, which outperform the state-of-the-art techniques.","",2021,"Thong Hoang",0,63,0,"https://www.semanticscholar.org/paper/62aceee1eca236841fddbad25833802750a92656"
"4d8bfc6b35d46a5a1dbad7aa273e81f49f5f6e4b",1,"Deep Learning Based Code Generation from Requirements Text: Are We There Yet?","A popularity based approach is proposed that always generates the most popular statements in training programs regardless of the input (software requirements), and evaluation results suggest that none of the state-of-the-art approaches can outperform this simple statistics-based approach.","",2021,"Hui Liu,Mingzhu Shen,Jiaqi Zhu,Nan Niu,Ge Li,Lu Zhang",0,60,0,"https://www.semanticscholar.org/paper/4d8bfc6b35d46a5a1dbad7aa273e81f49f5f6e4b"
"b029346bfa85fa2fc7a12498ae5f018922ce55f9",1,"Code Generation from Natural Language with Less Prior Knowledge and More Monolingual Data","This work investigates whether a generic transformer-based seq2seq model can achieve competitive performance with minimal code-generation-specific inductive bias design and achieves 81.03% exact match accuracy on Django and 32.57 BLEU score on CoNaLa.","Annual Meeting of the Association for Computational Linguistics",2021,"Sajad Norouzi,Keyi Tang,Yanshuai Cao",7,35,1,"https://www.semanticscholar.org/paper/b029346bfa85fa2fc7a12498ae5f018922ce55f9"
"ceeac1741f8c8dee5a1365828f79e8d3e84b0623",1,"Semantic Parsing with Less Prior and More Monolingual Data","This work investigates whether a generic transformerbased seq2seq model can achieve competitive performance with minimal semantic-parsing specific inductive bias design, and achieves positive evidence of a potentially easier path toward building accurate semantic parsers in the wild.","ArXiv",2021,"Sajad Norouzi,Yanshuai Cao",0,43,0,"https://www.semanticscholar.org/paper/ceeac1741f8c8dee5a1365828f79e8d3e84b0623"
"010c9f63c51ccc504de36d2d1693e0ea9d525da1",1,"Deep Learning for Source Code Modeling and Generation","A comprehensive review to categorize and investigate existing DL methods for source code modeling and generation, and formulate common program learning tasks under an encoder-decoder framework to address the limitations of the traditional source code models.","ACM Computing Surveys",2020,"T. H. Le,Hao Chen,M. Babar",57,297,1,"https://www.semanticscholar.org/paper/010c9f63c51ccc504de36d2d1693e0ea9d525da1"
"8c779ca55bef46f2380c1aea163ce9415f47b335",1,"One size does not fit all: Constructing complementary digital reskilling strategies using online labour market data","This commentary argues that, over the last decade, online labour platforms have become the ‘laboratories’ of skill rebundling; the combination of skills from different occupational domains that allows a new taxonomy on the individual complementarity of skills to be established.","",2021,"F. Stephany",9,37,1,"https://www.semanticscholar.org/paper/8c779ca55bef46f2380c1aea163ce9415f47b335"
"216425e1407875c94a754389b20bf983afe242c5",1,"Teach me how to Label: Labeling Functions from Natural Language with Text-to-text Transformers","The task of turning natural language descriptions into Python labeling functions by following a novel approach to semantic parsing with pre-trained text-to-text Transformers achieves a new state of the art on the semantic parsing benchmark CoNaLa, surpassing the previous best approach by 3.7 BLEU points.","ArXiv",2021,"Yannis Papanikolaou",0,23,0,"https://www.semanticscholar.org/paper/216425e1407875c94a754389b20bf983afe242c5"
"69a72ff5b30642d11c96635e99aadad3140d33a7",1,"CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation","This paper introduces CodeXGLUE, a benchmark dataset to foster machine learning research for program understanding and generation that includes a collection of 10 tasks across 14 datasets and a platform for model evaluation and comparison.","NeurIPS Datasets and Benchmarks",2021,"Shuai Lu,Daya Guo,Shuo Ren,Junjie Huang,Alexey Svyatkovskiy,Ambrosio Blanco,Colin B. Clement,Dawn Drain,Daxin Jiang,Duyu Tang,Ge Li,Lidong Zhou,Linjun Shou,Long Zhou,Michele Tufano,Ming Gong,Ming Zhou,Nan Duan,Neel Sundaresan,Shao Kun Deng,Shengyu Fu,Shujie Liu",257,115,65,"https://www.semanticscholar.org/paper/69a72ff5b30642d11c96635e99aadad3140d33a7"
"f389c09ad85263bdd1bb2518d61c90a8a558441d",1,"MulCode: A Multi-task Learning Approach for Source Code Understanding","This work proposes MulCode, a multi-task learning approach for source code understanding that learns unified representation space for tasks, with the pre-trained BERT model for the token sequence and the Tree-LSTM model for abstract syntax trees.","IEEE International Conference on Software Analysis, Evolution, and Reengineering",2021,"Deze Wang,Yue Yu,Shanshan Li,Wei Dong,Ji Wang,Qing Liao",7,56,1,"https://www.semanticscholar.org/paper/f389c09ad85263bdd1bb2518d61c90a8a558441d"
"b6262aa661b5195ad36b6a588c7160b1681abc2a",1,"Mining software architecture knowledge: Classifying stack overflow posts using machine learning","A supervised machine learning‐based approach to classify the architectural knowledge into predefined categories, that is, analysis, synthesis, evaluation, and implementation of software architectural knowledge management (AKM) is proposed.","Concurrency and Computation",2021,"Mubashir Ali,Husnain Mushtaq,M. B. Rasheed,Anees Baqir,T. Alquthami",1,38,0,"https://www.semanticscholar.org/paper/b6262aa661b5195ad36b6a588c7160b1681abc2a"
"969e8c2c7cdf26c35e6c3fc19a9a56b3e7fcd6f9",1,"Generating Code with the Help of Retrieved Template Functions and Stack Overflow Answers","This work presents a novel framework to precisely retrieve template functions as well as intent-snippet pairs and effectively train such a retrieval-guided code generator.","ArXiv",2021,"Dawn Drain,Changran Hu,Chen Wu,Mikhail Breslav,Neel Sundaresan",2,19,0,"https://www.semanticscholar.org/paper/969e8c2c7cdf26c35e6c3fc19a9a56b3e7fcd6f9"
"b15fa9e57fb791899154a0f6c321eb703f1c0b09",1,"Shellcode_IA32: A Dataset for Automatic Shellcode Generation","The first step to address the task of automatically generating shellcodes, i.e., small pieces of code used as a payload in the exploitation of a software vulnerability, starting from natural language comments is taken, consisting of challenging but common assembly instructions with their natural language descriptions.","NLP4PROG",2021,"Pietro Liguori,Erfan Al-Hossami,Domenico Cotroneo,R. Natella,B. Cukic,Samira Shaikh",11,30,1,"https://www.semanticscholar.org/paper/b15fa9e57fb791899154a0f6c321eb703f1c0b09"
"43e8ad04354bb40c1d10cb58b3187473a8275f82",1,"One Size Does not Fit All: Constructing Complementary Digital Re-Skilling Strategies Using Online Labour Market Data","","",2021,"F. Stephany",0,25,0,"https://www.semanticscholar.org/paper/43e8ad04354bb40c1d10cb58b3187473a8275f82"
"0c21334be0228431d619a180c809b43be0065bdd",1,"CoSQA: 20,000+ Web Queries for Code Search and Question Answering","A contrastive learning method dubbed CoCLR is introduced to enhance text-code matching, which works as a data augmenter to bring more artificially generated training instances to bring better semantic matching between query and code.","Annual Meeting of the Association for Computational Linguistics",2021,"Junjie Huang,Duyu Tang,Linjun Shou,Ming Gong,Ke Xu,Daxin Jiang,Ming Zhou,Nan Duan",30,40,5,"https://www.semanticscholar.org/paper/0c21334be0228431d619a180c809b43be0065bdd"
"8c4f89a9ac30cf94186916be1bfaa02dbfb3600d",1,"CoDesc: A Large Code–Description Parallel Dataset","It is shown that the dataset helps improve code search by up to 22% and achieves the new state-of-the-art in code summarization and CoDesc’s effectiveness in pre-training–finetuning setup, opening possibilities in building pretrained language models for Java.","Findings",2021,"Masum Hasan,Tanveer Muttaqueen,Abdullah Al Ishtiaq,Kazi Sajeed Mehrab,Md. Mahim Anjum Haque,Tahmid Hasan,Wasi Uddin Ahmad,Anindya Iqbal,Rifat Shahriyar",6,33,0,"https://www.semanticscholar.org/paper/8c4f89a9ac30cf94186916be1bfaa02dbfb3600d"
"47fa6b2645a95165399fc5c2e966f67ac2110df0",1,"Enriching API Documentation with Code Samples and Usage Scenarios from Crowd Knowledge","A novel approach named ADECK is proposed towards enriching API documentation with code samples and corresponding usage scenarios by leveraging crowd knowledge from Stack Overflow, a popular technical Question and Answer (Q&A) website attracting millions of developers.","IEEE Transactions on Software Engineering",2021,"Jingxuan Zhang,He Jiang,Zhilei Ren,Tao Zhang,Zhiqiu Huang",16,59,2,"https://www.semanticscholar.org/paper/47fa6b2645a95165399fc5c2e966f67ac2110df0"
"3ca1430fb5bbf6ffa8f377f6b603648268f7546e",1,"Exploring Dynamic Selection of Branch Expansion Orders for Code Generation","This paper proposes to equip the Seq2Tree model with a context-based Branch Selector, which is able to dynamically determine optimal expansion orders of branches for multi-branch nodes, and optimize the selector through reinforcement learning, and formulate the reward function as the difference of model losses obtained through different expansion orders.","Annual Meeting of the Association for Computational Linguistics",2021,"Hui Jiang,Chulun Zhou,Fandong Meng,Biao Zhang,Jie Zhou,Degen Huang,Qingqiang Wu,Jinsong Su",7,32,1,"https://www.semanticscholar.org/paper/3ca1430fb5bbf6ffa8f377f6b603648268f7546e"
"48db3e5425e1582f5659d98154fc8406cea0dc54",1,"A Globally Normalized Neural Model for Semantic Parsing","This paper proposes a globally normalized model for context-free grammar (CFG)-based semantic parsing that predicts a real-valued score at each step and does not suffer from the label bias problem.","SPNLP",2021,"Chenyang Huang,Wei Yang,Yanshuai Cao,O. Zaiane,Lili Mou",2,35,0,"https://www.semanticscholar.org/paper/48db3e5425e1582f5659d98154fc8406cea0dc54"
"cc9ad384ec0d0176ce05865d3866b44d2519bd68",1,"Reading StackOverflow Encourages Cheating: Adding Question Text Improves Extractive Code Generation","A corpus of over 40,000 StackOverflow question texts to be used in conjunction with the corresponding intents from the CoNaLa dataset to prove that BART is an unsupervised multimodal learner and examine its extractive behavior.","NLP4PROG",2021,"Gabriel Orlanski,Alex Gittens",9,42,2,"https://www.semanticscholar.org/paper/cc9ad384ec0d0176ce05865d3866b44d2519bd68"
"83a86fdf5d42fc70a07a2badd4fc9d42863f9b64",1,"SpreadsheetCoder: Formula Prediction from Semi-structured Context","This work proposes SPREADSHEETCODER, a BERT-based model architecture to represent the tabular context in both row-based and column-based formats, and achieves top-1 prediction accuracy of 42.51%, which is a considerable improvement over baselines that do not employ richtabular context.","International Conference on Machine Learning",2021,"Xinyun Chen,Petros Maniatis,Rishabh Singh,Charles Sutton,H. Dai,Max Lin,Denny Zhou",13,57,5,"https://www.semanticscholar.org/paper/83a86fdf5d42fc70a07a2badd4fc9d42863f9b64"
"04a9caa68ea24d183dce56903c5c05e49ae1d289",1,"Exploiting API Description Information to Improve Code Comment Generation","This paper has designed two models that combine code sequences and API description information to implement the code comment generation task, and conducted experiments on two open source data sets that demonstrate the effectiveness of API function description information for code commentgeneration task.","Advances in Artificial Intelligence and Security",2021,"Guang Yang,Qian Zhang,Yufei Wu,T. Zhou,Huan Liu,Wenting Feng",0,19,0,"https://www.semanticscholar.org/paper/04a9caa68ea24d183dce56903c5c05e49ae1d289"
"1601a4b1af2c22e047790ab189861368a5008f5f",1,"APIzation: Generating Reusable APIs from StackOverflow Code Snippets","This paper presents APIZATOR, a static analysis algorithm that automatically extracts the method parameters and return statements of JAVA code snippets automatically and is grounded by four common patterns that were extracted by studying real APIzations in GitHub.","International Conference on Automated Software Engineering",2021,"Valerio Terragni,P. Salza",3,63,0,"https://www.semanticscholar.org/paper/1601a4b1af2c22e047790ab189861368a5008f5f"
"0916d3112978bbe5f123553b5460ac1d05c6a8fd",1,"Mapping Language to Programs using Multiple Reward Components with Inverse Reinforcement Learning","This paper poses program generation from language as Inverse Reinforcement Learning as a challenge, and introduces several interpretable reward components that jointly learn a reward function that linearly combines them and a policy for program generation.","Conference on Empirical Methods in Natural Language Processing",2021,"Sayan Ghosh,Shashank Srivastava",1,49,0,"https://www.semanticscholar.org/paper/0916d3112978bbe5f123553b5460ac1d05c6a8fd"
"fa25e37fbd55dd05c0563de8f1e277f90c4ea589",1,"Text Classification for Task-based Source Code Related Questions","The task of determining if a pair of a question/problem and a corresponding code snippet is appropriate or not as a binary classification problem is posed.","ArXiv",2021,"Sairamvinay Vijayaraghavan,Jinxiao Song,David A. Tomassi,Siddhartha Punj,Jailan Sabet",0,20,0,"https://www.semanticscholar.org/paper/fa25e37fbd55dd05c0563de8f1e277f90c4ea589"
"e1d534c754d821bc405ecb0a954c8a3761d48a20",1,"Repo4QA: Answering Coding Questions via Dense Retrieval on GitHub Repositories","This paper introduces a specialized dataset named Repo4QA, which includes over 12,000 question-repository pairs constructed from Stack Overflow and GitHub, and proposes QuRep, a CodeBERT-based model that jointly learns the representation of both questions and repositories.","International Conference on Computational Linguistics",2022,"Minyu Chen,Guoqiang Li,Chen Ma,Jingyang Li,Hongfei Fu",0,44,0,"https://www.semanticscholar.org/paper/e1d534c754d821bc405ecb0a954c8a3761d48a20"
"445e5b31fc98f7acd2274aaa77d4de98816d89e3",1,"Towards Usable Neural Comment Generation Via Code-Comment Linkage Interpretation: Method and Empirical Study","CCLink is proposed, a novel model-independent framework, namely CCLink, to interpret the auto-generated comments of Neural Comment Generation (NCG), and is promising in making NCG more usable with a proper interpretation of theAuto- generated comments.","IEEE Transactions on Software Engineering",2022,"Shuyao Jiang,Jiacheng Shen,Shengnan Wu,Yu Cai,Yue Yu,Yangfan Zhou",0,70,0,"https://www.semanticscholar.org/paper/445e5b31fc98f7acd2274aaa77d4de98816d89e3"
"c317f4d5ddeb11da9a5c8fea1e3cdec2f7de485d",1,"Deep Learning Based Program Generation From Requirements Text: Are We There Yet?","A popularity-based approach is proposed that always generates the most popular statements in training programs regardless of the input (software requirements), and Evaluation results suggest that none of the state-of-the-art approaches can outperform this simple statistics- based approach.","IEEE Transactions on Software Engineering",2020,"Hui Liu,Mingzhu Shen,Jiaqi Zhu,Nan Niu,Ge Li,Lu Zhang",14,67,2,"https://www.semanticscholar.org/paper/c317f4d5ddeb11da9a5c8fea1e3cdec2f7de485d"
"1334674796f2122c4ede1eb6c1ad07cec9d77a28",1,"A Systematic Literature Review on the Use of Deep Learning in Software Engineering Research","A systematic literature review of research at the intersection of SE & DL, from its modern inception to the present, that delineates the foundations of DL techniques applied to SE research and highlights likely areas of fertile exploration for the future.","ACM Transactions on Software Engineering and Methodology",2020,"Cody Watson,N. Cooper,David Nader-Palacio,Kevin Moran,D. Poshyvanyk",28,203,0,"https://www.semanticscholar.org/paper/1334674796f2122c4ede1eb6c1ad07cec9d77a28"
"bea6af010fc02f5ac29edfc17096be6078edab46",1,"A Survey on Deep Learning for Software Engineering","A survey to analyze the relevant studies published since 2006 and presents a set of current challenges remaining to be investigated and outline a proposed research road map highlighting key opportunities for future work.","ACM Computing Surveys",2020,"Yanming Yang,Xin Xia,David Lo,J. Grundy",24,263,0,"https://www.semanticscholar.org/paper/bea6af010fc02f5ac29edfc17096be6078edab46"
"4a160efbe80c38cd5eb2f92c7c095b49b113397d",1,"In-IDE Code Generation from Natural Language: Promise and Challenges","This article develops a plugin for the PyCharm IDE that implements a hybrid of code generation and code retrieval functionality and asks developers with various backgrounds to complete 7 varieties of 14 Python programming tasks ranging from basic file manipulation to machine learning or data visualization, with or without the help of the plugin.","ACM Transactions on Software Engineering and Methodology",2021,"Frank F. Xu,Bogdan Vasilescu,Graham Neubig",41,134,5,"https://www.semanticscholar.org/paper/4a160efbe80c38cd5eb2f92c7c095b49b113397d"
"7ad2b12526e77badd629b10880db147afce4864a",1,"Lyra: A Benchmark for Turducken-Style Code Generation","This paper defines a new code generation task: given a natural language comment, this task aims to generate a program in a base imperative language with an embedded declarative language, and presents Lyra: a dataset in Python with embedded SQL, which they believe provides a new challenge for code generation.","International Joint Conference on Artificial Intelligence",2021,"Qingyuan Liang,Zeyu Sun,Qihao Zhu,Wenjie Zhang,Lian Yu,Yingfei Xiong,Lu Zhang",2,43,1,"https://www.semanticscholar.org/paper/7ad2b12526e77badd629b10880db147afce4864a"
"5bc74a4add942c340e6038235507e5f00b02d3b2",1,"Learning to Describe Solutions for Bug Reports Based on Developer Discussions","A corpus for this task is built using a novel technique for obtaining noisy supervision from repository changes linked to bug reports, with which it is found to form an ideal testbed for complex reasoning in long, bimodal dialogue context.","Findings",2021,"Sheena Panthaplackel,J. Li,Miloš Gligorić,R. Mooney",1,60,0,"https://www.semanticscholar.org/paper/5bc74a4add942c340e6038235507e5f00b02d3b2"
"2e375d8f4c4dbbf2fdf209f54eda70c9546e4096",1,"AstBERT: Enabling Language Model for Financial Code Understanding with Abstract Syntax Trees","This work proposes the AstBERT model, a pre-trained PL model aiming to better understand the financial codes using the abstract syntax tree (AST), and evaluates the performance of the proposed model on three tasks, including code question answering, code clone detection and code refinement.","FINNLP",2022,"Rong Liang,Tiehu Zhang,Y. Lu,Yuze Liu,Zhengqing Huang,Xin Chen",0,26,0,"https://www.semanticscholar.org/paper/2e375d8f4c4dbbf2fdf209f54eda70c9546e4096"
"758d85dd98f5caf59d51f9f3c09c2423471d56fd",1,"AstBERT: Enabling Language Model for Code Understanding with Abstract Syntax Tree","The AstBERT model is proposed, a pre-trained language model aiming to better understand the PL using the abstract syntax tree (AST), which collects a colossal amount of source codes from GitHub and incorporates the contextual code knowledge into the model through the help of code parsers.","ArXiv",2022,"Rong Liang,Yujie Lu,Zhen Huang,Tiehu Zhang,Yuze Liu",0,23,0,"https://www.semanticscholar.org/paper/758d85dd98f5caf59d51f9f3c09c2423471d56fd"
"532f32be1e918d6b75650947318e57fc8f4fb415",1,"CodeRetriever: Unimodal and Bimodal Contrastive Learning","The CodeRetriever model, which combines the unimodal and bimodal contrastive learning to train functionlevel code semantic representations, specifically for the code search task, achieves the new state-ofthe-art performance with significant improvement over existing code pre-trained models.","ArXiv",2022,"Xiaonan Li,Yeyun Gong,Yelong Shen,Xipeng Qiu,Hang Zhang,Bolun Yao,Weizhen Qi,Daxin Jiang,Weizhu Chen,Nan Duan",5,37,0,"https://www.semanticscholar.org/paper/532f32be1e918d6b75650947318e57fc8f4fb415"
"f5b3be8b0f06eba6d26ed02656fac82928b1ae05",1,"Natural Language to Code Using Transformers","The self-attention based transformer architecture is used and it is shown that it performs better than recurrent attention-based encoder decoder and a modified form of back translation and use cycle consistent losses to train the model in an end-to-end fashion.","ArXiv",2022,"Uday Kusupati,Venkata Ravi Teja Ailavarapu",2,13,0,"https://www.semanticscholar.org/paper/f5b3be8b0f06eba6d26ed02656fac82928b1ae05"
"2236b6036cd1ecba1792d5e1fedbae7cefc3d43b",1,"Can we generate shellcodes via natural language? An empirical study","The empirical analysis shows that NMT can generate assembly code snippets from the natural language with high accuracy and that in many cases can generate entire shellcodes with no errors.","International Conference on Automated Software Engineering",2022,"Pietro Liguori,Erfan Al-Hossami,Domenico Cotroneo,R. Natella,B. Cukic,Samira Shaikh",8,91,0,"https://www.semanticscholar.org/paper/2236b6036cd1ecba1792d5e1fedbae7cefc3d43b"
"97010ef4c4bd80b1f959df236501cf7741053d04",1,"On the Importance of Building High-quality Training Datasets for Neural Code Search","This is the first framework that applies semantic query cleaning to code search datasets and training the popular DeepCS model with the filtered dataset from this framework improves its performance by 19.2% MRR and 21.3% Answer@l, with the three validation benchmarks.","International Conference on Software Engineering",2022,"Zhensu Sun,Li Li,Y. Liu,Xiaoning Du",12,61,1,"https://www.semanticscholar.org/paper/97010ef4c4bd80b1f959df236501cf7741053d04"
"7ae55d0c0f501846deb1b6f13a03a249d9a2db4a",1,"Code Generation for Unknown Libraries via Reading API Documentations","This paper implements a model that can extract relevant code signatures from API documentations based on a natural language intent and copy primitives from the extracted signatures and can properly generate unknown primitives when extracted code signatures are noiseless.","ArXiv",2022,"Koki Washio,Yusuke Miyao",0,34,0,"https://www.semanticscholar.org/paper/7ae55d0c0f501846deb1b6f13a03a249d9a2db4a"
"f557534feabd3fa25052fd590a64d687b9754986",1,"Can we generate shellcodes via natural language? An empirical study","The empirical analysis shows that NMT can generate assembly code snippets from the natural language with high accuracy and that in many cases can generate entire shellcodes with no errors.","International Conference on Automated Software Engineering",2022,"Pietro Liguori,Erfan Al-Hossami,Domenico Cotroneo,R. Natella,Bojan Cukic,Samira Shaikh",0,77,0,"https://www.semanticscholar.org/paper/f557534feabd3fa25052fd590a64d687b9754986"
"56a75a76b86ea27c106f3e3e4a4d546c24e8678c",1,"Programming Language Agnostic Mining of Code and Language Pairs with Sequence Labeling Based Question Answering","This paper proposes a Sequence Labeling based Question Answering (SLQA) method to mine NL-PL pairs in a PL-agnostic manner and proposes to apply the BIO tagging scheme instead of the conventional binary scheme to mine the code solutions which are often composed of multiple blocks of a post.","ArXiv",2022,"Changran Hu,Akshara Reddi Methukupalli,Yutong Zhou,Chen Wu,Yubo Chen",0,42,0,"https://www.semanticscholar.org/paper/56a75a76b86ea27c106f3e3e4a4d546c24e8678c"
"8bf6109ed9dc5379d2340913e4184904d342918c",1,"DETECTION OF SOURCE CODE IN INTERNET TEXTS USING AUTOMATICALLY GENERATED MACHINE LEARNING MODELS","The software system was prepared for a discussion forum for software developers to find fragments of source code that were published without marking them as code snippets to be used for archiving purposes.","Applied Computer Science",2022,"M. Badurowicz",1,19,0,"https://www.semanticscholar.org/paper/8bf6109ed9dc5379d2340913e4184904d342918c"
"66b7836001407120ad0000369af8b30c44788a33",1,"Transformer with Tree-order Encoding for Neural Program Generation","This work has extended the positional encoding of the Transformer to allow the attention mechanism to also attend over hierarchical positions in the input and realized a decoder based on a restrictive grammar graph model to improve the generation accuracy and ensure the well-formedness of the generated code.","ArXiv",2022,"Klaudia Thellmann,Bernhard Stadler,Ricardo Usbeck,Jens Lehmann",0,31,0,"https://www.semanticscholar.org/paper/66b7836001407120ad0000369af8b30c44788a33"
"02da1f11b2620ee4a6c8b010fd1c8fe6f5ab5119",1,"Antecedent Predictions Are Dominant for Tree-Based Code Generation","This paper proposes an effective method, named APTRANX (Antecedent Prioritized TRANX), on the basis of TRANX, which helps the model attach importance to antecedent predictions by exploiting the position information of the generated AST nodes.","ArXiv",2022,"Yihong Dong,Ge Li,Zhi Jin",3,22,0,"https://www.semanticscholar.org/paper/02da1f11b2620ee4a6c8b010fd1c8fe6f5ab5119"
"b109588511459bf46e94cb4eb68b5cf79b092795",1,"Antecedent Predictions Are More Important Than You Think: An Effective Method for Tree-Based Code Generation","This paper designs an AST-to-Vector (AST2Vec) method, that maps AST node positions to two-dimensional vectors, to model the position information of AST nodes, and implements and trains an Antecedent Prioritized Tree-based code generation model called APT, which improves the performance of existing Seq2Tree methods.","",2022,"Yihong Dong,Ge Li,Zhi Jin",0,24,0,"https://www.semanticscholar.org/paper/b109588511459bf46e94cb4eb68b5cf79b092795"
"52fb239ea5cea1e9a2636f8f7922c8ede3e50ba7",1,"LILA: A Unified Benchmark for Mathematical Reasoning","It is found that multi-tasking leads to significant improvements (average relative improvement of 21.83% F1 score vs. single-task models), indicating the room for improvement in general mathematical reasoning and understanding.","Conference on Empirical Methods in Natural Language Processing",2022,"Swaroop Mishra,Matthew Finlayson,Pan Lu,Leonard Tang,S. Welleck,Chitta Baral,Tanmay Rajpurohit,Oyvind Tafjord,Ashish Sabharwal,Peter Clark,A. Kalyan",13,18,2,"https://www.semanticscholar.org/paper/52fb239ea5cea1e9a2636f8f7922c8ede3e50ba7"
"5fd0533ba1068af1cb075d4eb71ee551691a71ac",1,"ExploitGen: Template-augmented exploit code generation based on CodeBERT","","Journal of Systems and Software",2022,"Guang Yang,Yu Zhou,Xiang Chen,Xiangyu Zhang,Tingting Han,Taolue Chen",1,38,0,"https://www.semanticscholar.org/paper/5fd0533ba1068af1cb075d4eb71ee551691a71ac"
"f40aeae3e522ada1f6a9f326841b01ef5c8657b6",1,"Unifying Language Learning Paradigms","UL2 achieves SOTA performance on 50 well-established supervised NLP tasks ranging from language generation, language understanding, text classiﬁcation, question answering, commonsense reasoning, long text reasoning, structured knowledge grounding and information retrieval.","ArXiv",2022,"Yi Tay,M. Dehghani,V. Tran,Xavier García,Dara Bahri,Tal Schuster,Huaixiu Zheng,N. Houlsby,Donald Metzler",39,113,6,"https://www.semanticscholar.org/paper/f40aeae3e522ada1f6a9f326841b01ef5c8657b6"
"2ef60a4ea4ea53056be811ff55679eb59fb4b586",1,"Confident Adaptive Language Modeling","This work introduces Conﬁdent Adaptive Language Modeling (CALM), a framework for dynamically allocating different amounts of compute per input and generation timestep, and demonstrates the efﬂcacy of the framework in reducing compute—speedup of up to × 3 —while provably maintaining high performance.","ArXiv",2022,"Tal Schuster,Adam Fisch,Jai Gupta,M. Dehghani,Dara Bahri,V. Tran,Yi Tay,Donald Metzler",11,89,0,"https://www.semanticscholar.org/paper/2ef60a4ea4ea53056be811ff55679eb59fb4b586"
"ace0745f4449f20e4f4297476941fcd7dc7ab05c",1,"Higher Cognition: A Mechanical Perspective","","Encyclopedia",2022,"Robert Friedman",0,69,0,"https://www.semanticscholar.org/paper/ace0745f4449f20e4f4297476941fcd7dc7ab05c"
"eb5c1c666ce2fe1c531ecabfcdf264ae831fad89",1,"Understanding and Supporting Debugging Workflows in Multiverse Analysis","In understanding the composition of a multiverse, data strong in statistical analysis and design implications for future multiverse analysis authoring systems are concluded.","ArXiv",2022,"Ken Gu,Eunice Jun,Tim Althoff",0,45,0,"https://www.semanticscholar.org/paper/eb5c1c666ce2fe1c531ecabfcdf264ae831fad89"
"5e8bc5f84f3a550319b0d2b54cc0062b410d2328",1,"Taking Flight with Copilot","This study of Copilot shows that developers spend more time reviewing code than actually writing code, and developer roles will shift so that more time is spent assessing suggestions related to the task than doing the task itself.","Queue",2022,"C. Bird,Denae Ford,T. Zimmermann,Nicole Forsgren,Eirini Kalliamvakou,Travis Lowdermilk,Idan Gazit",0,12,0,"https://www.semanticscholar.org/paper/5e8bc5f84f3a550319b0d2b54cc0062b410d2328"
"5a05d7f6a2ee8fdb20f2e27baa95bd1e1a71c634",1,"Practitioners' Expectations on Code Completion","This work compares the practitioners’ demands with current research via conducting a literature review of papers on code completion published in premier publication venues from 2012 to 2022 and highlights the directions desirable for researchers to invest efforts towards developing code completion techniques for meeting practitioners' expectations.","ArXiv",2023,"Chaozheng Wang,Junhao Hu,Cuiyun Gao,Yu Jin,Tao Xie,Hailiang Huang,Zhenyu Lei,Yuetang Deng",0,54,0,"https://www.semanticscholar.org/paper/5a05d7f6a2ee8fdb20f2e27baa95bd1e1a71c634"
"522069bf612482f913fd83b2982127a19b2ab9b3",1,"Source Code Recommender Systems: The Practitioners' Perspective","A study involving 80 software developers to investigate the characteristics of code recommender systems they consider important is presented, and a taxonomy of 70 requirements that should be considered when designing codeRecommender systems is presented.","ArXiv",2023,"Matteo Ciniselli,L. Pascarella,Emad Aghajani,Simone Scalabrino,R. Oliveto,G. Bavota",0,60,0,"https://www.semanticscholar.org/paper/522069bf612482f913fd83b2982127a19b2ab9b3"
"43112f25190a9e19dc84cc7a0851318fdd1d9f71",1,"INTENT: Interactive Tensor Transformation Synthesis","INTENT, an interactive system that infers user intent and generates corresponding TensorFlow code on behalf of users, helps users understand and validate the semantics of generated code by rendering individual tensor transformation steps with intermediate results and element-wise data provenance.","ACM Symposium on User Interface Software and Technology",2022,"Zhanhui Zhou,Man To Tang,Qiping Pan,Shangyin Tan,Xinyu Wang,Tianyi Zhang",1,58,0,"https://www.semanticscholar.org/paper/43112f25190a9e19dc84cc7a0851318fdd1d9f71"
"6fe61d77b8a4a090899867b79e32efd658f848e7",1,"Explainable Natural Language to Bash Translation using Abstract Syntax Tree","This work proposes a novel transformer based solution by utilizing Bash Abstract Syntax Trees and manual pages that performs on par with the state of the art performance on Natural Language Context to Command task and performs better than fine-tuned T5 and Seq2Seq models.","Conference on Computational Natural Language Learning",2021,"Shikhar Bharadwaj,S. Shevade",4,21,0,"https://www.semanticscholar.org/paper/6fe61d77b8a4a090899867b79e32efd658f848e7"
"012d5d4346e84b6e158b252de9c87589dd62b16e",1,"Efficient Constituency Tree based Encoding for Natural Language to Bash Translation","A Segmented Invocation Transformer (SIT) that utilizes the information from the constituency parse tree of the natural language text and Bash command components is proposed that improves the performance of the model.","North American Chapter of the Association for Computational Linguistics",2022,"Shikhar Bharadwaj,S. Shevade",2,31,0,"https://www.semanticscholar.org/paper/012d5d4346e84b6e158b252de9c87589dd62b16e"
"94ac02f13ac3252a55b8740b7b310383cdf53445",1,"ShellFusion: Answer Generation for Shell Programming Tasks via Knowledge Fusion","This work proposes an approach, i.e., ShellFusion, to automatically generate comprehensive answers (including relevant shell commands, scripts, and explanations) for shell programming tasks, which significantly outperforms Magnum and DeepAns (a recent answer recommendation baseline).","International Conference on Software Engineering",2022,"Neng Zhang,Chao Liu,Xin Xia,Christoph Treude,Ying Zou,David Lo,Zibin Zheng",0,39,0,"https://www.semanticscholar.org/paper/94ac02f13ac3252a55b8740b7b310383cdf53445"
"988cb68d6510f3c4477b8c8ffe9cbdbea7971474",1,"Towards NLP-based Processing of Honeypot Logs","This work considers a widely used SSH/Telnet honeypot to record more than 200000 sessions, including 61000 unique shell scripts, some containing sequences of more than 100 Bash commands, to evaluate whether Natural Language Processing approaches can provide meaningful representations to find common traits in attackers' activity.","2022 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW)",2022,"Matteo Boffa,Giulia Milan,L. Vassio,I. Drago,M. Mellia,Zied Ben-Houidi",2,11,0,"https://www.semanticscholar.org/paper/988cb68d6510f3c4477b8c8ffe9cbdbea7971474"
"4b85c2ee560ccb3c62c75ee52fb5dda94353591a",1,"Code2Snapshot: Using Code Snapshots for Learning Representations of Source Code","Interestingly, obscuring input programs have insigniﬁcant impacts on the C ODE 2S NAPSHOT performance, suggesting that, for some tasks, neural models may provide high performance by relying merely on the structure of input programs.","",2021,"Md Rafiqul Islam Rabin,Mohammad Amin Alipour",3,32,0,"https://www.semanticscholar.org/paper/4b85c2ee560ccb3c62c75ee52fb5dda94353591a"
"6a3b6512de2caa712311feb876f1be599a7c0b68",1,"Encoding Program as Image: Evaluating Visual Representation of Source Code","This paper investigates Code2Snapshot, a novel representation of the source code that is based on the snapshots of input programs, and evaluates several variations of this representation and compares its performance with state-of-the-art representations that utilize the rich syntactic and semantic features ofinput programs.","ArXiv",2021,"Md Rafiqul Islam Rabin,Mohammad Amin Alipour",1,26,0,"https://www.semanticscholar.org/paper/6a3b6512de2caa712311feb876f1be599a7c0b68"
"87bb5593d04450bbbd29afc5b2ef395127d1ba6a",1,"Testing the Robustness of a BiLSTM-based Structural Story Classifier","This work examines the impact of noise on a state-of-the-art, structural model based on BiLSTM (Bidirectional Long-Short Term Model) for fake news detection, Hierarchical Discourse-level Structure for Fake News Detection by Karimi and Tang.","ArXiv",2022,"Aftab Hussain,Sai Durga Prasad Nanduri,Sneha Seenuvasavarathan",0,22,0,"https://www.semanticscholar.org/paper/87bb5593d04450bbbd29afc5b2ef395127d1ba6a"
"f0aacc7a0379883c4ab67d9a2d852c7bd99d9797",1,"Extracting Label-specific Key Input Features for Neural Code Intelligence Models","Extracting key input features from reduced programs reveals that the syntax-guided reduced programs contain more label-specific key input Features that may help to understand the reasoning of models’ prediction from different perspectives and increase the trustworthiness to correct classification given by CI models.","ArXiv",2022,"Md Rafiqul Islam Rabin",0,27,0,"https://www.semanticscholar.org/paper/f0aacc7a0379883c4ab67d9a2d852c7bd99d9797"
"b070d2c844d5b18d0c94fb6b20bef3946d60abfd",1,"Readle: A Formal Framework for Designing AI-based Edge Systems","A new systematic, extendable, manual approach, R EADLE, is proposed for creating representations of speciﬁcations in edge intelligent systems, capturing constraints in the edge system design space and constraint in the deep learning space in a coherent fashion.","ArXiv",2022,"Aftab Hussain",0,30,0,"https://www.semanticscholar.org/paper/b070d2c844d5b18d0c94fb6b20bef3946d60abfd"
"6042c51ccce53b94b84d1bdbcb33c3ab493323b4",1,"Syntax-guided program reduction for understanding neural code intelligence models","A syntax-guided program reduction technique that considers the grammar of the input programs during reduction that is faster and provides smaller sets of key tokens in reduced programs is applied.","MAPS@PLDI",2022,"Md Rafiqul Islam Rabin,Aftab Hussain,Mohammad Amin Alipour",4,29,0,"https://www.semanticscholar.org/paper/6042c51ccce53b94b84d1bdbcb33c3ab493323b4"
"81ce2664e892fc5f71fa4f8d61e7b42314dccb5e",1,"FeatureExtractor: A tool for extracting key input features of code intelligence models","","Softw. Impacts",2022,"Md Rafiqul Islam Rabin,Mohammad Amin Alipour",1,18,0,"https://www.semanticscholar.org/paper/81ce2664e892fc5f71fa4f8d61e7b42314dccb5e"
"66eae7128c34dd7967d79224eb9dbc978773c3d0",1,"I2D2: Inductive Knowledge Distillation with NeuroLogic and Self-Imitation","The key intellectual question is whether it is possible, if at all, to design a learning algorithm that does not beneﬁt from scale, yet leads to a competitive level of commonsense acquisition.","ArXiv",2022,"Chandra Bhagavatula,Jena D. Hwang,Doug Downey,Ronan Le Bras,Ximing Lu,Keisuke Sakaguchi,Swabha Swayamdipta,Peter West,Yejin Choi",0,33,0,"https://www.semanticscholar.org/paper/66eae7128c34dd7967d79224eb9dbc978773c3d0"
"459176532c85ae72f8b5cb35589b72468401d844",1,"SelfAPR: Self-supervised Program Repair with Test Execution Diagnostics","SelfAPR correctly repairs 110 bugs from Defects4J, outperforming all the supervised learning repair approaches and executes all training samples and extracts and encodes test execution diagnostics into the input representation, steering the neural model to fix the kind of fault.","International Conference on Automated Software Engineering",2022,"He Ye,Matias Martinez,Xiapu Luo,Tao Zhang,Monperrus Martin",6,98,1,"https://www.semanticscholar.org/paper/459176532c85ae72f8b5cb35589b72468401d844"
"3994eb8e237a94dae1efc6e767a09044b8550ace",1,"FCM: Forgetful Causal Masking Makes Causal Language Models Better Zero-Shot Learners","Experimental results show that the proposed technique improves PaLM’s zero and few-shot performance on a diverse suite of tasks, including commonsense reasoning, natural language inference and cloze completion, and also helps representation learning.","ArXiv",2022,"Hao Liu,Xinyang Geng,Lisa Lee,Igor Mordatch,S. Levine,Sharan Narang,P. Abbeel",2,53,0,"https://www.semanticscholar.org/paper/3994eb8e237a94dae1efc6e767a09044b8550ace"
"96f0f08e2dbeacc89a30d419a9cfb24312bd8da7",1,"BigIssue: A Realistic Bug Localization Benchmark","The introduction of BigIssue is proposed, a general benchmark for realistic bug localization and a motivation to improve bug localization capabilities of models through attention to the full repository context, to advance the state of the art in bug localization.","ArXiv",2022,"Paul Kassianik,Erik Nijkamp,Bo Pang,Yingbo Zhou,Caiming Xiong",0,33,0,"https://www.semanticscholar.org/paper/96f0f08e2dbeacc89a30d419a9cfb24312bd8da7"
"8fbd7ddf1ea30c991f3b1152a245df77caa18e16",1,"Learning by Distilling Context","This work shows that context distillation is a general method to train language models, and it can effectively internalize 3 types of training signals, and can internalize step-by-step reasoning for complex tasks.","ArXiv",2022,"Charles Burton Snell,D. Klein,Ruiqi Zhong",6,38,0,"https://www.semanticscholar.org/paper/8fbd7ddf1ea30c991f3b1152a245df77caa18e16"
"78f1ca609cd6f789749365c2870e2c2efd8f1fdf",1,"UniMASK: Unified Inference in Sequential Decision Problems","The Uni [MASK] framework is introduced, which provides a uniﬁed way to specify models which can be trained on many different sequential decision making tasks, and it is shown that a single Uni [ MASK] model is often capable of carrying out many tasks with performance similar to or better than single-task models.","ArXiv",2022,"Micah Carroll,Orr Paradise,Jessy Lin,Raluca Georgescu,Mingfei Sun,David Bignell,Stephanie Milani,Katja Hofmann,Matthew J. Hausknecht,A. Dragan,Sam Devlin",4,46,1,"https://www.semanticscholar.org/paper/78f1ca609cd6f789749365c2870e2c2efd8f1fdf"
"ef58e99dbb90bebbdc6187b5cba94dd5973dbb16",1,"Retrieval-Augmented Multimodal Language Modeling","Retrieval-Augmented CM3, the first retrieval-augmented multimodal model that can retrieve and generate mixtures of text and images, is proposed and shows that RA-CM3 exhibits novel capabilities such as knowledge-intensive image generation and multimodals in-context.","ArXiv",2022,"Michihiro Yasunaga,Armen Aghajanyan,Weijia Shi,Rich James,J. Leskovec,Percy Liang,M. Lewis,Luke Zettlemoyer,Wen-tau Yih",3,46,1,"https://www.semanticscholar.org/paper/ef58e99dbb90bebbdc6187b5cba94dd5973dbb16"
"7ed237af793f43c442b3e8e1bc9ace906a276b2a",1,"Transfer Knowledge from Natural Language to Electrocardiography: Can We Detect Cardiovascular Disease Through Language Models?","This work proposes an approach for cardiovascular disease diagnosis and automatic ECG diagnosis report generation and introduces an additional loss function by Optimal Transport to align the distribution between ECG and language embedding and proves the feasibility of transferring knowledge from LLMs to the cardiac domain.","ArXiv",2023,"Jielin Qiu,W. Han,Jiacheng Zhu,Mengdi Xu,Michael Rosenberg,Emerson Liu,Douglas Weber,Ding Zhao",0,95,0,"https://www.semanticscholar.org/paper/7ed237af793f43c442b3e8e1bc9ace906a276b2a"
"99752e255a866484291866a5ff5cf94e96d6bdc4",1,"Is a Question Decomposition Unit All We Need?","The findings indicate that Human-in-the-loop Question Decomposition (HQD) can potentially provide an alternate path to building large LMs and provides a viable option to involve people in NLP research in a meaningful way.","Conference on Empirical Methods in Natural Language Processing",2022,"Pruthvi H. Patel,Swaroop Mishra,Mihir Parmar,Chitta Baral",7,40,1,"https://www.semanticscholar.org/paper/99752e255a866484291866a5ff5cf94e96d6bdc4"
"a81d05e8812cd4adbd76bf408efdcab05d6bb8d7",1,"Creative Use of XAI In Socio-Technical Systems: A Case Study","It is shown that AI and explainability methods are used in creative ways in daily workflows, resulting in a divergence between their intended and actual use.","",2022,"Michaela Benk",0,14,0,"https://www.semanticscholar.org/paper/a81d05e8812cd4adbd76bf408efdcab05d6bb8d7"
"3fbea6c84b8c78c59392d7bf864dbe681924015f",1,"How Can We Develop Explainable Systems? Insights from a Literature Review and an Interview Study","","ICSSP/ICGSE",2022,"Larissa Chazette,J. Klünder,Merve Balci,K. Schneider",5,87,0,"https://www.semanticscholar.org/paper/3fbea6c84b8c78c59392d7bf864dbe681924015f"
"ba77991d19cf8c50ae2d2efcc9b5fb141acaa7b4",1,"Requirements Engineering for Machine Learning: A Review and Reflection","This paper aims to provide an overview of the requirements engineering process for machine learning applications in terms of cross domain collaborations, and goes through the collaborative requirements analysis process step-by-step.","2022 IEEE 30th International Requirements Engineering Conference Workshops (REW)",2022,"Zhong Pei,Lin Liu,Chen Wang,Jianmin Wang",2,182,0,"https://www.semanticscholar.org/paper/ba77991d19cf8c50ae2d2efcc9b5fb141acaa7b4"
"be747953df4b3269534c54addddc889986550343",1,"Psychological Impact and Influence of Animation on Viewer's Visual Attention and Cognition: A Systematic Literature Review, Open Challenges, and Future Research Directions","","Computational and Mathematical Methods in Medicine",2022,"C. K. Praveen,Kathiravan Srinivasan",1,85,0,"https://www.semanticscholar.org/paper/be747953df4b3269534c54addddc889986550343"
"edb6c93255bbaa879f6d4af173a947a2026ed4c6",1,"A nascent design theory for explainable intelligent systems","A nascent design theory for explainable intelligent systems is derived and evaluated based on a structured literature review, two qualitative expert studies, a real-world use case application, and quantitative research about how to socio-technically design these systems to address acceptance barriers among different user groups.","Electronic Markets",2022,"L. Herm,Th. Steinbach,Jonas Wanner,Christian Janiesch",2,132,0,"https://www.semanticscholar.org/paper/edb6c93255bbaa879f6d4af173a947a2026ed4c6"
"80a6501f518eaaf495e72373fc4128d374d25395",1,"Charting the Sociotechnical Gap in Explainable AI: A Framework to Address the Gap in XAI","","ArXiv",2023,"Upol Ehsan,Koustuv Saha,Munmun De Choudhury,Mark O. Riedl",0,167,0,"https://www.semanticscholar.org/paper/80a6501f518eaaf495e72373fc4128d374d25395"
"36589346063ff26506330451976280011273b935",1,"Towards Teachable Reasoning Systems","Generated chains of reasoning show how answers are implied by the system’s own internal beliefs, and are both faithful and truthful, which suggests new opportunities for using language models in an interactive setting where users can inspect, debug, correct, and improve a system‘s performance over time.","ArXiv",2022,"Bhavana Dalvi,Oyvind Tafjord,Peter Clark",10,40,3,"https://www.semanticscholar.org/paper/36589346063ff26506330451976280011273b935"
"18bda734a1546eae13f6b13600023ff73f95b6e3",1,"Program Synthesis Through Learning the Input-Output Behavior of Commands","The proposed system receives the syntax of the available commands and learns their meanings independently by writing programs and observing their input-output behavior, and believes that the proposed system provides a basis for synthesis systems based on learning input- Output behavior.","IEEE Access",2022,"Sihyung Lee,S. Nam,Jiyeon Kim",0,20,0,"https://www.semanticscholar.org/paper/18bda734a1546eae13f6b13600023ff73f95b6e3"
"29ed68d701f8450853938827b5124c9613c56aff",1,"ET-BERT: A Contextualized Datagram Representation with Pre-training Transformers for Encrypted Traffic Classification","This paper proposes a new traffic representation model called Encrypted Traffic Bidirectional Encoder Representations from Transformer (ET-BERT), which pre-trains deep contextualized datagram-level representation from large-scale unlabeled data and achieves state-of-the-art performance across five encrypted traffic classification tasks.","The Web Conference",2022,"Xinjie Lin,G. Xiong,Gaopeng Gou,Zhen Li,Junzheng Shi,J. Yu",4,47,0,"https://www.semanticscholar.org/paper/29ed68d701f8450853938827b5124c9613c56aff"
"608df5bd7a0ad0f4d335ae4d071b8cfe60e2f3c5",1,"On the Effectiveness of Pretrained Models for API Learning","This work uses a dataset that contains 7 million annotations collected from GitHub to evaluate the effectiveness of recent Pre-trained Transformer based Models (PTMs) for the API learning task and identifies two different tokenization approaches that can contribute to a significant boost in PTMs' performance for theAPI sequence generation task.","IEEE International Conference on Program Comprehension",2022,"M. Hadi,Imam Nur Bani Yusuf,Ferdian Thung,K. Luong,Lingxiao Jiang,F. Fard,David Lo",0,51,0,"https://www.semanticscholar.org/paper/608df5bd7a0ad0f4d335ae4d071b8cfe60e2f3c5"
"3eda53506586216acc96f4f34446f697874f360c",1,"Learning to Induce Causal Structure","The performance of the model improves as it observes more interventions, this suggest that the model is able to extract useful information from interventions in order to predict the causal structure.","ArXiv",2022,"Nan Rosemary Ke,S. Chiappa,Jane X. Wang,J. Bornschein,T. Weber,Anirudh Goyal,Matthew Botvinic,M. Mozer,Danilo Jimenez Rezende",9,81,0,"https://www.semanticscholar.org/paper/3eda53506586216acc96f4f34446f697874f360c"
"905cbe787b20fca3917d2afd6a7a5f073a50386e",1,"MP-CodeCheck: Evolving Logical Expression Code Anomaly Learning with Iterative Self-Supervision","This work presents MP-CodeCheck, an MP system that tries to identify anomalous code patterns within logical program expressions and compares it against ControlFlag, a state-of-the-art self-supervised code anomaly detection system; it is found that MPCC is more spatially and temporally efficient.","ArXiv",2022,"Urs C. Muff,Celine Lee,Paul Gottschlich,Justin Emile Gottschlich",0,71,0,"https://www.semanticscholar.org/paper/905cbe787b20fca3917d2afd6a7a5f073a50386e"
"abab9ae27efb40bbe6ffb9f6d27d56001412d856",1,"Scaling Genetic Improvement and Automated Program Repair","","APR",2022,"M. Harman",0,42,0,"https://www.semanticscholar.org/paper/abab9ae27efb40bbe6ffb9f6d27d56001412d856"
"74600cebaec0ecd6a9bde7e3830d813899bf8a91",1,"From {Solution Synthesis} to {Student Attempt Synthesis} for Block-Based Visual Programming Tasks","This work inves-tigate the crucial component of student modeling, the ability to automatically infer students’ misconceptions for predicting (synthesizing) their behavior, and introduces a novel benchmark, StudentSyn, centered around the following challenge: For a given student, synthesize the student’s attempt on a new target task after observing theStudentSyn.","ArXiv",2022,"A. Singla,Nikitas Theodoropoulos",2,52,0,"https://www.semanticscholar.org/paper/74600cebaec0ecd6a9bde7e3830d813899bf8a91"
"e7e1feff05edf89cac6c2e6de46815a3f89144ef",1,"Tensor Program Optimization with Probabilistic Programs","Experimental results show that MetaSchedule can cover the search space used in the state-of-the-art tensor program optimization frameworks in a modular way, and it empowers domain experts to conveniently grow theSearch space and modularly enhance the system, which brings 48% speedup on end-to-end deep learning workloads.","ArXiv",2022,"Junru Shao,Xiyou Zhou,Siyuan Feng,Bohan Hou,Ruihang Lai,Hongyi Jin,Wuwei Lin,Masahiro Masuda,Cody Hao Yu,Tianqi Chen",2,51,0,"https://www.semanticscholar.org/paper/e7e1feff05edf89cac6c2e6de46815a3f89144ef"
"29acc890e521f7a6415666ab9eb3432c49b4587a",1,"Self-critiquing models for assisting human evaluators","This work fine-tune large language models to write natural language critiques (natural language critical comments) using behavioral cloning, and suggests that even large models may still have relevant knowledge they cannot or do not articulate as critiques with both topic-based summarization and synthetic tasks.","ArXiv",2022,"W. Saunders,Catherine Yeh,Jeff Wu,Steven Bills,Long Ouyang,Jonathan Ward,J. Leike",17,46,1,"https://www.semanticscholar.org/paper/29acc890e521f7a6415666ab9eb3432c49b4587a"
"a82d6acc26d34f25d572da5dace6c29f4acfddfc",1,"Actionable Guidance for High-Consequence AI Risk Management: Towards Standards Addressing AI Catastrophic Risks","This document provides detailed actionable-guidance recommendations focused on identifying and managing risks of events with very high or catastrophic consequences, intended as a risk management practices resource for NIST for AI RMF version 1.0 (scheduled for release in early 2023), or for AIRMF users, or for other AI risk management guidance and standards as appropriate.","ArXiv",2022,"A. Barrett,Dan Hendrycks,J. Newman,Brandie Nonnecke",0,72,0,"https://www.semanticscholar.org/paper/a82d6acc26d34f25d572da5dace6c29f4acfddfc"
"3a2aa950971a46167b6da9431098b02facffe342",1,"Questions Are All You Need to Train a Dense Passage Retriever","ART is introduced, a new corpus-level autoencoding approach for training dense retrieval models that does not require any labeled training data and removes the need for labeled data and task-speciﬁc losses.","ArXiv",2022,"Devendra Singh Sachan,M. Lewis,Dani Yogatama,Luke Zettlemoyer,J. Pineau,M. Zaheer",6,51,2,"https://www.semanticscholar.org/paper/3a2aa950971a46167b6da9431098b02facffe342"
"746b6108a72b2b1bd78f70d4b1a211cdebfd8f49",1,"Multi-objective Grammar-guided Genetic Programming with Code Similarity Measurement for Program Synthesis","A novel multi-objective G3P approach that combines the similarity to the target program and the traditional input/output error rate is proposed and shown to improve the success rate of specific problems and has great potential to improve on the traditional G 3P system.","IEEE Congress on Evolutionary Computation",2022,"Ning Tao,Anthony Ventresque,Takfarinas Saber",0,33,0,"https://www.semanticscholar.org/paper/746b6108a72b2b1bd78f70d4b1a211cdebfd8f49"
"45875d5f55c72c1bdfa6d7c312eead7dcc93123d",1,"Borch: A Deep Universal Probabilistic Programming Language","Borch is presented, a scalable deep universal probabilistic programming language, built on top of PyTorch, which aims to force the models it creates to represent, learn, and report uncertainty in every prediction that is made.","ArXiv",2022,"Lewis Belcher,Johan Gudmundsson,Michael Green",0,34,0,"https://www.semanticscholar.org/paper/45875d5f55c72c1bdfa6d7c312eead7dcc93123d"
"558b7245a54575e16143324df98129254d5a244c",1,"Enhancing Code Similarity with Augmented Data Filtering and Ensemble Strategies","This algorithm is the first automated development system for increasing software productivity that addresses the current situation—a worldwide shortage of software dramatically improves performance in various downstream natural language processing tasks (NLP).","JOIV: International Journal on Informatics Visualization",2022,"Gyeongmin Kim,Minseok Kim,Jaechoon Jo",0,26,0,"https://www.semanticscholar.org/paper/558b7245a54575e16143324df98129254d5a244c"
"d400a649f0f0a3de22b89a268f48aff2dcb06a09",1,"Entailer: Answering Questions with Faithful and Truthful Chains of Reasoning","This work recursively combines a trained backward-chaining model, capable of generating a set of premises entailing an answer hypothesis, with a verifier that checks that the model itself believes those premises (and the entailment itself) through self-querying.","Conference on Empirical Methods in Natural Language Processing",2022,"Oyvind Tafjord,Bhavana Dalvi,Peter Clark",2,38,0,"https://www.semanticscholar.org/paper/d400a649f0f0a3de22b89a268f48aff2dcb06a09"
"4af2891ce1aab624c4917e8a69fcee5c8a1f41db",1,"NL2Viz: natural language to visualization via constrained syntax-guided synthesis","This work proposes a new approach and its supporting tool named NL2VIZ with three salient features: leveraging not only the user's NL input but also the data and program context that the NL query is upon, and providing support for result refinement and reuse.","ESEC/SIGSOFT FSE",2022,"Zhengkai Wu,Vu Le,A. Tiwari,Sumit Gulwani,Arjun Radhakrishna,Ivan Radicek,Gustavo Soares,Xinyu Wang,Zhenwen Li,Tao Xie",1,40,0,"https://www.semanticscholar.org/paper/4af2891ce1aab624c4917e8a69fcee5c8a1f41db"
"3d3012bfcc8bc7e4dc84c177e94650e66f03bc5b",1,"Are ChatGPT and AlphaCode going to replace programmers?","","Nature",2022,"D. Castelvecchi",8,1,0,"https://www.semanticscholar.org/paper/3d3012bfcc8bc7e4dc84c177e94650e66f03bc5b"
"000b8567d17dd982ae226c29505027ed692911dd",1,"AlphaCode and “data-driven” programming","The AlphaCode system is presented, which represents a substantial step forward in the development of machine learning models that can synthesize computer programs to solve these types of challenging problems, and what is perhaps most surprising about the system is what AlphaCode does not do: it contains no explicit built-in knowledge about the structure of computer code.","Science",2022,"J. Kolter",0,3,0,"https://www.semanticscholar.org/paper/000b8567d17dd982ae226c29505027ed692911dd"
"e8aa5f51aaf29344174f90d7edca49cc153a6b00",1,"Economic impacts of AI-augmented R&D","This work estimates the idea production function for AI in two computer vision tasks that are considered key test-beds for deep learning and suggests that AI-augmented R&D has the potential to speed up technological change and economic growth.","",2022,"T. Besiroglu,Nicholas Emery-Xu,Neil C. Thompson",0,112,0,"https://www.semanticscholar.org/paper/e8aa5f51aaf29344174f90d7edca49cc153a6b00"
"b7823997fb185f208b6a6723b60413ff179d2639",1,"Standing on the Shoulders of AI Giants","","Computer",2023,"Hsiao-Ying Lin",0,12,0,"https://www.semanticscholar.org/paper/b7823997fb185f208b6a6723b60413ff179d2639"
"e42843bfb05263df00837fa1b287bc816296e1fc",1,"Transformers Meet Directed Graphs","This work proposes two direction- and structure-aware positional encodings for directed graphs: the eigenvectors of the Magnetic Laplacian - a direction-aware generalization of the combinatorial LaPLacian; and directional random walkencodings.","ArXiv",2023,"Simon Geisler,Yujia Li,D. Mankowitz,A. Cemgil,Stephan Gunnemann,Cosmin Paduraru",0,42,0,"https://www.semanticscholar.org/paper/e42843bfb05263df00837fa1b287bc816296e1fc"
"be09ed6cd73654a23f78416433a1b23ea623ea79",1,"Symbolic Behaviour in Artificial Intelligence","This work argues that the path towards symbolically fluent artificial intelligence (AI) begins with a reinterpretation of what symbols are, how they come to exist, and how a system behaves when it uses them, and suggests that AI research explore social and cultural engagement as a tool to develop the cognitive machinery necessary for symbolic behaviour to emerge.","ArXiv",2021,"Adam Santoro,Andrew Kyle Lampinen,K. Mathewson,T. Lillicrap,David Raposo",19,139,0,"https://www.semanticscholar.org/paper/be09ed6cd73654a23f78416433a1b23ea623ea79"
"abd77509ef1cc739c0757ae657025fcee13c98dc",1,"Program Synthesis Guided Reinforcement Learning for Partially Observed Environments","This work proposes a new approach, model predictive program synthesis (MPPS), that uses program synthesis to automatically generate the guiding programs for program-guided reinforcement learning without requiring the user to provide a new guiding program for every new task.","Neural Information Processing Systems",2021,"Yichen Yang,J. Inala,O. Bastani,Yewen Pu,Armando Solar-Lezama,M. Rinard",5,83,0,"https://www.semanticscholar.org/paper/abd77509ef1cc739c0757ae657025fcee13c98dc"
"1093adc2a47212ef599e4708fe3e41ff7c9ec6d0",1,"GenLine and GenForm: Two Tools for Interacting with Generative Language Models in a Code Editor","A macro system with two tools that allow users to invoke language model prompts as macros in a code editor, and a form-like interface where the user provides input that is then transformed into multiple pieces of output at the same time.","ACM Symposium on User Interface Software and Technology",2021,"Ellen Jiang,Edwin Toh,A. Molina,Aaron Donsbach,Carrie J. Cai,Michael Terry",6,8,0,"https://www.semanticscholar.org/paper/1093adc2a47212ef599e4708fe3e41ff7c9ec6d0"
"3dc7dc1bea9a4f70c02b6759a0bda7aca0005a9e",1,"A General Language Assistant as a Laboratory for Alignment","A ‘preference model pre-training’ stage of training is studied, with the goal of improving sample efﬁciency when ﬁnetuning on human preferences, and investigating scaling trends for several training objectives relevant to alignment.","ArXiv",2021,"Amanda Askell,Yuntao Bai,Anna Chen,Dawn Drain,Deep Ganguli,T. Henighan,Andy Jones,Nicholas Joseph,Benjamin Mann,Nova DasSarma,Nelson Elhage,Zac Hatfield-Dodds,Danny Hernandez,John Kernion,Kamal Ndousse,Catherine Olsson,Dario Amodei,Tom B. Brown,Jack Clark,Sam McCandlish,C. Olah,Jared Kaplan",53,52,2,"https://www.semanticscholar.org/paper/3dc7dc1bea9a4f70c02b6759a0bda7aca0005a9e"
"4b70f356f50d3e8e1f72c4a10f0ce2a26da95b5a",1,"Controlling Conditional Language Models with Distributional Policy Gradients","The results show that fine-tuning using CDPG robustly moves these pretrained models closer towards meeting control objectives and — in contrast with baseline approaches — does not result in catastrophic forgetting.","ArXiv",2021,"Tomasz Korbak,Hady ElSahar,Germán Kruszewski,Marc Dymetman",0,42,0,"https://www.semanticscholar.org/paper/4b70f356f50d3e8e1f72c4a10f0ce2a26da95b5a"
"54d00fc330248b3b2f89193da31bb17851ebd2b7",1,"M EMORIZING T RANSFORMERS","It is demonstrated that an approximate kNN lookup into a non-differentiable memory of recent (key, value) pairs improves language modeling across various benchmarks and tasks, including generic webtext, math papers, books, code, as well as formal theorems (Isabelle).","",2022,"Memorizing Transformers,Yuhuai Wu,Markus N. Rabe,DeLesley S. Hutchins,Christian Szegedy",0,57,0,"https://www.semanticscholar.org/paper/54d00fc330248b3b2f89193da31bb17851ebd2b7"
"2aec574791fd33e9be32fd5191a66734f805a6a1",1,"Training Language Models with Natural Language Feedback","This work proposes to learn from natural language feedback, which conveys more information per human evaluation, from a GPT-3 model to roughly human-level summarization ability using a three-step learning algorithm.","",2022,"J. Scheurer,Jon Ander Campos,Jun Shern Chan,Angelica Chen,Kyunghyun Cho,Ethan Perez",4,35,0,"https://www.semanticscholar.org/paper/2aec574791fd33e9be32fd5191a66734f805a6a1"
"d3640eb3b542eaf36fee2261f037a6bf0d8eac9c",1,"AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts","Chaining LLM steps together is introduced, where the output of one step becomes the input for the next, thus aggregating the gains per step, and found that Chaining not only improved the quality of task outcomes, but also significantly enhanced system transparency, controllability, and sense of collaboration.","International Conference on Human Factors in Computing Systems",2021,"Tongshuang Sherry Wu,Michael Terry,Carrie J. Cai",36,96,1,"https://www.semanticscholar.org/paper/d3640eb3b542eaf36fee2261f037a6bf0d8eac9c"
"05af6c968ef8c7f9b07b0d67f138780179f29511",1,"Sparks: Inspiration for Science Writing using Language Models","This work presents a system for generating “sparks”, sentences related to a scientific concept intended to inspire writers, and finds three main use cases of sparks—inspiration, translation, and perspective—each of which correlates with a unique interaction pattern.","IN2WRITING",2021,"K. Gero,Vivian Liu,Lydia B. Chilton",8,84,0,"https://www.semanticscholar.org/paper/05af6c968ef8c7f9b07b0d67f138780179f29511"
"edc07f490c1c1b773094f236157219677f6a2f71",1,"Better Modeling the Programming World with Code Concept Graphs-augmented Multi-modal Learning","This paper proposes to enhance an existing pretrained language model of code by joint-learning it with a graph neural network based on a concept graphs based on the idea of leveraging multi-modal learning approaches to modeling the programming world.","2022 IEEE/ACM 44th International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER)",2022,"M. Weyssow,H. Sahraoui,Bang Liu",1,39,0,"https://www.semanticscholar.org/paper/edc07f490c1c1b773094f236157219677f6a2f71"
"0e802c0739771acf70e60d59c2df51cd7e8c50c0",1,"Memorizing Transformers","It is demonstrated that an approximate kNN lookup into a non-differentiable memory of recent (key, value) pairs improves language modeling across various benchmarks and tasks, including generic webtext, math papers, books, code, as well as formal theorems (Isabelle).","International Conference on Learning Representations",2022,"Yuhuai Wu,Markus N. Rabe,DeLesley S. Hutchins,Christian Szegedy",40,57,9,"https://www.semanticscholar.org/paper/0e802c0739771acf70e60d59c2df51cd7e8c50c0"
"9a6730534295335247eebdec59b7decdeb83d59a",1,"On the Transferability of Pre-trained Language Models for Low-Resource Programming Languages","The results show that multilingual PLMs have a lower Performance-to-Time Ratio as compared to monolingual PLMs, and the proposed strategy to select target programming languages to fine-tune mult bilingual PLMs is effective — it reduces the time to Fine-Tune yet achieves higher performance in Code Summarization and Code Search tasks.","IEEE International Conference on Program Comprehension",2022,"Fuxiang Chen,F. Fard,David Lo,T. Bryksin",4,49,0,"https://www.semanticscholar.org/paper/9a6730534295335247eebdec59b7decdeb83d59a"
"fd7c3c8fbe8cf88bd967ead02738b43081e306a7",1,"Training Language Models with Language Feedback","This work proposes to learn from natural language feedback, which conveys more information per human evaluation, from a GPT-3 model to roughly human-level summarization ability using a three-step learning algorithm.","",2022,"J. Scheurer,Jon Ander Campos,Jun Shern Chan,Angelica Chen,Kyunghyun Cho,Ethan Perez",6,43,1,"https://www.semanticscholar.org/paper/fd7c3c8fbe8cf88bd967ead02738b43081e306a7"
"16168520c7efbfa84bcb609a05362916b04022bb",1,"Context-Aware Abbreviation Expansion Using Large Language Models","This work proposes a paradigm in which phrases are abbreviated aggressively as primarily word-initial letters, and aims to expand the abbreviations into full-phrase options by leveraging conversation context with the power of pretrained large language models (LLMs).","North American Chapter of the Association for Computational Linguistics",2022,"Shanqing Cai,Subhashini Venugopalan,Katrin Tomanek,Ajit Narayanan,M. Morris,Michael P. Brenner",3,45,0,"https://www.semanticscholar.org/paper/16168520c7efbfa84bcb609a05362916b04022bb"
"6e10343767ab09dde83cf99ea3442907402a9810",1,"Evaluating the Impact of Model Scale for Compositional Generalization in Semantic Parsing","Limits of current techniques for effectively leveraging model scale for compositional generalization are highlighted, while the analysis also suggests promising directions for future work.","Conference on Empirical Methods in Natural Language Processing",2022,"Linlu Qiu,Peter Shaw,Panupong Pasupat,Tianze Shi,Jonathan Herzig,Emily Pitler,Fei Sha,Kristina Toutanova",10,84,2,"https://www.semanticscholar.org/paper/6e10343767ab09dde83cf99ea3442907402a9810"
"0f86d5ae106a53f40f89b60dff24074f6c2cd127",1,"The Case for a Single Model that can Both Generate Continuations and Fill in the Blank","This work shows that models pre-trained with a F IT B- 012 style objective are capable of both tasks, while model pre- trained for continuation are not, and shows how these models can be easily tuned to allow forained control over the length and word choice of the generation.","NAACL-HLT",2022,"Daphne Ippolito,Liam Dugan,Emily Reif,Ann Yuan,Andy Coenen,Chris Callison-Burch",0,27,0,"https://www.semanticscholar.org/paper/0f86d5ae106a53f40f89b60dff24074f6c2cd127"
"18a831422a4b4c89bbf1cc4baaa2cfcbf29daaf1",1,"Exploring and evaluating personalized models for code generation","This paper explores and evaluates transformer model fine-tuning for personalization in the context of generating unit tests for Java methods, and evaluates learning to personalize to a specific software project using several personalization techniques.","ESEC/SIGSOFT FSE",2022,"Andrei Zlotchevski,Dawn Drain,Alexey Svyatkovskiy,Colin B. Clement,Neel Sundaresan,Michele Tufano",0,31,0,"https://www.semanticscholar.org/paper/18a831422a4b4c89bbf1cc4baaa2cfcbf29daaf1"
"3ee3f425482cf86989d809155cc8cf2bf8d8113e",1,"Understanding HTML with Large Language Models","It is shown that LLMs pretrained on standard natural language corpora transfer re-markably well to HTML understanding tasks, and evidence that T5-based models are ideal due to their bidirectional encoder-decoder architecture is shown.","ArXiv",2022,"Izzeddin Gur,Ofir Nachum,Yingjie Miao,Mustafa Safdari,Austin Huang,Aakanksha Chowdhery,Sharan Narang,Noah Fiedel,Aleksandra Faust",1,29,0,"https://www.semanticscholar.org/paper/3ee3f425482cf86989d809155cc8cf2bf8d8113e"
"13d3733e0dabbb4ccdd036a5f04fd5b3e39eecb0",1,"Vision Transformers provably learn spatial structure","This paper proposes a spatially structured dataset and a simplified ViT model and proposes a mechanism that implicitly learns the spatial structure of the dataset while generalizing, and proves that patch association helps to sample-efficiently transfer to downstream datasets that share the same structure as the pre-training one but differ in the features.","ArXiv",2022,"Samy Jelassi,Michael E. Sander,Yuan-Fang Li",1,77,0,"https://www.semanticscholar.org/paper/13d3733e0dabbb4ccdd036a5f04fd5b3e39eecb0"
"e8db669c8cb1c07557ede15e2771968f9370330b",1,"Large language models are not zero-shot communicators","A simple task is designed and widely used state-of-the-art models are evaluated, finding that, despite only evaluating on utterances that require a binary inference (yes or no), most perform close to random.","ArXiv",2022,"Laura Ruis,Akbir Khan,Stella Rose Biderman,Sara Hooker,Tim Rocktaschel,Edward Grefenstette",2,100,0,"https://www.semanticscholar.org/paper/e8db669c8cb1c07557ede15e2771968f9370330b"
"e7d0a8eb7e98863f37b51d89b5ca305b04aaba99",1,"SemanticOn: Specifying Content-Based Semantic Conditions for Web Automation Programs","SemanticOn is introduced, a system that enables users to specify, refine, and incorporate visual and textual semantic conditions in web automation programs via two methods: natural language description via prompts or information highlighting.","ACM Symposium on User Interface Software and Technology",2022,"Kevin Pu,Rainey Fu,Rui Dong,Xinyu Wang,Yuanchun Chen,Tovi Grossman",0,71,0,"https://www.semanticscholar.org/paper/e7d0a8eb7e98863f37b51d89b5ca305b04aaba99"
"9b5fb07df99b0dd65f3058701d7f017c3a70c144",1,"Leveraging Large Language Models to Power Chatbots for Collecting User Self-Reported Data","This work formulated four prompt designs with different structures and personas to explore what design factors of prompts can help steer chatbots to talk naturally and collect data reliably and discusses the opportunities and challenges of building chatbots with LLMs.","ArXiv",2023,"Jing Wei,Sungdong Kim,Hyunhoon Jung,Young-Ho Kim",0,102,0,"https://www.semanticscholar.org/paper/9b5fb07df99b0dd65f3058701d7f017c3a70c144"
"fd0bccf5e7c1fb5dadd75972e3212554fb255fe2",1,"MISIM: A Neural Code Semantics Similarity System Using the Context-Aware Semantics Structure","This work presents Machine Inferred Code Similarity (MISIM), a neural code semantics similarity system consisting of two core components: a novel context-aware semantics structure, which was purpose-built to lift semantics from code syntax and an extensible neural code similarity scoring algorithm, which can be used for various neural network architectures with learned parameters.","",2020,"Fangke Ye,Sheng-Tian Zhou,Anand Venkat,Ryan Marcus,Nesime Tatbul,Jesmin Jahan Tithi,N. Hasabnis,Paul Petersen,T. Mattson,Tim Kraska,P. Dubey,Vivek Sarkar,Justin Emile Gottschlich",3,62,0,"https://www.semanticscholar.org/paper/fd0bccf5e7c1fb5dadd75972e3212554fb255fe2"
"0c7cb854756f6b69f070a925cd497c2970b136f2",1,"DeSkew-LSH based Code-to-Code Recommendation Engine","Senatus, a new code-to-code recommendation engine that addresses both the scale gracefully to large codebases and the global statistics of code repositories in the ranking function, such as the distribution of code snippet lengths, leads to sub-optimal retrieval results.","ArXiv",2021,"Fran Silavong,S. Moran,Antonios Georgiadis,Rohan Saphal,R. Otter",0,48,0,"https://www.semanticscholar.org/paper/0c7cb854756f6b69f070a925cd497c2970b136f2"
"21363c1ac138d8df80b20af4848b5113bd3bf6f8",1,"Clone-advisor: recommending code tokens and clone methods with deep learning and information retrieval","This paper applies an information retrieval technique on top of DeepClone output to recommend real clone methods closely matching the predicted clone method, thus improving the original output by DeepClones.","PeerJ Computer Science",2021,"Muhammad Hammad,Önder Babur,H. Basit,M. Brand",1,107,1,"https://www.semanticscholar.org/paper/21363c1ac138d8df80b20af4848b5113bd3bf6f8"
"58b142663367ef6ed67507e3d7591b6e384a6937",1,"Deep Distilling: automated code generation using explainable deep learning","Deep distilling is introduced, a machine learning method that learns patterns from data using explainable deep learning and then condenses it into concise, executable computer code that generalizes out-of-distribution to solve problems orders of-magnitude larger and more complex than the training data.","ArXiv",2021,"Paul J. Blazek,Kesavan Venkatesh,M. Lin",1,20,0,"https://www.semanticscholar.org/paper/58b142663367ef6ed67507e3d7591b6e384a6937"
"4e7de32c8da8c910285acdaf397347dc94ca3594",1,"Many Heads but One Brain: Fusion Brain -- a Competition and a Single Multimodal Multitask Architecture","The proposed Fusion approach proves to be competitive and more energy-efﬁcient compared to the task- speci⬁c one.","",2021,"Daria Bakshandaeva,Denis Dimitrov,Alex Shonenkov,M. Potanin,V.Ya. Arkhipkin,Denis Karachev,Vera Davydova,Anton Voronov,Mikhail Martynov,Natalia Semenova,Mikhail Stepnov,Elena Tutubalina,Andrey Chertok,Aleksandr Petiushko",0,50,0,"https://www.semanticscholar.org/paper/4e7de32c8da8c910285acdaf397347dc94ca3594"
"7fba3100768fa3aac0fbf961d5e894b2f629e6e6",1,"Federated Data Science to Break Down Silos [Vision]","KEK is proposed, an open federated data science platform that does not only allow for sharing data science pipelines and their (meta) data but also provides methods for efficient search and, in the ideal case, even allows for combining and defining pipelines across platforms in a federated manner.","SIGMOD record",2021,"Essam Mansour,Kavitha Srinivas,K. Hose",4,42,0,"https://www.semanticscholar.org/paper/7fba3100768fa3aac0fbf961d5e894b2f629e6e6"
"eeadabea580953c14bb00ca99b41ee9b2cef6300",1,"Energy-bounded Learning for Robust Models of Code","This paper proposes the use of an energy-bounded learning objective function to assign a higher score to in-distribution samples and a lower score to out-of-distributed samples in order to incorporate such out- of-dist distribution samples into the training process of source code models.","ArXiv",2021,"Nghi D. Q. Bui,Yijun Yu",1,70,0,"https://www.semanticscholar.org/paper/eeadabea580953c14bb00ca99b41ee9b2cef6300"
"d4f16dae4ab1d21db3c0b0bd7b54f4b62e2d1b85",1,"The Effectiveness of Transformer Models for Analyzing Low-Level Programs","It is shown that transformer models can translate C to LLVM-IR with high accuracy, by training on a parallel corpus of functions extract from 1 million compilable, open-sourced C programs (AnghaBench) and its corresponding LL VM-IR after compiling with Clang.","",2022,"Zifan Carl,William S. Moses",0,39,0,"https://www.semanticscholar.org/paper/d4f16dae4ab1d21db3c0b0bd7b54f4b62e2d1b85"
"7d500d6bd3ae49fa3acb213fd25d5b11566e64fd",1,"Labeling-Free Comparison Testing of Deep Learning Models","A labeling-free comparison testing approach to overcome the limitations of labeling effort and sampling randomness and learns a Bayesian model to infer the models’ specialty only based on predicted labels.","ArXiv",2022,"Yuejun Guo,Qiang Hu,Maxime Cordy,Xiaofei Xie,Mike Papadakis,Yves Le Traon",0,37,0,"https://www.semanticscholar.org/paper/7d500d6bd3ae49fa3acb213fd25d5b11566e64fd"
"b2c0e903b79835b6ee8fd553c2213ea8abbf7864",1,"Senatus - A Fast and Accurate Code-to-Code Recommendation Engine","De-Skew LSH a new locality sensitive hashing (LSH) algorithm that indexes the data for fast (sub-linear time) retrieval while also counteracting the skewness in the snippet length distribution using novel abstract syntax tree-based feature scoring and selection algorithms is developed.","IEEE Working Conference on Mining Software Repositories",2021,"Fran Silavong,S. Moran,Antonios Georgiadis,Rohan Saphal,R. Otter",0,56,0,"https://www.semanticscholar.org/paper/b2c0e903b79835b6ee8fd553c2213ea8abbf7864"
"9f0852ce9338c00135fe39426d893a36a289e5d5",1,"GraphCode2Vec: Generic Code Embedding via Lexical and Program Dependence Analyses","Graphcode2vec, the first self-supervised pre-training approach which produces task-agnostic embedding of lexical and program dependence features, is proposed and demonstrated to be more effective than both generic and task-specific learning-based baselines.","IEEE Working Conference on Mining Software Repositories",2021,"Wei Ma,Mengjie Zhao,Ezekiel O. Soremekun,Q. Hu,Jie Zhang,Mike Papadakis,Maxime Cordy,Xiaofei Xie,Yves Le Traon",7,78,0,"https://www.semanticscholar.org/paper/9f0852ce9338c00135fe39426d893a36a289e5d5"
"7438626a757c5442b9c0fb37b54ec0fe7e1889c3",1,"Better Together? An Evaluation of AI-Supported Code Translation","This work motivates the need for intelligent user interfaces that help software engineers effectively work with generative code models in order to understand and evaluate their outputs and achieve superior outcomes to working alone.","International Conference on Intelligent User Interfaces",2022,"Justin D. Weisz,Michael J. Muller,Steven I. Ross,Fernando Martinez,Stephanie Houde,Mayank Agarwal,Kartik Talamadupula,John T. Richards",7,103,0,"https://www.semanticscholar.org/paper/7438626a757c5442b9c0fb37b54ec0fe7e1889c3"
"4b27f18bff43d605805c92696a979714ced0b805",1,"UniXcoder: Unified Cross-Modal Pre-training for Code Representation","Results show that the model achieves state-of-the-art performance on most tasks and analysis reveals that comment and AST can both enhance UniXcoder.","Annual Meeting of the Association for Computational Linguistics",2022,"Daya Guo,Shuai Lu,Nan Duan,Yanlin Wang,Ming Zhou,Jian Yin",42,36,10,"https://www.semanticscholar.org/paper/4b27f18bff43d605805c92696a979714ced0b805"
"8c8bf30828bc789be679f29ee08cc6cdebd36600",1,"Characterizing and Understanding the Behavior of Quantized Models for Reliable Deployment","This study considers 4 datasets spanning from image to text, 8 DNN architectures including feed-forward neural networks and recurrent neural networks, and 42 shifted sets with both synthetic and natural distribution shifts and reveals that data with distribution shifts happen more disagreements than without.","ArXiv",2022,"Qiang Hu,Yuejun Guo,Maxime Cordy,Xiaofei Xie,Wei Ma,Mike Papadakis,Yves Le Traon",1,64,0,"https://www.semanticscholar.org/paper/8c8bf30828bc789be679f29ee08cc6cdebd36600"
"5e5a7f8423e0b990bbe1c85a999da86f16ee68a3",1,"LaF: Labeling-Free Model Selection for Automated Deep Neural Network Reusing","A labeling-free (LaF) model selection approach to overcome the limitations of labeling efforts for automated model reusing and statistically learn a Bayesian model to infer the models’ specialty only based on predicted labels.","",2022,"Qiang Hu,Yuejun Guo,Maxime Cordy,Xiaofei Xie,Mike Papadakis,Yves Le Traon",0,46,0,"https://www.semanticscholar.org/paper/5e5a7f8423e0b990bbe1c85a999da86f16ee68a3"
"1413acc991434ee36248b282b4cedac77ade1737",1,"Evaluating few shot and Contrastive learning Methods for Code Clone Detection","This research assesses the generalizability of the state of the art models for CCD in few shot settings and employs Model Agnostic Meta-learning (MAML), where the model learns a meta-learner capable of extracting transferable knowledge from the train set so that the model can be fine-tuned using a few samples.","ArXiv",2022,"Mohamad Khajezade,F. Fard,M. Shehata",1,49,0,"https://www.semanticscholar.org/paper/1413acc991434ee36248b282b4cedac77ade1737"
"c765091cb8bec8448669351f3662101c307c03c4",1,"Zero-Shot Program Representation Learning","Zecoler is a zero-shot learning approach for code representations built upon a pre-trained programming language model that significantly outperforms baseline models in both zero- shot and few-shot settings.","IEEE International Conference on Program Comprehension",2022,"Nan Cui,Yuze Jiang,Xiaodong Gu,Beijun Shen",0,43,0,"https://www.semanticscholar.org/paper/c765091cb8bec8448669351f3662101c307c03c4"
"80b2b006ed2f26ec3ddc91e303dc9861fb456a26",1,"On The Cross-Modal Transfer from Natural Language to Code through Adapter Modules","Studying the bimodality of adapters for two tasks of cloze test and code clone detection, compared to their benchmarks from the CodeXGLUE platform confirms the success of the adapters in knowledge transfer to software engineering, which sometimes are in par with or exceed the results of a PTLM trained on source code while being more efficient in terms of the number of parameters, memory usage, and inference time.","IEEE International Conference on Program Comprehension",2022,"Divyam Goel,Raman Grover,F. Fard",0,37,0,"https://www.semanticscholar.org/paper/80b2b006ed2f26ec3ddc91e303dc9861fb456a26"
"c1ddf0006e1aa0d5551e1ba1ad734ec0ecf27fd0",1,"CV4Code: Sourcecode Understanding via Visual Code Representations","This work presents CV4Code, a compact and effective computer vision method for sourcecode understanding that leverages the contextual and the structural information available from the code snippet by treating each snippet as a two-dimensional image, which naturally encodes the context and retains the underlying structural information through an explicit spatial representation.","ArXiv",2022,"Ruibo Shi,Lili Tao,Rohan Saphal,Fran Silavong,S. Moran",0,30,0,"https://www.semanticscholar.org/paper/c1ddf0006e1aa0d5551e1ba1ad734ec0ecf27fd0"
"6fb1a9d5278b85dfbbb0be3731d480ab36a0372e",1,"CodeAttack: Code-based Adversarial Attacks for Pre-Trained Programming Language Models","This work proposes, CodeAttack, a simple yet effective black- box attack model that uses code structure to generate effective, efﬁcient, and imperceptible adversarial code samples and demonstrates the vulnerabilities of the state-of-the-art PL models to code-species adversarial attacks.","ArXiv",2022,"Akshita Jha,C. Reddy",3,41,0,"https://www.semanticscholar.org/paper/6fb1a9d5278b85dfbbb0be3731d480ab36a0372e"
"5514b87e34db2b34bd9a9b995894243f91435efc",1,"Learning to Represent Programs with Code Hierarchies","A method for representing code as a hierarchy ( Code Hierarchy), in which different code components are represented separately at various levels of granular- ity, and a novel pretraining objective called Miss- ing Subtree Prediction to complement this method.","ArXiv",2022,"Minh Nguyen,Nghi D. Q. Bui",0,66,0,"https://www.semanticscholar.org/paper/5514b87e34db2b34bd9a9b995894243f91435efc"
"c6e6cb19e7055f3d0616c3314a85b0914132ae40",1,"CodeS: A Distribution Shift Benchmark Dataset for Source Code Learning","The proposed CodeS is a distribution shift benchmark dataset for source code learning that supports 2 programming languages and 5 types of code distribution shifts, and is the best of its knowledge to be the first to propose the code representation-based (token and CST) distribution shifts.","ArXiv",2022,"Qiang Hu,Yuejun Guo,Xiaofei Xie,Maxime Cordy,L. Ma,Mike Papadakis,Yves Le Traon",0,19,0,"https://www.semanticscholar.org/paper/c6e6cb19e7055f3d0616c3314a85b0914132ae40"
"73b4f4c31852273b38868f2bd362abeafce40232",1,"CodeS: Towards Code Model Generalization Under Distribution Shift","This paper initiates to propose CodeS, a distribution shift benchmark dataset, for source code learning, which supports two programming languages and five shift types and reveals that out-of-distribution detectors from other domains do not generalize to source code, all code classification models suffer from distribution shifts.","",2022,"Qiang Hu,Yuejun Guo,Xiaofei Xie,Maxime Cordy,Lei Ma,Mike Papadakis,Yves Le Traon",0,28,0,"https://www.semanticscholar.org/paper/73b4f4c31852273b38868f2bd362abeafce40232"
"62851a515ea0ee3a547d94e8a493d978c22d0be9",1,"Multilingual Code Snippets Training for Program Translation","CoST is introduced, a new multilingual Code Snippet Translation dataset that contains parallel data from 7 commonly used programming languages and outperforms the baselines on both snippet-level and program-level translation, and achieves state-of-the-art performance on CodeXGLUE translation task.","AAAI Conference on Artificial Intelligence",2022,"Ming-Yuan Zhu,Karthik Suresh,C. Reddy",8,27,0,"https://www.semanticscholar.org/paper/62851a515ea0ee3a547d94e8a493d978c22d0be9"
"8bf89cf8f18f08a43fd3d058687987666996b995",1,"PST: Measuring Skill Proficiency in Programming Exercise Process via Programming Skill Tracing","A model that measures skill proficiency in programming exercise process named Programming Skill Tracing (PST) is proposed, which divided programming skill into programming knowledge and coding ability to get more fine-grained assessment.","Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",2022,"Ruixin Li,Yu Yin,Le Dai,Shuanghong Shen,Xin Lin,Yu Su,Enhong Chen",0,30,0,"https://www.semanticscholar.org/paper/8bf89cf8f18f08a43fd3d058687987666996b995"
"1444ed03083523a4413d9f15f2200007447771db",1,"A Library for Representing Python Programs as Graphs for Machine Learning","An open source Python library python_graphs is introduced that applies static analysis to construct graph representations of Python programs suitable for training machine learning models.","ArXiv",2022,"David Bieber,Kensen Shi,Petros Maniatis,Charles Sutton,V. Hellendoorn,Daniel D. Johnson,Daniel Tarlow",1,45,1,"https://www.semanticscholar.org/paper/1444ed03083523a4413d9f15f2200007447771db"
"da78bab10019e530a93584f60b9224e353d90f2a",1,"A Tree-structured Transformer for Program Representation Learning","The extensive experimental results show that the Tree-Transformer outperforms existing tree-based or graph-based neural networks in program-related tasks with tree-level and node-level prediction tasks, indicating that Tree- transformer performs well on learning both tree- level and nodes-level representations.","ArXiv",2022,"Wenhan Wang,Kechi Zhang,Ge Li,Shangqing Liu,Zhi Jin,Yang Liu",0,25,0,"https://www.semanticscholar.org/paper/da78bab10019e530a93584f60b9224e353d90f2a"
"89b58765614bd6c52baca0006d67f64985d2204e",1,"Topical: Learning Repository Embeddings from Source Code using Attention","Topical a deep neural network to generate repository level embeddings of publicly available GitHub code repositories directly from source code is introduced and it is shown that Topical’s attention mechanism out- performs naive aggregation methods when computing repository-level representations from script-level representation generated by existing methods.","ArXiv",2022,"Agathe Lherondelle,Yash Satsangi,Fran Silavong,Shaltiel Eloul,S. Moran",0,53,0,"https://www.semanticscholar.org/paper/89b58765614bd6c52baca0006d67f64985d2204e"
"939b4b1ff5a21108bb2f8c81117f1d5b230180a9",1,"Extreme Multi-Domain, Multi-Task Learning With Unified Text-to-Text Transfer Transformers","It is shown that while negative knowledge transfer and catastrophic forgetting are still considerable challenges for all the models, the GPT-style joint pretraining + joint ﬁnetuning strategy showed the most promise in multi-domain, multi-task learning as it performs well across all four tasks while still keeping its multi- domain knowledge.","ArXiv",2022,"Adebayo Oshingbesan,Courage Ekoh,Germann Atakpa,Yonah Byaruagaba",0,30,0,"https://www.semanticscholar.org/paper/939b4b1ff5a21108bb2f8c81117f1d5b230180a9"
"05f225085154e4326af07f7c8f273156f132aa70",1,"Geração Automática de Benchmarks para Compilação Preditiva","","Brazilian Symposium on Programming Languages",2022,"Cecília Kind,João Coelho,Bruno Kind,F. Pereira",0,32,0,"https://www.semanticscholar.org/paper/05f225085154e4326af07f7c8f273156f132aa70"
"8b58130ecb302a2f0e78e9ffb7115cb4906cb966",1,"Towards Robust Models of Code via Energy-Based Learning on Auxiliary Datasets","This work proposes to use an auxiliary dataset (out-of-distribution) such that, when trained together with the main dataset, they will enhance the model’s robustness and demonstrate a greater robustness for existing source code models to become more accurate at recognizing OOD data while being more resistant to adversarial attacks at the same time.","International Conference on Automated Software Engineering",2022,"Nghi D. Q. Bui,Yijun Yu",0,24,0,"https://www.semanticscholar.org/paper/8b58130ecb302a2f0e78e9ffb7115cb4906cb966"
"00aacec39159bcd92a412aa314b376c3378c49cb",1,"Improvement of Vulnerable Code Dataset Based on Program Equivalence Transformation","A generator of complex code vulnerability dataset based on program equivalence transformation is proposed, which improves the complexity of program structure and code size while preserving the labels of the original case.","Journal of Physics: Conference Series",2022,"Dejiang Jing",0,15,0,"https://www.semanticscholar.org/paper/00aacec39159bcd92a412aa314b376c3378c49cb"
"e052fd3e1480a501c3145f53ad5ddb4526efbb21",1,"Source Code Preprocessing Method Analysis in Unit Test Code Classification","The results show that the preprocessing methods and their combinations used significantly influences the performance of the machine learning model.","2022 1st International Conference on Software Engineering and Information Technology (ICoSEIT)",2022,"A. Rasyid,M. J. Alibasa,N. Selviandro,Y. Priyadi",0,18,0,"https://www.semanticscholar.org/paper/e052fd3e1480a501c3145f53ad5ddb4526efbb21"
"9431181f8115a2360621df5ed76e1a23b88e3b2f",1,"Evaluating Human-Language Model Interaction","A framework, Human-AI Language-based Interaction Evaluation (H-LINE), is developed that expands non-interactive evaluation along three dimensions, capturing the interactive process, not only the output of the system, and notions of preference beyond quality.","ArXiv",2022,"Mina Lee,Megha Srivastava,Amelia Hardy,John Thickstun,Esin Durmus,Ashwin Paranjape,Ines Gerard-Ursin,Xiang Lisa Li,Faisal Ladhak,Frieda Rong,Rose E. Wang,Minae Kwon,Joon Sung Park,Hancheng Cao,Tony Lee,Rishi Bommasani,Michael Bernstein,Percy Liang",2,168,0,"https://www.semanticscholar.org/paper/9431181f8115a2360621df5ed76e1a23b88e3b2f"
"1d74875aa4f415cb2c60b17fd1eb3e4ae543bfe1",1,"Keeping Pace with Ever-Increasing Data: Towards Continual Learning of Code Intelligence Models","This paper proposes REPEAT, a novel method for continual learning of code intelligence models that addresses the catastrophic forgetting problem with representative exemplars replay and adaptive parameter regularization.","ArXiv",2023,"Shuzheng Gao,Hongyu Zhang,Cuiyun Gao,Chaozheng Wang",0,62,0,"https://www.semanticscholar.org/paper/1d74875aa4f415cb2c60b17fd1eb3e4ae543bfe1"
"f5eb526492798dd7a53fe78f28431f5f489192da",1,"A Survey on Semantic Parsing for Machine Programming","An overview of the growing body of research in natural language semantic parsing techniques and extracting lessons from the evolution of semantic parsing is provided, drawing parallels between modern efforts in neural semantic parsing and program synthesis.","",2021,"Celine Lee,Justin Emile Gottschlich,D. Roth",0,89,0,"https://www.semanticscholar.org/paper/f5eb526492798dd7a53fe78f28431f5f489192da"
"6a1b25f7a67395ad1e676027322913acbb0a0635",1,"CUAD: An Expert-Annotated NLP Dataset for Legal Contract Review","It is found that Transformer models have nascent performance, but that this performance is strongly influenced by model design and training dataset size, so there is still substantial room for improvement.","NeurIPS Datasets and Benchmarks",2021,"Dan Hendrycks,Collin Burns,Anya Chen,Spencer Ball",42,26,10,"https://www.semanticscholar.org/paper/6a1b25f7a67395ad1e676027322913acbb0a0635"
"04ff95e0edc3759fc5d18a1b929b3ccf79b032b2",1,"Deconstructing Distributions: A Pointwise Framework of Learning","This work studies a point’s profile : the relationship between models’ average performance on the test distribution and their pointwise performance on this individual point, and finds that profiles can yield new insights into the structure of both models and data—in and out-of-distribution.","ArXiv",2022,"Gal Kaplun,Nikhil Ghosh,S. Garg,B. Barak,Preetum Nakkiran",6,90,0,"https://www.semanticscholar.org/paper/04ff95e0edc3759fc5d18a1b929b3ccf79b032b2"
"1c1ca2392155ddf30408a442e6b504b5d60d4f2a",1,"When to Make Exceptions: Exploring Language Models as Accounts of Human Moral Judgment","This paper presents a novel challenge set consisting of rule-breaking question answering (RBQA) of cases that involve potentially permissible rule- Breaking – inspired by recent moral psychology studies and proposes a novel moral chain of thought prompting strategy that combines the strengths of LLMs with theories of moral reasoning developed in cognitive science to predict human moral judgments.","ArXiv",2022,"Zhijing Jin,Sydney Levine,Fernando Gonzalez,Ojasv Kamal,Maarten Sap,Mrinmaya Sachan,Rada Mihalcea,J. Tenenbaum,B. Schölkopf",1,78,0,"https://www.semanticscholar.org/paper/1c1ca2392155ddf30408a442e6b504b5d60d4f2a"
"a4c216d2ce9dd245c84771acc574722055967fd6",1,"Enhancing Code Classification by Mixup-Based Data Augmentation","A Mixup-based data augmentation approach, MixCode, to enhance the source code classiﬁcation task, which employs multiple code refactoring methods to generate label-consistent code data.","ArXiv",2022,"Zeming Dong,Qiang Hu,Yuejun Guo,Maxime Cordy,Mike Papadakis,Yves Le Traon,Jianjun Zhao",0,79,0,"https://www.semanticscholar.org/paper/a4c216d2ce9dd245c84771acc574722055967fd6"
"cb123f1afd67fb8bae15dc876709c842b626c49c",1,"SimSCOOD: Systematic Analysis of Out-of-Distribution Behavior of Source Code Models","This work contributes the first systematic approach that simulates various OOD scenarios along different dimensions of data properties and investigates the model behaviors in such scenarios and provides insights and sheds light for future research in terms of generalization, ro-bustness, and inductive biases of source code models.","ArXiv",2022,"Hossein Hajipour,Ning Yu,Cristian-Alexandru Staicu,Mario Fritz",0,43,0,"https://www.semanticscholar.org/paper/cb123f1afd67fb8bae15dc876709c842b626c49c"
"45a37f351bb275d22354b712c78df65715a37cc5",1,"CrystalBLEU: Precisely and Efficiently Measuring the Similarity of Code","The metric preserves the desirable properties of BLEU, such as being language-agnostic, able to handle incomplete or partially incorrect code, and efficient, while reducing the noise caused by trivially shared n-grams.","International Conference on Automated Software Engineering",2022,"A. Eghbali,Michael Pradel",0,55,0,"https://www.semanticscholar.org/paper/45a37f351bb275d22354b712c78df65715a37cc5"
"cdec75f901a93c75ee5386a98abbe44746286e80",1,"Delivering Fairness in Human Resources AI: Mutual Information to the Rescue","This paper proposes to minimize the MI between a candidate’s name and a latent representation of their CV or short biography to mitigate bias from sensitive variables without requiring the collection of these variables.","AACL",2022,"L'eo Hemamou,Willi Coleman",0,46,0,"https://www.semanticscholar.org/paper/cdec75f901a93c75ee5386a98abbe44746286e80"
"82d9f1db6db43cb61fe4b0b26a489a2e72628675",1,"A Test for Evaluating Performance in Human-Computer Systems","This work shows how to perform a Turing test for comparing computer performance to that of humans using the ratio of means as a measure of effect size, and shows that 50 human non- programmers using GPT-3 can perform the task about as well as–and less expensively than–the human programmers.","ArXiv",2022,"Andres Campero,Michelle Vaccaro,Jaeyoon Song,Haoran Wen,Abdullah Almaatouq,T. Malone",2,79,0,"https://www.semanticscholar.org/paper/82d9f1db6db43cb61fe4b0b26a489a2e72628675"
"2cfd0dacfa267a64a23392332c358d4e3ec6fbd4",1,"The COVID That Wasn’t: Counterfactual Journalism Using GPT","","LATECHCLFL",2022,"S. Hamilton,Andrew Piper",1,33,0,"https://www.semanticscholar.org/paper/2cfd0dacfa267a64a23392332c358d4e3ec6fbd4"
"8a9e437b2e2d813b402ac560c852ef0ab2f1cd3c",1,"Recognizing Families In the Wild (RFIW): The 4th Edition","The purpose of this paper is to describe the 2020 RFIW challenge, end-to-end, along with forecasts in promising future directions.","IEEE International Conference on Automatic Face & Gesture Recognition",2020,"Joseph P. Robinson,Yu Yin,Zaid Khan,Ming Shao,Siyu Xia,Michael Stopa,Samson Timoner,Matthew A. Turk,R. Chellappa,Y. Fu",13,64,3,"https://www.semanticscholar.org/paper/8a9e437b2e2d813b402ac560c852ef0ab2f1cd3c"
"4ff14a0580f3b36a9564ec18a51d2ce1d4eafebc",1,"Learning Methods for Solving Astronomy Course Problems","This work trains a specialized machine learning model to solve university undergraduate level Introduction to Astronomy course problems using a Transformer trained on both text and code, namely OpenAI Codex, and introduces the concept of turning questions into programming tasks.","",2021,"Avi Shporer,Brandon Kates",2,34,0,"https://www.semanticscholar.org/paper/4ff14a0580f3b36a9564ec18a51d2ce1d4eafebc"
"b874faa9c6cfb5d7e87e3d79650007ade1394958",1,"Creating new Program Proofs by Combining Abductive and Deductive Reasoning","The abduction system that creates new formal specifications by leveraging a small set of inspiring artefacts to augment a subset of candidate problems by employing knowledge graphs to represent the raw data, discovering latent similarities between graphs using a graph-matching process.","International Conference on Innovative Computing and Cloud Computing",2021,"Kuruvilla George Aiyankovil,D. O'Donoghue,Rosemary Monahan",1,13,0,"https://www.semanticscholar.org/paper/b874faa9c6cfb5d7e87e3d79650007ade1394958"
"d66e80224cda0c1d5a4c1be3798df6a6bfe3713c",1,"GPT-3 for Few-Shot Dialogue State Tracking","It is found that natural language instructions in the prompt have little impact on performance, larger language models do not always induce higher downstream performance and that GPT-3 is highly sensitive to the order and number of the in-context examples.","",2021,"Nicholas Pezzotti",0,51,0,"https://www.semanticscholar.org/paper/d66e80224cda0c1d5a4c1be3798df6a6bfe3713c"
"a3c2b81d8bb5ac69771ed7830d009310d98ac9dc",1,"A First Approach to AGI-based Robot Task Planning","An existing proto-Artificial General Intelligence system, namely OpenCog, is extended and given the ability to effectively solve manipulation tasks whose domains contain four actions: pick, place, stack, and unstack.","AIRO@AI*IA",2021,"Michele Thiella,E. Tosello,E. Pagello",0,23,0,"https://www.semanticscholar.org/paper/a3c2b81d8bb5ac69771ed7830d009310d98ac9dc"
"007153d786caa906255fba2ca265fd67994f8b44",1,"Tracking Blobs in the Turbulent Edge Plasma of Tokamak Fusion Reactors","This work tracks the shape and the position of blobs in high frequency video data obtained from Gas Puff Imaging (GPI) diagnostics, by training a mask R-CNN model on synthetic data and testing on both synthetic and real data.","ArXiv",2021,"W. Han,RA Pietersen,Rafael Villamor-Lora,Matthew Beveridge,N. Offeddu,T. Golfinopoulos,C. Theiler,J. Terry,E. Marmar,Iddo Drori",0,13,0,"https://www.semanticscholar.org/paper/007153d786caa906255fba2ca265fd67994f8b44"
"4da830b6d84e117cb147ff71f205e71500ebbbb1",1,"Machines and Influence","It is suggested that better regulation and management of information systems can more optimally offset the risks of AI and utilise the emerging capabilities which these systems have to offer to policymakers and political institutions across the world.","",2021,"Shashank Yadav",0,128,0,"https://www.semanticscholar.org/paper/4da830b6d84e117cb147ff71f205e71500ebbbb1"
"021bbcefc993c389bad6c1daefd8ff92d0fc2441",1,"Contrastive Code Representation Learning","Contracode is proposed: a contrastive pre-training task that learns code functionality, not form, and improves summarization and TypeScript type inference accuracy by 2 to 13 percentage points over competitive baselines.","Conference on Empirical Methods in Natural Language Processing",2020,"Paras Jain,Ajay Jain,Tianjun Zhang,P. Abbeel,Joseph Gonzalez,I. Stoica",65,94,13,"https://www.semanticscholar.org/paper/021bbcefc993c389bad6c1daefd8ff92d0fc2441"
"09279dc8018a8131e11d527cebb06d0a43c67cff",1,"Creativity and Machine Learning: A Survey","An overview of the history and the state of the art of computational creativity theories, key machine learning techniques (including generative deep learning), and corresponding automatic evaluation methods is presented.","ArXiv",2021,"Giorgio Franceschelli,Mirco Musolesi",13,285,1,"https://www.semanticscholar.org/paper/09279dc8018a8131e11d527cebb06d0a43c67cff"
"26450917d41c828b470ec8818d49f59516a5b9c0",1,"Towards Universality in Multilingual Text Rewriting","This work takes the first steps towards building a universal rewriter: a model capable of rewriting text in any language to exhibit a wide variety of attributes, including styles and languages, while preserving as much of the original semantics as possible.","ArXiv",2021,"Xavier García,Noah Constant,Mandy Guo,Orhan Firat",5,36,0,"https://www.semanticscholar.org/paper/26450917d41c828b470ec8818d49f59516a5b9c0"
"70087677fd1a6309829b42968934575d05a95f92",1,"What do pre-trained code models know about code?","Four probing tasks are constructed (probing for surface-level, syntactic, structural, and semantic information) for pre-trained code models to identify whether models are deficient in (understanding) certain code properties, characterize different model layers, and get insight into the model sample-efficiency.","International Conference on Automated Software Engineering",2021,"Anjan Karmakar,R. Robbes",22,34,2,"https://www.semanticscholar.org/paper/70087677fd1a6309829b42968934575d05a95f92"
"a30f912f8c5e2a2bfb06351d4578e1ba3fa37896",1,"CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation","Comprehensive experiments show that CodeT5 significantly outperforms prior methods on understanding tasks such as code defect detection and clone detection, and generation tasks across various directions including PL-NL, NL-PL, and PL-PL.","Conference on Empirical Methods in Natural Language Processing",2021,"Yue Wang,Weishi Wang,Shafiq R. Joty,S. Hoi",199,40,79,"https://www.semanticscholar.org/paper/a30f912f8c5e2a2bfb06351d4578e1ba3fa37896"
"b8b21c2ddcd7d1c23d7ccfceabb63cb1a05bcfca",1,"HYDRA - Hyper Dependency Representation Attentions","This paper proposes HYDRA heads, lightweight pretrained linguistic self-attention heads to inject knowledge into transformer models without pretraining them again, and empirically verify the framework on benchmark datasets to show the contribution of linguistic knowledge to a transformer model.","ArXiv",2021,"Nguyen Ha Thanh,Vu D. Tran,Binh Dang,Minh Q. Bui,Minh Le Nguyen,Le-Minh Nguyen",0,24,0,"https://www.semanticscholar.org/paper/b8b21c2ddcd7d1c23d7ccfceabb63cb1a05bcfca"
"24e775b20adf21e9b5b95c6a9b7a5c164d055849",1,"M6-10T: A Sharing-Delinking Paradigm for Efficient Multi-Trillion Parameter Pretraining","This paper demonstrates a practice of pretraining unprecedented 10-trillion-parameter model, an order of magnitude larger than the state-of-the-art, on solely 512 GPUs within 10 days, and provides a technique, Granular CPU offloading, to manage CPU memory for training large model and maintain high GPU utilities.","ArXiv",2021,"Junyang Lin,An Yang,Jinze Bai,Chang Zhou,Le Jiang,Xianyan Jia,Ang Wang,J. Zhang,Yong Li,Wei Lin,Jingren Zhou,Hongxia Yang",19,52,0,"https://www.semanticscholar.org/paper/24e775b20adf21e9b5b95c6a9b7a5c164d055849"
"360e0197378799d890f473893cc0c773b8182b4e",1,"Searching for Replacement Classes","This work introduces ClassFinder, a system which given a query class Q, and a search corpus S, returns a ranked subset of classes that can replace Q and its functionality, and leverages the complementary strengths of a distributed embeddingsbased search and type-based analysis.","ArXiv",2021,"Malavika Samak,J. Cambronero,M. Rinard",1,36,0,"https://www.semanticscholar.org/paper/360e0197378799d890f473893cc0c773b8182b4e"
"9991bb2eb7e7d7e9d831e257ae77ba2eaeaba3dc",1,"Applying quantum approximate optimization to the heterogeneous vehicle routing problem","","",2021,"David Fitzek,Toheed Ghandriz,L. Laine,M. Granath,A. F. Kockum",7,177,0,"https://www.semanticscholar.org/paper/9991bb2eb7e7d7e9d831e257ae77ba2eaeaba3dc"
"21bc4ead8ea415579ab40e437fcbc274929f17c8",1,"Solving the Families In the Wild Kinship Verification Challenge by Program Synthesis","This work uses Codex to generate model variants, and also demonstrates its ability to generate entire running programs for kinship verification tasks of specific relationships, among the top 3 winning entries in the competition.","IEEE International Conference on Automatic Face & Gesture Recognition",2021,"Junyi Huang,M. Strome,I. Jenkins,Parker Williams,Bo Feng,Yaning Wang,Roman Wang,Vaibhav Bagri,Newman Cheng,Iddo Drori",1,25,0,"https://www.semanticscholar.org/paper/21bc4ead8ea415579ab40e437fcbc274929f17c8"
"8091e51ebbcd2424a1c5b50c036bae5295090525",1,"Top 3 in FG 2021 Families In the Wild Kinship Verification Challenge","This work demonstrates high quality kinship verification by participating in the 2021 Recognizing Families in the Wild challenge which provides the largest publicly available dataset in the field.","ArXiv",2021,"Junyi Huang,M. Strome,Ian Jenkins,Parker Williams,Bo Feng,Yaning Wang,Roman Wang,Vaibhav Bagri,Newman Cheng,Iddo Drori",3,11,0,"https://www.semanticscholar.org/paper/8091e51ebbcd2424a1c5b50c036bae5295090525"
"6a269b1abccdbf57e79b3f115a97bff14b435ad9",1,"Automated Support for Unit Test Generation: A Tutorial Book Chapter","This chapter introduces two algorithms that can generate pytest-formatted unit tests, tuned towards coverage of source code statements, and introduces the concept of search-based unit test generation.","ArXiv",2021,"Afonso Fontes,Gregory Gay,F. G. O. Neto,R. Feldt",1,32,0,"https://www.semanticscholar.org/paper/6a269b1abccdbf57e79b3f115a97bff14b435ad9"
"9f260bdd4030af5297a9c1cbb817c75701ac8c83",1,"The 5th Recognizing Families in the Wild Data Challenge: Predicting Kinship from Faces","Submissions for this year's RFIW are summarized, and the results for kinship verification, tri-subject verification, and family member search and retrieval are reviewed.","IEEE International Conference on Automatic Face & Gesture Recognition",2021,"Joseph P. Robinson,Can Qin,Ming Shao,Matthew A. Turk,R. Chellappa,Y. Fu",2,54,0,"https://www.semanticscholar.org/paper/9f260bdd4030af5297a9c1cbb817c75701ac8c83"
"c23d9d44e8bc68408cea9f305d1f24d915bc0d0d",1,"Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey","A survey of recent work that uses large, pre-trained transformer-based language models to solve NLP tasks via pre-training then fine-tuning, prompting, or text generation approaches.","ArXiv",2021,"Bonan Min,Hayley H. Ross,Elior Sulem,Amir Pouran Ben Veyseh,Thien Huu Nguyen,Oscar Sainz,Eneko Agirre,Ilana Heinz,D. Roth",39,322,2,"https://www.semanticscholar.org/paper/c23d9d44e8bc68408cea9f305d1f24d915bc0d0d"
"1444536496d8064f33e10b38b5820fecfab5b367",1,"Automatic Program Repair with OpenAI's Codex: Evaluating QuixBugs","This work investigates whether Codex is able to localize and fix bugs, a task of central interest in the field of automated program repair, and finds that, despite not being trained for APR, Codex is surprisingly effective, and competitive with recent state of the art techniques.","ArXiv",2021,"Julian Aron Prenner,R. Robbes",14,22,1,"https://www.semanticscholar.org/paper/1444536496d8064f33e10b38b5820fecfab5b367"
"4e40595d6ecba027cebb4f2e3b43ae44bcf51daf",1,"Solving Linear Algebra by Program Synthesis","This work uses OpenAI Codex with zero-shot learning to synthesize code from questions and quantifies the difference between the original question text and the transformed question text that yields a correct answer.","ArXiv",2021,"Iddo Drori,Nakul Verma",10,17,0,"https://www.semanticscholar.org/paper/4e40595d6ecba027cebb4f2e3b43ae44bcf51daf"
"f7987fa2aadc0b368c185dc4d2fdb1337a202c32",1,"Solving Probability and Statistics Problems by Program Synthesis","This work is the first to introduce a new dataset of university-level probability and statistics problems and solve these problems in a scalable fashion using the program synthesis capabilities of large language models.","ArXiv",2021,"Leonard Tang,Elizabeth Ke,Nikhil Singh,Nakul Verma,Iddo Drori",9,14,1,"https://www.semanticscholar.org/paper/f7987fa2aadc0b368c185dc4d2fdb1337a202c32"
"04db9b694280134f09af5fa787a306907edba29d",1,"How much do language models copy from their training data? Evaluating linguistic novelty in text generation using RAVEN","AVEN, a suite of analyses for assessing the novelty of generated text, focusing on sequential structure (n-grams) and syntactic structure, is introduced, showing that GPT-2's novel text is usually well-formed morphologically and syntactically but has reasonably frequent semantic issues.","ArXiv",2021,"R. Thomas McCoy,P. Smolensky,Tal Linzen,Jianfeng Gao,Asli Celikyilmaz",18,81,2,"https://www.semanticscholar.org/paper/04db9b694280134f09af5fa787a306907edba29d"
"cecc913290736a5a368642c5b59a130eddd1fa7b",1,"Can Pre-trained Language Models be Used to Resolve Textual and Semantic Merge Conflicts?","The feasibility of automatically repairing merge conflicts (both textual and semantic) using k-shot learning with large neural language models (LM) such as GPT-3 is explored and the results are mixed.","ArXiv",2021,"Jialu Zhang,Todd Mytkowicz,Mike Kaufman,R. Piskac,Shuvendu K. Lahiri",0,22,0,"https://www.semanticscholar.org/paper/cecc913290736a5a368642c5b59a130eddd1fa7b"
"21ab011a3adccbd912aea58f76b84b7873c41df3",1,"Machines&Influence: An Information Systems Lens","","",2021,"Shashank Yadav",1,130,0,"https://www.semanticscholar.org/paper/21ab011a3adccbd912aea58f76b84b7873c41df3"
"827a67bbb96c8ed34c0f79e2ea811c5b53a6896b",1,"Controllable Response Generation for Assistive Use-cases","This study shows that keyword-control on end-to-end response generation models is powerful and can enable and empower users with degenerative disorders to carry out their dayto-day communication.","ArXiv",2021,"Shachi H. Kumar,Hsuan Su,R. Manuvinakurike,Saurav Sahay,L. Nachman",0,56,0,"https://www.semanticscholar.org/paper/827a67bbb96c8ed34c0f79e2ea811c5b53a6896b"
"ee042a3e299a32c413532e64603de8d3ddb6aa87",1,"Automap: Towards Ergonomic Automated Parallelism for ML Models","This work presents the prototype of an automated partitioner that seamlessly integrates into existing compilers and existing user workflows and enables SPMD-style parallelism that encompasses data parallelism and parameter/activation sharding.","ArXiv",2021,"Michael Schaarschmidt,Dominik Grewe,Dimitrios Vytiniotis,Adam Paszke,G. Schmid,Tamara Norman,James Molloy,Jonathan Godwin,Norman A. Rink,Vinod Nair,Dan Belov",6,36,0,"https://www.semanticscholar.org/paper/ee042a3e299a32c413532e64603de8d3ddb6aa87"
"6ccc0ca964ddab19705e4832758e6a2447325348",1,"End to End Software Engineering Research","The dataset is constructed in a way that enables not only predicting concepts but also investigating their causes, and improves over features based machine learning by not requiring domain experts and being able to extract new knowledge.","ArXiv",2021,"Idan Amit",0,71,0,"https://www.semanticscholar.org/paper/6ccc0ca964ddab19705e4832758e6a2447325348"
"58dd9a3da16c10f5c3cdbb9760a9ff378847bf76",1,"Self-supervision of wearable sensors time-series data for influenza detection","The results show that predicting the next day’s resting heart rate or time-in-bed during sleep provides better representations for ILI prediction, adding to previous work demonstrating the practical application of self-supervised learning from activity data to improve health predictions.","ArXiv",2021,"Arinbjörn Kolbeinsson,Piyusha S. Gade,R. Kainkaryam,Filip Jankovic,L. Foschini",1,14,0,"https://www.semanticscholar.org/paper/58dd9a3da16c10f5c3cdbb9760a9ff378847bf76"
"1b94afca9d6688cc584a744734126473283cbc93",1,"Can Transformers be Strong Treatment Effect Estimators?","A general framework based on the Transformer architecture is developed to address a variety of challenging treatment effect estimation (TEE) problems and a propensity score network is proposed that is trained with TransTEE in an adversarial manner to promote independence between covariates and treatments to further address selection bias.","ArXiv",2022,"Yi-Fan Zhang,Hanlin Zhang,Zachary Chase Lipton,Li Erran Li,Eric Xing",8,58,4,"https://www.semanticscholar.org/paper/1b94afca9d6688cc584a744734126473283cbc93"
"856d2c0f7b3f80dcf1f68d1dc0dcbf5c6fe5679a",1,"Interpreting docstrings without using common sense: the private science of very large language models∗","GPT-3, the natural language model on which Codex is built, and that services such as Copilot ultimately depend on, suffers from scientific deficiencies, and critical remarks on Copilot’s structure and underlying language model are presented.","",2022,"Darren Abramson,Ali Emami",0,39,0,"https://www.semanticscholar.org/paper/856d2c0f7b3f80dcf1f68d1dc0dcbf5c6fe5679a"
"78fd8185c5cd55830c31aa718a9909827e20774e",1,"A Research Agenda for Assessing the Economic Impacts of Code Generation Models","","",2022,"Sam Manning,Pamela Mishkin,Gillian K. Hadfield,Tyna,Eloundou,E. Eisner",1,58,0,"https://www.semanticscholar.org/paper/78fd8185c5cd55830c31aa718a9909827e20774e"
"8a4dce5735a101ff8f64c2b676afb8c24950a5d8",1,"Zero-shot Mathematical Problem Solving via Generative Pre-trained Transformers","The proposed approach shows that coding based problem-solving is more effective than the natural language reasoning based one, and by exploiting the Python as programming language, the proposed pipeline achieves 54.20% solve rate.","International Conference on Enterprise Information Systems",2022,"Federico A. Galatolo,M. Cimino,G. Vaglini",0,9,0,"https://www.semanticscholar.org/paper/8a4dce5735a101ff8f64c2b676afb8c24950a5d8"
"bee0be592c314435048599281bcd9c72bf63b735",1,"CueBot: Cue-Controlled Response Generation for Assistive Interaction Usages","This work builds a system that can represent people with disabilities, or speech and language disorders, in a social conversation and generate responses that can be controlled by the users using cues/keywords and introduces a keyword-loss to lexically constrain the model response output.","Workshop on Speech and Language Processing for Assistive Technologies",2022,"Shachi H. Kumar,Hsuan Su,R. Manuvinakurike,Maximilian Pinaroc,Sai Prasad,Saurav Sahay,L. Nachman",0,52,0,"https://www.semanticscholar.org/paper/bee0be592c314435048599281bcd9c72bf63b735"
"57c31c709792949bfbb9d4aaee941048aa07cc4b",1,"How to Give Imperfect Automated Guidance to Learners: A Case-Study in Workplace Learning","There was tentative evidence that workers’ behaviors were impacted by the FP/FN trade-oﬀ of their assigned experimental condition even after the ML assistant was removed and evidence that learners modulate their behaviors based on the ﬁne-grained conﬁdence values conveyed by the assistant.","International Conference on Artificial Intelligence in Education",2022,"J. Whitehill,Amitai Erfanian",0,18,0,"https://www.semanticscholar.org/paper/57c31c709792949bfbb9d4aaee941048aa07cc4b"
"2e5b29457ff45b8faba69bc2eaf05521584a7bec",1,"B UG F IX G ENERATION USING G RAPH T RANS","This work proposes FIXUR, a new architecture for generating bug fixing edits, by complementing graph neural networks with Transformer to encode the code graph as a graph that encapsulates rich syntactic and semantic dependencies.","",2022,"",0,25,0,"https://www.semanticscholar.org/paper/2e5b29457ff45b8faba69bc2eaf05521584a7bec"
"f01e316d3b28ccecda25b4d57926f496a9b17d3d",1,"How Robust are Neural Code Completion Models to Source Code Transformation?","This work develops a methodology for systematically evaluating neural code completion models using common source code transformations and provides insights into the strengths and weaknesses of different models, and serves as a foundation for future work towards improving the accuracy and robustness of Neural code completion.","",2022,"",0,22,0,"https://www.semanticscholar.org/paper/f01e316d3b28ccecda25b4d57926f496a9b17d3d"
"24c6982a25c0114bc98805d368b06d1a4f6d8fd5",1,"Understanding AI alignment research: A Systematic Analysis","This project collected and analyzed existing AI alignment research and found that the dataset is growing quickly, with several sub-elds emerging in parallel, and a classiﬁer trained onAI alignment research articles can detect relevant articles that the authors did not originally include in the dataset.","",2022,"Jan H. Kirchner",0,60,0,"https://www.semanticscholar.org/paper/24c6982a25c0114bc98805d368b06d1a4f6d8fd5"
"b562be15b076b494023b8ac24fc8c459f4fdf80a",1,"Craft an Iron Sword: Dynamically Generating Interactive Game Characters by Prompting Large Language Models Tuned on Code","It is demonstrated that use of a few example conversational prompts can power a conversational agent to generate both natural language and novel code, which can permit development of NPCs with which players can have grounded conversations that are free-form and less repetitive.","WORDPLAY",2022,"Ryan Volum,Sudha Rao,Michael Xu,Gabriel DesGarennes,Chris Brockett,Benjamin Van Durme,Olivia Deng,Akanksha Malhotra,Bill Dolan",3,21,1,"https://www.semanticscholar.org/paper/b562be15b076b494023b8ac24fc8c459f4fdf80a"
"15e767aa26a14455da95a2b2f11e3d59f2c250f6",1,"Autoformalization for Neural Theorem Proving","This work demonstrates the feasibility and usefulness of autoformalization in the context of the newly introduced MiniF2F benchmark, and finds that transformer-based language models trained on a large amount of web data are capable of formalizing mathematical competition problem statements with a relatively high success rate.","",2022,"Yuhuai Wu,Albert Qiaochu Jiang,Wenda Li,Markus N. Rabe,Charles Staats,M. Jamnik,Christian Szegedy",0,11,0,"https://www.semanticscholar.org/paper/15e767aa26a14455da95a2b2f11e3d59f2c250f6"
"b69b84706fe84c4c614e4473760c57dffbfeb9a0",1,"Waveformer: Linear-Time Attention with Forward and Backward Wavelet Transform","Extensive experiments on seven long-range understanding datasets from the Long Range Arena benchmark and code understanding tasks demonstrate that Waveformer achieves competitive and even better accuracy than a number of state-of-the-art Transformer variants and WISE can boost accuracies of various attention approximation methods without increasing the time complexity.","ArXiv",2022,"Yufan Zhuang,Zihan Wang,Fangbo Tao,Jingbo Shang",0,43,0,"https://www.semanticscholar.org/paper/b69b84706fe84c4c614e4473760c57dffbfeb9a0"
"cd155729180ea707dea251f8e9654db241ffd808",1,"Is GPT-3 all you need for machine learning for chemistry?","This work analyzes whether one of the largest pre-trained LLMs, GPT-3, can be directly used for chemistry applications by fine-tuning on only a few data points from a chemistry dataset, i.e., without pre-training on a chemistry-specific dataset.","",2022,"K. Jablonka",0,50,0,"https://www.semanticscholar.org/paper/cd155729180ea707dea251f8e9654db241ffd808"
"0180d35b85dd4daead90e0652b64b1339e754684",1,"Assistance with large language models","A behavioral cloning approach is applied to GPT-3 such that it can respond to clear input questions directly, clarify the intent behind vague input questions, and respond based on the clarification it receives, and this approach leads to quantitative improvements in answer accuracy compared to a baseline that cannot ask for clarifications.","",2022,"Dmitrii Krasheninnikov",2,30,0,"https://www.semanticscholar.org/paper/0180d35b85dd4daead90e0652b64b1339e754684"
"e002bb8dae5a18a5ea1e7e1aafa16e19ad545662",1,"Solving Math Word Problems with Process-based and Outcome-based Feedback","This work runs the first comprehensive comparison between process- and outcome- based approaches trained on a natural language task, GSM8K, and finds that pure outcome-based supervision produces similar final-answer error rates with less label supervision.","",2022,"J. Uesato,Nate Kushman,Ramana Kumar,Francis Song,Noah Siegel,L. Wang,Antonia Creswell,Geoffery Irving,I. Higgins",0,61,0,"https://www.semanticscholar.org/paper/e002bb8dae5a18a5ea1e7e1aafa16e19ad545662"
"f9d38e03c97562b5f5942f3a0c43bdb751b9dc1c",1,"Wordplay 2022 The 3rd Wordplay: When Language Meets Games Workshop Proceedings of the Workshop","Novel techniques to generate text in a particular style are described, providing an approach of generating engaging naturalistic conversation responses using knowledge generated by pre-trained language models, considering their recent success in a multitude of NLP tasks.","",2022,"Shrimai Prabhumoye",0,67,0,"https://www.semanticscholar.org/paper/f9d38e03c97562b5f5942f3a0c43bdb751b9dc1c"
"a85c5d7272371345e28a9910080224cad799972e",1,"Schema Matching using Pre-Trained Language Models","The Learned Schema Mapper (LSM) is proposed, a novel linguistic schema matching system that leverages the natural language understanding capabilities of pre-trained language models to improve the overall accuracy and significantly reduce the overall human labeling cost.","",2022,"Yunjia Zhang",0,47,0,"https://www.semanticscholar.org/paper/a85c5d7272371345e28a9910080224cad799972e"
"95a2ee5aeccf2883f904ee3fcd7369adeb176359",1,"Probing Pretrained Models of Source Codes","This work shows that pretrained models of code indeed contain information about code syntactic structure, the notions of identifiers, and namespaces, but they may fail to recognize more complex code properties such as semantic equivalence, and investigates how probing results are affected by using code-specific pretraining objectives, varying the model size, or finetuning.","BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP",2022,"Sergey Troshin,N. Chirkova",0,43,0,"https://www.semanticscholar.org/paper/95a2ee5aeccf2883f904ee3fcd7369adeb176359"
"51256ee5425d5c425b84e7fac011775d8eff0d1c",1,"An Empirical Analysis of Memorization in Fine-tuned Autoregressive Language Models","This paper empirically study memorization of fine-tuning methods using membership inference and extraction attacks, and shows that their susceptibility to attacks is very different.","Conference on Empirical Methods in Natural Language Processing",2022,"Fatemehsadat Mireshghallah,Archit Uniyal,Tianhao Wang,David Evans,Taylor Berg-Kirkpatrick",0,27,0,"https://www.semanticscholar.org/paper/51256ee5425d5c425b84e7fac011775d8eff0d1c"
"9cd0cb3af7c2215eae9afdcf500a2bcd5330aae3",1,"20Q: Overlap-Free World Knowledge Benchmark for Language Models","20Q is introduced, a novel benchmark using the Twenty Questions game to evaluate world knowledge and common sense of language models and shows that in-context learning is inefficient for evaluating language models’ world knowledge — fine-tuning is necessary to show their true capabilities.","IEEE Games Entertainment Media Conference",2022,"Maxime De Bruyn,Ehsan Lotfi,Jeska Buhmann,Walter Daelemans",0,36,0,"https://www.semanticscholar.org/paper/9cd0cb3af7c2215eae9afdcf500a2bcd5330aae3"
"ae10c4b220a0bc0999bf169d5c219086d1f1aeed",1,"Edinburgh Research Explorer Taxonomy of risks posed by language models","A comprehensive taxonomy of ethical and social risks associated with LMs is developed, drawing on expertise and literature from computer science, linguistics, and the social sciences to ensure that language models are developed responsibly.","",2022,"Laura Weidinger,J. Uesato,M. Rauh,C. Griffin,P. Huang,John F. J. Mellor,A. Glaese,M. Cheng,B. Balle,A. Kasirzadeh,C. Biles,S. Brown,Z. Kenton,W. Hawkins,T. Stepleton,A. Birhane,L. Hendricks,Rimell,Laura Weidinger,J. Uesato,M. Rauh,C. Griffin,John F. J. Mellor,A. Glaese,M. Cheng,B. Balle,A. Kasirzadeh,C. Biles,S. Brown,Z. Kenton,Tom,Stepleton,A. Birhane,Lisa Anne Hendricks,Laura Rimell",0,218,0,"https://www.semanticscholar.org/paper/ae10c4b220a0bc0999bf169d5c219086d1f1aeed"
"60043104ca33a1fc905af57ead32768e52c69103",1,"C3PO: A Lightweight Copying Mechanism for Translating Pseudocode to Code","This work proposes a lightweight alternative to LLMs that exploits the property of code wherein most tokens can be simply copied from the pseudocode, and achieves similar performance to non-C3PO models while reducing the computational cost of training as well as the vocabulary sizes.","AACL",2022,"Vishruth Veerendranath,Vibha Masti,Prajwal Anagani,Mamatha Hr",0,21,0,"https://www.semanticscholar.org/paper/60043104ca33a1fc905af57ead32768e52c69103"
"8a4299a61cc44b60e5be32fef35341c3bc7b2a0d",1,"The Hole Story: Type-Directed Synthesis and Repair","This thesis explores the integration of program synthesis into GHC compiler error messages using typed-hole suggestions to aid the completion of partial programs during development and presents PropR, a tool based on type-driven synthesis aided by propertybased testing and fault-localization in conjunction with genetic algorithms to automatically repair buggy programs.","",2022,"Matthías Páll Gissurarson",0,106,0,"https://www.semanticscholar.org/paper/8a4299a61cc44b60e5be32fef35341c3bc7b2a0d"
"25c402db512d327f1da143de3b8e797ad6fbfe5b",1,"P ROG P ROMPT : Generating Situated Robot Task Plans using Large Language Models","This work presents a programmatic LLM prompt structure that enables plan generation functional across situated environments, robot capabilities, and tasks, and makes concrete recommendations about prompt structure and generation constraints through ablation experiments.","",2022,"Llm Gpt",0,39,0,"https://www.semanticscholar.org/paper/25c402db512d327f1da143de3b8e797ad6fbfe5b"
"75e36bb95023e55f7dec95d1af557e219ba3d349",1,"CORAL: COde RepresentAtion learning with weakly-supervised transformers for analyzing data analysis","This work proposes a novel weakly supervised transformer-based architecture for computing joint representations of code from both abstract syntax trees and surrounding natural language comments and achieves a 38% increase in accuracy over expert-supplied heuristics and outperforms a suite of baselines.","EPJ Data Science",2020,"Ashley Ge Zhang,Michael Merrill,Yang Liu,Jeffrey Heer,Tim Althoff",7,71,2,"https://www.semanticscholar.org/paper/75e36bb95023e55f7dec95d1af557e219ba3d349"
"a63535ebbf90d0c51408252c23b85ffaf87f09ae",1,"Towards an AI Assistant for Power Grid Operators","The vision of a new assistant framework rely- ing on an hypervision interface and greater bidirectional interaction is exposed, and the known principles of decision-making driving the assistant design alongside with its supporting assistance functions are reviewed.","HHAI",2020,"Antoine Marot,Alexandre Rozier,Matthieu Dussartre,Laure Crochepierre,Benjamin Donnot",2,111,0,"https://www.semanticscholar.org/paper/a63535ebbf90d0c51408252c23b85ffaf87f09ae"
"8cf3a454556060d6e9aa86dbabf221bd10bf9759",1,"On the Effectiveness of Transfer Learning for Code Search","It is demonstrated that natural language processing models based on the Transformer architecture can be directly applied to source code analysis tasks, such as code search, and the combined use of an information retrieval-based approach followed by a Transformer leads to the best results overall.","IEEE Transactions on Software Engineering",2021,"P. Salza,Christoph Schwizer,Jian Gu,H. Gall",10,86,3,"https://www.semanticscholar.org/paper/8cf3a454556060d6e9aa86dbabf221bd10bf9759"
"a1e1297fb132d7769dda3f7917e57757e6e22605",1,"Impact of Evaluation Methodologies on Code Summarization","The time-segmented evaluation methodology is introduced, which is novel to the code summarization research community, and compared with the mixed-project and cross-project methodologies that have been commonly used and shows that different methodologies lead to conflicting evaluation results.","Annual Meeting of the Association for Computational Linguistics",2021,"Pengyu Nie,Jiyang Zhang,Junyi Jessy Li,R. Mooney,Miloš Gligorić",4,56,0,"https://www.semanticscholar.org/paper/a1e1297fb132d7769dda3f7917e57757e6e22605"
"77d956cdab4508d569ae5741549b78e715fd0749",1,"TruthfulQA: Measuring How Models Mimic Human Falsehoods","It is suggested that scaling up models alone is less promising for improving truthfulness than fine-tuning using training objectives other than imitation of text from the web.","Annual Meeting of the Association for Computational Linguistics",2021,"Stephanie C. Lin,Jacob Hilton,Owain Evans",74,70,13,"https://www.semanticscholar.org/paper/77d956cdab4508d569ae5741549b78e715fd0749"
"2672777d25562c9df6fc13b653181db62d39bece",1,"An Empirical Study of GPT-3 for Few-Shot Knowledge-Based VQA","This work proposes PICa, a simple yet effective method that Prompts GPT3 via the use of Image Captions, for knowledge-based VQA, and treats GPT-3 as an implicit and unstructured KB that can jointly acquire and process relevant knowledge.","AAAI Conference on Artificial Intelligence",2021,"Zhengyuan Yang,Zhe Gan,Jianfeng Wang,Xiaowei Hu,Yumao Lu,Zicheng Liu,Lijuan Wang",58,42,21,"https://www.semanticscholar.org/paper/2672777d25562c9df6fc13b653181db62d39bece"
"c6bb04f3d8000b7e800f6359082de39548c7da79",1,"Capturing Structural Locality in Non-parametric Language Models","This paper proposes a simple yet effective approach for adding locality information into non-parametric language models by adding learned parameters that improve the likelihood of retrieving examples from local neighborhoods.","International Conference on Learning Representations",2021,"Frank F. Xu,Junxian He,Graham Neubig,V. Hellendoorn",5,47,0,"https://www.semanticscholar.org/paper/c6bb04f3d8000b7e800f6359082de39548c7da79"
"a421ba0a9150cd35e231dddc323bdd9a59b3af93",1,"Coherence boosting: When your pretrained language model is not paying enough attention","It is found that coherence boosting with state-of-the-art models for various zero-shot NLP tasks yields performance gains with no additional training.","Annual Meeting of the Association for Computational Linguistics",2021,"Nikolay Malkin,Zhen Wang,N. Jojic",4,64,1,"https://www.semanticscholar.org/paper/a421ba0a9150cd35e231dddc323bdd9a59b3af93"
"1cbb3d96242c3f47c3f40aada33616d0f5c07737",1,"Inductive Biases and Variable Creation in Self-Attention Mechanisms","The main result shows that bounded-norm Transformer networks “cre-ate sparse variables”: a single self-attention head can represent a sparse function of the input sequence, with sample complexity scaling only logarithmically with the context length.","International Conference on Machine Learning",2021,"Benjamin Edelman,Surbhi Goel,S. Kakade,Cyril Zhang",12,74,4,"https://www.semanticscholar.org/paper/1cbb3d96242c3f47c3f40aada33616d0f5c07737"
"231e768f0cd280faa0f725bb353262cb4fed08d1",1,"Hierarchical Transformers Are More Efficient Language Models","Hourglass is a hierarchical Transformer language model that sets new state-of-the-art for Transformer models on the ImageNet32 generation task and improves language modeling efﬁciency on the widely studied enwik8 benchmark.","NAACL-HLT",2021,"Piotr Nawrot,Szymon Tworkowski,Michal Tyrolski,Lukasz Kaiser,Yuhuai Wu,Christian Szegedy,H. Michalewski",13,38,1,"https://www.semanticscholar.org/paper/231e768f0cd280faa0f725bb353262cb4fed08d1"