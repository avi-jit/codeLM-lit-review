"id","score","title","summary","venue","year","authors","citationCount","referenceCount","influentialCitationCount","url"
"9e3b52669d81dbf0d638a5f5d1d537c7087195d6",4,"When Neural Model Meets NL2Code: A Survey","This survey focuses on how does neural network (NN) solves NL2Code and proposes a comprehensive framework, which is able to cover all studies in this task, and in-depth parse the existing studies into this framework.","ArXiv",2022,"Daoguang Zan,Bei Chen,Fengji Zhang,Di Lu,Bingchao Wu,Bei Guan,Yongji Wang,Jian-Guang Lou",0,156,0,"https://www.semanticscholar.org/paper/9e3b52669d81dbf0d638a5f5d1d537c7087195d6"
"3d5463a16d85d9d1d0d8ebb4117a31aca3c240ff",3,"Fooling MOSS Detection with Pretrained Language Models","It is found that a student using GPT-J can complete introductory level programming assignments without triggering suspicion from MOSS, a widely used software similarity and plagiarism detection tool.","International Conference on Information and Knowledge Management",2022,"Stella Rose Biderman,Edward Raff",2,70,0,"https://www.semanticscholar.org/paper/3d5463a16d85d9d1d0d8ebb4117a31aca3c240ff"
"075b6fb7d3787953164eecc1bd2e13f97c9f3c44",3,"Fault-Aware Neural Code Rankers","C ODE R ANKER is a neural ranker that can predict the correctness of a sampled program without executing it and can signiﬁcantly increase the pass@1 accuracy of various code generation models on APPS, HumanEval, and MBPP datasets.","ArXiv",2022,"J. Inala,Chenglong Wang,Mei Yang,Andrés Codas,Mark Encarnaci'on,Shuvendu K. Lahiri,M. Musuvathi,Jianfeng Gao",6,41,2,"https://www.semanticscholar.org/paper/075b6fb7d3787953164eecc1bd2e13f97c9f3c44"
"a08a3b08a5a1de6462a7da2906b1cd81691d6c18",3,"CERT: Continual Pre-Training on Sketches for Library-Oriented Code Generation","This paper investigates how to leverage an unlabelled code corpus to train a model for library-oriented code generation, and observes that library- oriented code snippets are more likely to share similar code sketches.","International Joint Conference on Artificial Intelligence",2022,"Daoguang Zan,Bei Chen,Dejian Yang,Zeqi Lin,Minsu Kim,Bei Guan,Yongji Wang,Weizhu Chen,Jian-Guang Lou",4,27,0,"https://www.semanticscholar.org/paper/a08a3b08a5a1de6462a7da2906b1cd81691d6c18"
"876eb375cb7b365475040046df669c039ad54202",3,"CodeT: Code Generation with Generated Tests","A novel method, C ODE T, leverages the same pre-trained language models to test cases for the code samples, thus reducing the human effort and increasing the coverage of the test scenarios, achieving remarkable and consistent gains across different models and benchmarks.","ArXiv",2022,"Bei Chen,Fengji Zhang,A. Nguyen,Daoguang Zan,Zeqi Lin,Jian-Guang Lou,Weizhu Chen",10,40,3,"https://www.semanticscholar.org/paper/876eb375cb7b365475040046df669c039ad54202"
"780f7eebde16b1ae5843df3a79a7772899ef6a71",3,"MultiPL-E: A Scalable and Extensible Approach to Benchmarking Neural Code Generation","This work creates the first massively multilingual code generation benchmark by using MultiPL-E to translate two popular Python code generation benchmarks to 18 additional programming languages and evaluates the multi-language performance of three state-of-the-art code generation models.","",2022,"Federico Cassano,John Gouwar,Daniel Nguyen,S. Nguyen,Luna Phipps-Costin,Donald Pinckney,Ming-Ho Yee,Yangtian Zi,Carolyn Jane Anderson,Molly Q. Feldman,Arjun Guha,M. Greenberg,Abhinav Jangda",0,42,0,"https://www.semanticscholar.org/paper/780f7eebde16b1ae5843df3a79a7772899ef6a71"
"1b4c19168410fb2690d285b205ab2281793db81a",3,"A Scalable and Extensible Approach to Benchmarking NL2Code for 18 Programming Languages","It is shown that on several languages, Codex matches and even exceeds its performance on Python, and a general approach is described for easily adding support for new benchmarks and languages to MultiPL-E, the first multi-language parallel benchmark for natural-language-to-code-generation.","ArXiv",2022,"Federico Cassano,John Gouwar,Daniel Nguyen,S. Nguyen,Luna Phipps-Costin,Donald Pinckney,Ming-Ho Yee,Yangtian Zi,Carolyn Jane Anderson,Molly Q. Feldman,Arjun Guha,M. Greenberg,Abhinav Jangda",2,27,0,"https://www.semanticscholar.org/paper/1b4c19168410fb2690d285b205ab2281793db81a"
"6032212d5790b6a580d68d469a9895aad6238c89",3,"Diverse Title Generation for Stack Overflow Posts with Multiple Sampling Enhanced Transformer","A novel approach to automatically generate multiple post titles from the given code snippets, using the maximal marginal multiple nucleus sampling strategy to generate multiple high-quality and diverse title candidates at a time for the developers to choose from.","ArXiv",2022,"Fengji Zhang,Jin Liu,Yao Wan,Xiao Yu,Xiao Liu,J. Keung",0,56,0,"https://www.semanticscholar.org/paper/6032212d5790b6a580d68d469a9895aad6238c89"
"0b340dd78fd04bbde2807d5efedb796d319355e3",3,"Piloting Copilot and Codex: Hot Temperature, Cold Prompts, or Black Magic?","Investigation of the various input parameters of two language models shows that varying the input parameters can improve the performance of language models, but there is a tight dependency when varying the temperature, the prompt and the number of generated solutions, making potentially hard to properly control the parameters to obtain an optimal result.","ArXiv",2022,"Jean-Baptiste Döderlein,M. Acher,D. Khelladi,B. Combemale",0,45,0,"https://www.semanticscholar.org/paper/0b340dd78fd04bbde2807d5efedb796d319355e3"
"cba98048f3e85a974c287b271692bf6c197db940",3,"Aligning Offline Metrics and Human Judgments of Value of AI-Pair Programmers","A simple hybrid metric is proposed, which combines functional correctness and similarity- based metrics to capture different dimensions of what programmers might value and shows that this hybrid metric more accurately captures effort.","ArXiv",2022,"Victor C. Dibia,Adam Fourney,Gagan Bansal,Forough Poursabzi-Sangdeh,Han Liu,Saleema Amershi",1,32,0,"https://www.semanticscholar.org/paper/cba98048f3e85a974c287b271692bf6c197db940"
"8a4fc5f00cd4aca61e148e46a2125c3a406719f1",3,"DS-1000: A Natural and Reliable Benchmark for Data Science Code Generation","This work introduces DS-1000, a code generation benchmark with a thousand data science problems spanning seven Python libraries, such as NumPy and Pandas, and proactively defends against memorization by slightly modifying the problems to be different from the original StackOverﬂow source.","ArXiv",2022,"Yuhang Lai,Chengxi Li,Yiming Wang,Tianyi Zhang,Ruiqi Zhong,Luke Zettlemoyer,S. Yih,Daniel Fried,Si-yi Wang,Tao Yu",5,30,2,"https://www.semanticscholar.org/paper/8a4fc5f00cd4aca61e148e46a2125c3a406719f1"
"815c6ca281536d18ec0eb408b6e46e72a0826163",3,"Natural Language to Code Generation in Interactive Data Science Notebooks","P A C H - I NC O, a 62B code language model for Python computational notebooks, which outperforms public code LMs and explores few-shot prompting strategies to elicit better code with step-by-step decomposition and NL explanation, showing the potential to improve the diversity and explainability of model predictions.","ArXiv",2022,"Pengcheng Yin,Wen-Ding Li,Kefan Xiao,A. Rao,Yeming Wen,Kensen Shi,Joshua Howland,Paige Bailey,Michele Catasta,H. Michalewski,Alex Polozov,Charles Sutton",1,60,0,"https://www.semanticscholar.org/paper/815c6ca281536d18ec0eb408b6e46e72a0826163"
"433def684b5a9de5a9163f50b9004a44a11128b1",3,"CoCoMIC: Code Completion By Jointly Modeling In-file and Cross-file Context","A framework that incorporates cross-file context to learn the in-file and cross- file context jointly on top of pretrained code LMs is proposed, COCOMIC, which successfully improves the existing code LM with a 19.30% relative increase in exact match and a 15.41%relative increase in identifier matching for code completion when the cross-line context is provided.","ArXiv",2022,"Yangruibo Ding,Zijian Wang,Wasi Uddin Ahmad,M. Ramanathan,Ramesh Nallapati,Parminder Bhatia,D. Roth,Bing Xiang",0,39,0,"https://www.semanticscholar.org/paper/433def684b5a9de5a9163f50b9004a44a11128b1"
"239b5649b12f28fd610de036afba41b9246db6c9",3,"Parsel: A Unified Natural Language Framework for Algorithmic Reasoning","This work introduces Parsel 2, a framework enabling automatic implementation and validation of complex algorithms with code LLMs, based on hierarchical function descriptions in natural language, which can be used across domains requiring hierarchical reasoning, e.g. code synthesis, theorem proving, and robotic planning.","ArXiv",2022,"E. Zelikman,Qian Huang,Gabriel Poesia,Noah D. Goodman,N. Haber",0,65,0,"https://www.semanticscholar.org/paper/239b5649b12f28fd610de036afba41b9246db6c9"
"a3e355b5de868f34fdfa2500415c5f74c69d2091",3,"Recommending Root-Cause and Mitigation Steps for Cloud Incidents using Large Language Models","A rigorous study on the effectiveness of large language models for helping engineers root cause and mitigate production incidents, and a human evaluation with actual incident owners show the future potential of using artiﬁcial intelligence for resolving cloud incidents.","ArXiv",2023,"Toufique Ahmed,Supriyo Ghosh,Chetan Bansal,T. Zimmermann,Xuchao Zhang,S. Rajmohan",0,63,0,"https://www.semanticscholar.org/paper/a3e355b5de868f34fdfa2500415c5f74c69d2091"
"317208b423d24d52ba04221cfb46956962364e22",2,"Extracting Meaningful Attention on Source Code: An Empirical Study of Developer and Neural Model Code Exploration","This work empirically evaluates attention-agnostic heuris-tics and ten attention-based post processing approaches of the attention signal against the ground truth of developers exploring code, including the novel concept of follow-up attention which exhibits the highest agreement.","ArXiv",2022,"Matteo Paltenghi,Rahul Pandita,Austin Z. Henley,Albert Ziegler",0,42,0,"https://www.semanticscholar.org/paper/317208b423d24d52ba04221cfb46956962364e22"
"20e4ca6368a0731d3cbbd2e68aa90cef7384dc72",2,"Multi-lingual Evaluation of Code Generation Models","This work presents MBXP, an execution-based code completion benchmark in 10+ programming languages that is able to evaluate code generation models in a multi-lingual fashion, and discovers generalization ability of language models on out-of-domain languages, advantages of large multi-lingsual models over mono-lingUAL, benefits of few-shot prompting, and zero-shot translation abilities.","ArXiv",2022,"Ben Athiwaratkun,Sanjay Krishna Gouda,Zijian Wang,Xiaopeng Li,Yuchen Tian,Ming Tan,Wasi Uddin Ahmad,Shiqi Wang,Qing Sun,Mingyue Shang,Sujan Kumar Gonugondla,Hantian Ding,Varun Kumar,Nathan Fulton,A. Farahani,Siddharth Jain,Robert Giaquinto,Haifeng Qian,M. Ramanathan,Ramesh Nallapati,Baishakhi Ray,Parminder Bhatia,Sudipta Sengupta,D. Roth,Bing Xiang",4,29,2,"https://www.semanticscholar.org/paper/20e4ca6368a0731d3cbbd2e68aa90cef7384dc72"
"7547680408358916e66917d03436fca7540a7528",2,"Project CodeNet: A Large-Scale AI for Code Dataset for Learning a Diversity of Coding Tasks","Project CodeNet is a first-of-its-kind, very large scale, diverse, and high-quality dataset to accelerate the algorithmic advancements in AI for Code, which consists of 14M code samples and about 500M lines of code in 55 different programming languages.","NeurIPS Datasets and Benchmarks",2021,"Ruchi Puri,David S. Kung,G. Janssen,Wei Zhang,Giacomo Domeniconi,Vladmir Zolotov,Julian Dolby,Jie Chen,M. Choudhury,Lindsey Decker,Veronika Thost,Luca Buratti,Saurabh Pujar,Ulrich Finkler",65,45,21,"https://www.semanticscholar.org/paper/7547680408358916e66917d03436fca7540a7528"
"f7664102a451332ed7e1286561b2f621eaff128d",2,"Programming Puzzles","A positive correlation between puzzlesolving performance and coding experience, and between the puzzle difficulty for humans and AI solvers are found, and further improvements on P3 could have a significant impact on many program synthesis areas.","NeurIPS Datasets and Benchmarks",2021,"Tal Schuster,A. Kalyan,Oleksandr Polozov,A. Kalai",12,83,0,"https://www.semanticscholar.org/paper/f7664102a451332ed7e1286561b2f621eaff128d"
"58a6ca2ae28a618126f71a07262cb958a8c37904",2,"Latent Execution for Neural Program Synthesis","LaSynth learns the latent representation to approximate the execution of partially generated programs, even if they are incomplete in syntax, and significantly improves the performance of next token prediction over existing approaches, facilitating search.","",2021,"Xinyun Chen,D. Song,Yuandong Tian",2,60,0,"https://www.semanticscholar.org/paper/58a6ca2ae28a618126f71a07262cb958a8c37904"
"a38e0f993e4805ba8a9beae4c275c91ffcec01df",2,"Program Synthesis with Large Language Models","The limits of the current generation of large language models for program synthesis in general purpose programming languages are explored, finding that even the best models are generally unable to predict the output of a program given a speciﬁc input.","ArXiv",2021,"Jacob Austin,Augustus Odena,Maxwell Nye,Maarten Bosma,H. Michalewski,David Dohan,Ellen Jiang,Carrie J. Cai,Michael Terry,Quoc V. Le,Charles Sutton",151,102,35,"https://www.semanticscholar.org/paper/a38e0f993e4805ba8a9beae4c275c91ffcec01df"
"a8863de15a5ee8eed98107f423138a1a8f5a2ba8",2,"Multi-modal program inference: a marriage of pre-trained language models and component-based synthesis","This work presents an approach that combines PTMs with component-based synthesis (CBS): PTMs are used to generate candidates programs from the natural language description of the task, which are then used to guide the CBS procedure to find the program that matches the precise examples-based specification.","Proc. ACM Program. Lang.",2021,"Kia Rahmani,Mohammad Raza,Sumit Gulwani,Vu Le,Daniel Morris,Arjun Radhakrishna,Gustavo Soares,A. Tiwari",16,77,0,"https://www.semanticscholar.org/paper/a8863de15a5ee8eed98107f423138a1a8f5a2ba8"
"570a6a5b8ec2827c3f33bb1b1bd027190a0d3e07",2,"Neural Program Generation Modulo Static Analysis","The neurosymbolic method allows a deep generative model to symbolically compute, using calls to a static-analysis tool, long-distance semantic relationships in the code that it has already generated, and learns to generate programs conditioned on them.","Neural Information Processing Systems",2021,"Rohan Mukherjee,Yeming Wen,Dipak Chaudhari,T. Reps,Swarat Chaudhuri,C. Jermaine",9,56,0,"https://www.semanticscholar.org/paper/570a6a5b8ec2827c3f33bb1b1bd027190a0d3e07"
"a5731122200fbb8b37f048010a1e1ca4474aa606",2,"Examining Zero-Shot Vulnerability Repair with Large Language Models","This work examines the use of large language models for code (such as OpenAI’s Codex and AI21's Jurassic J-1) for zero-shot vulnerability repair, and investigates challenges in the design of prompts that coax LLMs into generating repaired versions of insecure code.","",2021,"H. Pearce,B. Tan,Baleegh Ahmad,R. Karri,Brendan Dolan-Gavitt",1,56,0,"https://www.semanticscholar.org/paper/a5731122200fbb8b37f048010a1e1ca4474aa606"
"5ff9032d0f7f246d01ae7b2c231ab03469a7344a",2,"Can OpenAI Codex and Other Large Language Models Help Us Fix Security Bugs?","This work examines the use of large language models for code (such as OpenAI's Codex and AI21's Jurassic J-1) for zero-shot vulnerability repair, and investigates challenges in the design of prompts that coax LLMs into generating repaired versions of insecure code.","ArXiv",2021,"H. Pearce,B. Tan,Baleegh Ahmad,R. Karri,Brendan Dolan-Gavitt",20,56,1,"https://www.semanticscholar.org/paper/5ff9032d0f7f246d01ae7b2c231ab03469a7344a"
"a3564f3cf954c05844c757505325a50b4d858e22",2,"Generating Infrastructure-as-Code from Natural Language: Evaluating Fine-Tuned GPT-3 Models for Cloud Infrastructure Provisioning","A transformer-based model to generate Infrastructure-as-Code from natural language is introduced, which allows both technical and nontechnical users to dynamically generate IaC artifacts, enabling them to request and receive cloud resources using conversational interfaces such as chat bots, SMS, etc.","",2022,"",0,8,0,"https://www.semanticscholar.org/paper/a3564f3cf954c05844c757505325a50b4d858e22"
"6f84d0cc33c7c58f74b28ddcc1cbda91ea608c9f",2,"C ODE S UMMARIZATION : D O T RANSFORMERS R E ALLY U C","Overall, the quality of the generated summaries even from state-of-the-art (SOTA) models is quite poor, raising questions about the utility of current approaches and datasets.","",2022,"Manasi S. Patwardhan,L. Vig,Raveendra Kumar Medicherla,Ravindra Naik,Gautam M. Shroff",0,40,0,"https://www.semanticscholar.org/paper/6f84d0cc33c7c58f74b28ddcc1cbda91ea608c9f"
"3b0cf543a730e674d4213d344ebc857fada76ead",2,"Understanding High-Level Properties of Low-Level Programs Through Transformers","It is shown that Transformer models can translate C to LLVM-IR with high accuracy, by training on a parallel corpus of functions extract from 1 million compilable, open-sourced C programs and its corresponding LL VM-IR after compiling with Clang.","",2022,"William S. Moses",0,63,0,"https://www.semanticscholar.org/paper/3b0cf543a730e674d4213d344ebc857fada76ead"
"a2b6e1f7d8a7963d321f29fca7c01eeb1ebd7f0f",2,"P ATCH G ENERATION WITH L ANGUAGE M ODELS : F EASIBILITY AND S CALING B EHAVIOR","This work highlights a noticeable correlation of model size with test-passing accuracy and patch ranking quality, and the propensity for especially the largest models to generate candidate patches that closely resemble (if not exactly match), the original developer patch.","",2022,"Sophia Kolak,Ruben Martins,Claire Le Goues,V. Hellendoorn",0,23,0,"https://www.semanticscholar.org/paper/a2b6e1f7d8a7963d321f29fca7c01eeb1ebd7f0f"
"b2c4fdb49bdb23e6ad0ac3272029324157046ea7",2,"Automated Repair of Code from Language Models","The study revealed that automatically generated code shares common programming mistakes with human-crafted solutions, indicating APR techniques may have potential to auto-generated code, and given bug location information provided by a statistical fault localization approach, Codex edit mode is similar to or better than existing Java repair tools TBar and Recoder in correcting incorrect solutions.","",2022,"Zhiyu Fan,Xiang Gao,M. Mirchev,Abhik Roychoudhury,Shin Hwei Tan",0,49,0,"https://www.semanticscholar.org/paper/b2c4fdb49bdb23e6ad0ac3272029324157046ea7"
"78863000eb70945cc8d791d45d4a3fe8a6521cb6",2,"Open-Ended Knowledge Tracing for Computer Science Education","This paper develops an initial solution to the OKT problem, a student knowledge-guided code generation approach that combines program synthesis methods using language models with student knowledge tracing methods and conducts a series of quantitative and qualitative experiments to validate OKT and demonstrate its promise in educational applications.","",2022,"Naiming Liu,Zichao Wang",0,54,0,"https://www.semanticscholar.org/paper/78863000eb70945cc8d791d45d4a3fe8a6521cb6"
"1aed58bd07026492194672adec494dc37c894a28",2,"Leveraging Automated Unit Tests for Unsupervised Code Translation","This work proposes to leverage an automated unit-testing system to filter out invalid translations, thereby creating a fully tested parallel corpus, and finds that fine-tuning an unsupervised model with this filtered data set significantly reduces the noise in the translations so-generated, comfortably outperforming the state of the art for all language pairs studied.","International Conference on Learning Representations",2021,"Baptiste Rozière,J Zhang,François Charton,M. Harman,Gabriel Synnaeve,Guillaume Lample",16,60,1,"https://www.semanticscholar.org/paper/1aed58bd07026492194672adec494dc37c894a28"
"52db8674337e5d86dcb96d013734befc8c3d4581",2,"Large Language Models are not Models of Natural Language: they are Corpus Models.","It is argued that the term language model is misleading because deep learning models are not theoretical models of language and proposed the adoption of corpus model instead, which better reflects the genesis and contents of the model.","IEEE Access",2021,"C. Veres",1,63,0,"https://www.semanticscholar.org/paper/52db8674337e5d86dcb96d013734befc8c3d4581"
"92a8f7f09f3705cb5a6009a42220a6f01ea084e8",2,"Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents","This paper investigates the possibility of grounding high-level tasks, expressed in natural language, to a chosen set of actionable steps and proposes a procedure that conditions on existing demonstrations and semantically translates the plans to admissible actions.","International Conference on Machine Learning",2022,"Wenlong Huang,P. Abbeel,Deepak Pathak,Igor Mordatch",81,55,13,"https://www.semanticscholar.org/paper/92a8f7f09f3705cb5a6009a42220a6f01ea084e8"
"55ad5e818cfed72317576027fb33a9609210d592",2,"Training and Evaluating a Jupyter Notebook Data Science Assistant","This work studies the feasibility of a Data Science assistant powered by a sequence-to-sequence transformer by training a new model JuPyT5 on all publicly available Jupyter Notebook GitHub repositories and developing a new metric: Data Science Problems (DSP).","ArXiv",2022,"Shubham Chandel,Colin B. Clement,Guillermo Serrato,Neel Sundaresan",7,22,2,"https://www.semanticscholar.org/paper/55ad5e818cfed72317576027fb33a9609210d592"
"5cbe278b65a81602a864184bbca37de91448a5f5",2,"Competition-level code generation with AlphaCode","AlphaCode is introduced, a system for code generation that achieved an average ranking in the top 54.3% in simulated evaluations on recent programming competitions on the Codeforces platform, marking the first time an artificial intelligence system has performed competitively in programming competitions.","Science",2022,"Yujia Li,David H. Choi,Junyoung Chung,Nate Kushman,Julian Schrittwieser,Rémi Leblond,Tom,Eccles,James Keeling,Felix Gimeno,Agustin Dal Lago,T. Hubert,Peter Choy,Cyprien de,Masson d’Autume,I. Babuschkin,Xinyun Chen,Po-Sen Huang,Johannes Welbl,Sven Gowal,Alexey,Cherepanov,James Molloy,D. Mankowitz,Esme Sutherland Robson,Pushmeet Kohli,Nando de,Freitas,K. Kavukcuoglu,Oriol Vinyals",125,81,28,"https://www.semanticscholar.org/paper/5cbe278b65a81602a864184bbca37de91448a5f5"
"76ebf56d6ebb833d8c8c4124f7b2f15771a4997c",2,"Investigating Explainability of Generative AI for Code through Scenario-based Design","This work explores explainability needs for GenAI for code and demonstrates how human-centered approaches can drive the technical development of XAI in novel domains.","International Conference on Intelligent User Interfaces",2022,"Jiao Sun,Q. Liao,Michael J. Muller,Mayank Agarwal,Stephanie Houde,Kartik Talamadupula,Justin D. Weisz",8,102,0,"https://www.semanticscholar.org/paper/76ebf56d6ebb833d8c8c4124f7b2f15771a4997c"
"7b46b9da287429d19a00ca3f9219c1020f7c9df8",2,"A Survey on Artificial Intelligence for Source Code: A Dialogue Systems Perspective","This survey paper overviews major deep learning methods used in Natural Language Processing (NLP) and source code over the last 35 years and presents a software-engineering centered taxonomy for CI placing each of the works into one category describing how it best assists the software development cycle.","ArXiv",2022,"Erfan Al-Hossami,Samira Shaikh",3,265,0,"https://www.semanticscholar.org/paper/7b46b9da287429d19a00ca3f9219c1020f7c9df8"
"7b5aa186ca8abc585607c5ec91562e127a398601",2,"Open-Ended Knowledge Tracing","This paper develops an initial solution to the OKT problem, a student knowledge-guided code generation approach that combines program synthesis methods using language models with student knowledge tracing methods and conducts a series of quantitative and qualitative experiments on a real-world student code dataset to validate OKT and demonstrate its promise in educational applications.","ArXiv",2022,"Naiming Liu,Zichao Wang,Richard Baraniuk,Andrew S. Lan",0,64,0,"https://www.semanticscholar.org/paper/7b5aa186ca8abc585607c5ec91562e127a398601"
"76f023c3a819fc58989a064a1b50825b11fce95d",2,"Capturing Failures of Large Language Models via Human Cognitive Biases","The results indicate that experimental methodology from cognitive science can help characterize how machine learning systems behave, and draw inspiration from human cognitive biases as motivation to generate hypotheses for problems that models may have and develop experiments that elicit these problems.","ArXiv",2022,"Erik Jones,J. Steinhardt",7,54,0,"https://www.semanticscholar.org/paper/76f023c3a819fc58989a064a1b50825b11fce95d"
"1f11601f9eb8c0bee1d1d2cc7f4fa187e8c5e525",2,"The impact of lexical and grammatical processing on generating code from natural language","The paper highlights the importance of the lexical substitution component in the current natural language to code systems with a state-of-the-art architecture that relies on BERT encoder and a grammar-based decoder for which a formalization is provided.","Findings",2022,"Nathanael Beau,Benoit Crabb'e",4,19,2,"https://www.semanticscholar.org/paper/1f11601f9eb8c0bee1d1d2cc7f4fa187e8c5e525"
"c96363c42bc8c465902c22b8c33c8704233f519e",2,"MCoNaLa: A Benchmark for Code Generation from Multiple Natural Languages","A multilingual dataset, MCoNaLa, is proposed to benchmark code generation from natural language commands extending beyond English, and a quantitative evaluation of performance on the M coNaLa dataset is presented by testing with state-of-theart code generation systems.","ArXiv",2022,"Zhiruo Wang,Grace Cuenca,Shuyan Zhou,Frank F. Xu,Graham Neubig",6,50,2,"https://www.semanticscholar.org/paper/c96363c42bc8c465902c22b8c33c8704233f519e"
"590f6817b42407f96b079e82c935fae298196359",2,"Less is More: Summary of Long Instructions is Better for Program Synthesis","A meta-dataset consisting of human and synthesized summaries of the long and complicated programming questions shows that summaries improve performance for introductory and interview programming questions and shows improvement by a small margin for competitive programming questions, implying scope for future research in this direction.","ArXiv",2022,"Kirby Kuznia,Swaroop Mishra,Mihir Parmar,Chitta Baral",4,28,0,"https://www.semanticscholar.org/paper/590f6817b42407f96b079e82c935fae298196359"
"1a903282f7c19dbdb2714b852fb42dbb4675422b",2,"CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis","The utility of the trained model is shown by demonstrating that it is competitive with the previous state-of-the-art on zero-shot Python code generation on HumanEval, and experiments show that the multi-step program synthesis capacity scales as a function of the model size and data size.","",2022,"Erik Nijkamp,Bo Pang,Hiroaki Hayashi,Lifu Tu,Haiquan Wang,Yingbo Zhou,S. Savarese,Caiming Xiong",6,47,2,"https://www.semanticscholar.org/paper/1a903282f7c19dbdb2714b852fb42dbb4675422b"
"771371fb288da26a9812f5808535847a0a9c9a80",2,"A Conversational Paradigm for Program Synthesis","This work proposes and trains C ODE G EN, an interactive code generation model for program synthesis, and suggests that the capacity of conversational program synthesis scales as a function of the model size and data size.","ArXiv",2022,"Erik Nijkamp,Bo Pang,Hiroaki Hayashi,Lifu Tu,Haiquan Wang,Yingbo Zhou,S. Savarese,Caiming Xiong",52,39,19,"https://www.semanticscholar.org/paper/771371fb288da26a9812f5808535847a0a9c9a80"
"a8fc183c089bd596ccc48b3d666f8814e1b41e55",2,"InCoder: A Generative Model for Code Infilling and Synthesis","INCODER is introduced, a unified generative model that can perform program synthesis (via left-to-right generation) as well as editing (via infilling) and the ability to condition on bidirectional context substantially improves performance on challenging tasks such as type inference, comment generation, and variable re-naming.","ArXiv",2022,"Daniel Fried,Armen Aghajanyan,Jessy Lin,Sida I. Wang,Eric Wallace,Freda Shi,Ruiqi Zhong,Wen-tau Yih,Luke Zettlemoyer,M. Lewis",47,77,17,"https://www.semanticscholar.org/paper/a8fc183c089bd596ccc48b3d666f8814e1b41e55"
"47e15941c8b157873c8264e4bf50318d1ba5cd18",2,"Natural Language to Code Translation with Execution","This work introduces execution result– based minimum Bayes risk decoding (MBR-EXEC) for program selection and shows that it improves the few-shot performance of pretrained code models on natural-language-to-code tasks, suggesting it as an effective approach for natural language to code translation.","ArXiv",2022,"Freda Shi,Daniel Fried,Marjan Ghazvininejad,Luke Zettlemoyer,Sida I. Wang",12,46,4,"https://www.semanticscholar.org/paper/47e15941c8b157873c8264e4bf50318d1ba5cd18"
"6050454e0446a3068617f73b0301453f3f67844d",2,"Stylette: Styling the Web with Natural Language","Stylette is a browser extension that enables users to change the style of websites by expressing goals in natural language, and shows that Stylette lowered the learning curve, helping participants perform styling changes 35% faster than those using developer tools.","International Conference on Human Factors in Computing Systems",2022,"Tae Soo Kim,Yoonseo Choi,D. Choi,Juho Kim",1,65,0,"https://www.semanticscholar.org/paper/6050454e0446a3068617f73b0301453f3f67844d"
"3fbc8d04a1f3dba58bdaada1924ee132512e98be",2,"Productivity assessment of neural code completion","It is found that the rate with which shown suggestions are accepted, rather than more specific metrics regarding the persistence of completions in the code over time, drives developers’ perception of productivity.","MAPS@PLDI",2022,"Albert Ziegler,Eirini Kalliamvakou,Shawn Simister,Ganesh Sittampalam,X. A. Li,A. Rice,Devon Rifkin,E. Aftandilian",15,23,2,"https://www.semanticscholar.org/paper/3fbc8d04a1f3dba58bdaada1924ee132512e98be"
"58aacb967cc7fc25cfc9d51b7ad3e57ac00d119b",2,"Can Foundation Models Wrangle Your Data?","It is found that large FMs generalize and achieve SoTA performance on data cleaning and integration tasks, even though they are not trained for these data tasks.","Proceedings of the VLDB Endowment",2022,"A. Narayan,Ines Chami,Laurel J. Orr,Christopher R'e",6,91,1,"https://www.semanticscholar.org/paper/58aacb967cc7fc25cfc9d51b7ad3e57ac00d119b"
"0bcd59da541fdae66884afba8d25475a54a9da1a",2,"Automated Repair of Programs from Large Language Models","The study revealed that automatically generated code shares common programming mistakes with human-crafted solutions, indicating APR techniques may have potential to auto-generated code, and given bug location information provided by a statistical fault localization approach, Codex edit mode is similar to or better than existing Java repair tools TBar and Recoder in correcting incorrect solutions.","",2022,"Zhiyu Fan,Xiang Gao,M. Mirchev,Abhik Roychoudhury,Shin Hwei Tan",0,49,0,"https://www.semanticscholar.org/paper/0bcd59da541fdae66884afba8d25475a54a9da1a"
"6074c7b75f27ca9adb6d74b080c07d5d079c3ea0",2,"Improving automatically generated code from Codex via Automated Program Repair","This study systematically study whether automated program repair (APR) techniques can fix the incorrect solutions produced by language models in LeetCode contests, revealing that automatically generated codes share some common programming mistakes with human-crafted solutions, indicating existing APR tools have the potential to fix auto-generated code.","ArXiv",2022,"Zhiyu Fan,Xiang Gao,Abhik Roychoudhury,Shin Hwei Tan",4,45,0,"https://www.semanticscholar.org/paper/6074c7b75f27ca9adb6d74b080c07d5d079c3ea0"
"35afb74de9660962ebac2843d26de22a6fac2ef6",2,"Learning from Self-Sampled Correct and Partially-Correct Programs","This work proposes to let the model perform sampling during training and learn from both self-sampled fully-Correct programs, which yield the gold execution results, as well as partially-correct programs, whose intermediate execution state matches another correct program.","ArXiv",2022,"Ansong Ni,J. Inala,Chenglong Wang,Oleksandr Polozov,Christopher Meek,Dragomir R. Radev,Jianfeng Gao",4,28,3,"https://www.semanticscholar.org/paper/35afb74de9660962ebac2843d26de22a6fac2ef6"
"1100dee3fd78655cddc4b7bfaef1161351d4fab5",2,"Automated Feedback Generation for Competition-Level Code","This work presents Clef, the first data-driven tool that can generate feedback on competition-level code automatically by repairing programmers’ incorrect submissions, and introduces a new data structure, merge trees, to capture the changes between submissions.","International Conference on Automated Software Engineering",2022,"Jialu Zhang,De Li,John C. Kolesar,Hanyuan Shi,R. Piskac",1,48,0,"https://www.semanticscholar.org/paper/1100dee3fd78655cddc4b7bfaef1161351d4fab5"
"2edc8efcda27c944a46f367acf6a5280b8f65525",2,"FixEval: Execution-based Evaluation of Program Fixes for Competitive Programming Problems","This work introduces F IX E VAL, a benchmark comprising of buggy code submissions to competitive programming problems and their respective ﬁxes, and believes it provides a step towards real-world automatic bugﬁxing and model-generated code evaluation.","ArXiv",2022,"Md. Mahim Anjum Haque,W. Ahmad,Ismini Lourentzou,Chris Brown",0,56,0,"https://www.semanticscholar.org/paper/2edc8efcda27c944a46f367acf6a5280b8f65525"
"1d160123cbbef972ea151a641dd435d57c727de8",2,"AixBench: A Code Generation Benchmark Dataset","A benchmark dataset for evaluating method-level code generation task and a new metric for automatically evaluating the correctness of the generated code, and a set of criteria to manually evaluating the overall quality of thegenerated code are presented.","ArXiv",2022,"Yiyang Hao,Ge Li,Yongqiang Liu,Xiaowei Miao,He Zong,Siyuan Jiang,Yang Liu,He Wei",1,4,0,"https://www.semanticscholar.org/paper/1d160123cbbef972ea151a641dd435d57c727de8"
"6d994b4f5a46cd14e8f09f1e9e49120546b15e31",2,"CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning","This work proposes “CodeRL”, a new framework for program synthesis tasks through pretrained LMs and deep reinforcement learning (RL), and treats the code-generating LM as an actor network, and introduces a critic network that is trained to predict the functional correctness of generated programs and provide dense feedback signals to the actor.","ArXiv",2022,"Hung Le,Yue Wang,Akhilesh Deepak Gotmare,S. Savarese,S. Hoi",9,77,1,"https://www.semanticscholar.org/paper/6d994b4f5a46cd14e8f09f1e9e49120546b15e31"
"b31b21d0750e849badfe76000e8170482f32b9be",2,"DocCoder: Generating Code by Retrieving and Reading Docs","DocCoder is introduced : an approach that explicitly leverages code manuals and documentation by retrieving the relevant documentation given the natural language intent, and generating the code based on the NL intent and the retrieved documentation.","ArXiv",2022,"Shuyan Zhou,Uri Alon,Frank F. Xu,Zhengbao Jiang,Graham Neubig",3,33,1,"https://www.semanticscholar.org/paper/b31b21d0750e849badfe76000e8170482f32b9be"
"06ea568379211ffa07d9605f66f26f6f736ea5e0",2,"PanGu-Coder: Program Synthesis with Function-Level Language Modeling","A pretrained decoder-only language model adopting the P AN G U - α architecture for text-to-code generation, i.e. the synthesis of programming language solutions given a natural language problem description is presented.","ArXiv",2022,"Fenia Christopoulou,Gerasimos Lampouras,Milan Gritta,Guchun Zhang,Yinpeng Guo,Zhong-Yi Li,Qi Zhang,M. Xiao,Bo Shen,Lin Li,Hao Yu,Li-yu Yan,Pingyi Zhou,Xin Wang,Yu Ma,Ignacio Iacobacci,Yasheng Wang,Guangtai Liang,Jia Wei,Xin Jiang,Qianxiang Wang,Qun Liu",6,72,0,"https://www.semanticscholar.org/paper/06ea568379211ffa07d9605f66f26f6f736ea5e0"
"63c670ba8018da0a7e33c34ffd84c2a3ca54b894",2,"Language Models Can Teach Themselves to Program Better","This work shows how generating synthetic programming puzzles and solutions, veriﬁed for correctness by a Python interpreter, can be used to improve performance in solving test puzzles from P3, a public benchmark set of Python Programming Puzzles.","ArXiv",2022,"Patrick M. Haluptzok,Matthew Bowers,A. Kalai",2,46,1,"https://www.semanticscholar.org/paper/63c670ba8018da0a7e33c34ffd84c2a3ca54b894"
"618d17d60fcdd5da1fd1d1e2b7e19a47af9c9ba7",2,"What is it like to program with artificial intelligence?","This paper explores how programming with large language models (LLM-assisted programming) is similar to, and differs from, prior conceptualisations of programmer assistance, and draws upon publicly available experience reports of LLM- assisted programming, as well as prior usability and design studies.","ArXiv",2022,"Advait Sarkar,A. Gordon,C. Negreanu,Christian Poelitz,Sruti Srinivasa Ragavan,B. Zorn",4,97,2,"https://www.semanticscholar.org/paper/618d17d60fcdd5da1fd1d1e2b7e19a47af9c9ba7"
"453a8fac3be9282be53908f0735160d0d21e0f48",2,"Repair Is Nearly Generation: Multilingual Program Repair with LLMs","This work introduces RING, a multilingual repair engine powered by a large language model trained on code (LLMC) such as Codex that enables a ﬂipped model for programming assistance, one where the programmer writes code and the AI assistance suggests code, compared to traditional code suggestion technology.","ArXiv",2022,"Harshit Joshi,J. Cambronero,Sumit Gulwani,Vu Le,Ivan Radicek,Gust Verbruggen",4,48,0,"https://www.semanticscholar.org/paper/453a8fac3be9282be53908f0735160d0d21e0f48"
"a7435722d8ab595da5a9c70ac9160f57d0dcd75a",2,"Enabling Transformers to Understand Low-Level Programs","This work applies transfer learning to low-level (LLVM) programs and study how low- level programs can be made more amenable to Transformer models through various techniques, including preprocessing, infix/prefix operators, and information deduplication.","IEEE Conference on High Performance Extreme Computing",2022,"Zifan Carl Guo,William S. Moses",0,53,0,"https://www.semanticscholar.org/paper/a7435722d8ab595da5a9c70ac9160f57d0dcd75a"
"8a854331c593c6a766fa3b8037fb2ad1b95a6f06",2,"An Empirical Study of Code Smells in Transformer-based Code Generation Techniques","This study investigates to what extent code smells are present in the datasets of coding generation techniques and verify whether they leak into the output of these techniques.","IEEE Working Conference on Source Code Analysis and Manipulation",2022,"Mohammed Latif Siddiq,Shafayat H. Majumder,Maisha R. Mim,Sourov Jajodia,Joanna C. S. Santos",3,57,1,"https://www.semanticscholar.org/paper/8a854331c593c6a766fa3b8037fb2ad1b95a6f06"
"0c78a473e33a81246d5c0fbbda7e7de168814c18",2,"FlexType: A Plug-and-Play Framework for Type Inference Models","This work introduces FlexType, an IDE extension that can be used on both JavaScript and TypeScript to infer types in an interactive or automatic fashion and believes the interactive Visual Studio Code extension is inherently useful in both TypeScript and JavaScript especially when resolving types is taxing for the developer.","International Conference on Automated Software Engineering",2022,"Sivani Voruganti,Kevin Jesse,Prem Devanbu",0,39,0,"https://www.semanticscholar.org/paper/0c78a473e33a81246d5c0fbbda7e7de168814c18"
"39e40821b7207125e54e6ed7112e55cd38c6f0c3",2,"Language Models of Code are Few-Shot Commonsense Learners","This paper shows that when this task is frame as code generation tasks, pre-trained LMs of code are better structured commonsense reasoners than L Ms of natural language, even when the downstream task does not involve source code at all.","ArXiv",2022,"Aman Madaan,Shuyan Zhou,Uri Alon,Yiming Yang,Graham Neubig",9,38,1,"https://www.semanticscholar.org/paper/39e40821b7207125e54e6ed7112e55cd38c6f0c3"
"5f86bbe35dbca8d932b3110f0c98a6b2d06a0b5b",2,"Reading Between the Lines: Modeling User Behavior and Costs in AI-Assisted Programming","This work studied GitHub Copilot, developed CUPS– a taxonomy of 12 programmer activities common to AI code completion systems, and conducted a study with 21 programmers who completed coding tasks and used the labeling tool to retrospectively label their sessions with CUPS.","ArXiv",2022,"Hussein Mozannar,Gagan Bansal,Adam Fourney,E. Horvitz",0,32,0,"https://www.semanticscholar.org/paper/5f86bbe35dbca8d932b3110f0c98a6b2d06a0b5b"
"41f5e1ad7793593befc0b9c38f756836e8b07c98",2,"Code4ML: a Large-scale Dataset of annotated Machine Learning Code","The Code4ML corpus, which contains code snippets, task summaries, competitions and dataset descriptions publicly available from Kaggle, can potentially help address a number of software engineering or data science challenges through a data-driven approach.","ArXiv",2022,"Anastasia Drozdova,P. Guseva,E. Trofimova,Anna Scherbakova,Andrey Ustyuzhanin",0,34,0,"https://www.semanticscholar.org/paper/41f5e1ad7793593befc0b9c38f756836e8b07c98"
"4fbe0cb0777b228e39243692bf29e2829060b8de",2,"When Language Model Meets Private Library","This paper investigates how to equip pre-trained language models with the ability of code generation for private libraries, and proposes a novel framework with two modules: the APIRetriever and the APICoder, which generates code using these APIs.","ArXiv",2022,"Daoguang Zan,Bei Chen,Zeqi Lin,Bei Guan,Yongji Wang,Jian-Guang Lou",1,40,0,"https://www.semanticscholar.org/paper/4fbe0cb0777b228e39243692bf29e2829060b8de"
"20fae749e3d469c331731ffa2f811079db792fdc",2,"A Simple, Yet Effective Approach to Finding Biases in Code Generation","This work shows that current code generation systems exhibit biases inherited from large language model backbones, which might leak into generated code under specific circumstances, and proposes a framework that automatically removes hints and exposes various biases that these code generation models use.","ArXiv",2022,"Spyridon Mouselinos,Mateusz Malinowski,H. Michalewski",1,43,0,"https://www.semanticscholar.org/paper/20fae749e3d469c331731ffa2f811079db792fdc"
"ae7e1cdd6dbfd375a7fecc558e4565ccc792fba4",2,"Evaluating How Fine-tuning on Bimodal Data Effects Code Generation","It is found that at higher temperatures, there are decreases to the model’s ability to generate runnable programs despite higher pass @ k scores, underscoring the need for better methods of incorporating such data that mitigate these side effects.","ArXiv",2022,"Gabriel Orlanski,Seonhye Yang,Michael Healy",1,31,0,"https://www.semanticscholar.org/paper/ae7e1cdd6dbfd375a7fecc558e4565ccc792fba4"
"e402dd77eba504ea93bc38e2a052398bb95db351",2,"Execution-based Evaluation for Data Science Code Generation Models","ExeDS is introduced, an evaluation dataset for execution evaluation for data science code generation tasks that contains a set of 534 problems from Jupyter Notebooks, each consisting of code context, task description, reference program, and the desired execution output.","ArXiv",2022,"Junjie Huang,Chenglong Wang,Jipeng Zhang,Cong Yan,Haotian Cui,J. Inala,Colin B. Clement,Nan Duan,Jianfeng Gao",2,35,2,"https://www.semanticscholar.org/paper/e402dd77eba504ea93bc38e2a052398bb95db351"
"f3a6115e5fb2237df938976e005468f0b18da797",2,"The Stack: 3 TB of permissively licensed source code","This work introduces The Stack, a 3.1 TB dataset consisting of permissively licensed source code in 30 programming languages, and describes how to collect the full dataset, construct a permissically licensed subset, and present a data governance plan.","ArXiv",2022,"Denis Kocetkov,Raymond Li,Loubna Ben Allal,Jia Li,Chenghao Mou,Carlos Muñoz Ferrandis,Yacine Jernite,Margaret Mitchell,Sean Hughes,Thomas Wolf,Dzmitry Bahdanau,Leandro von Werra,Harm de Vries",2,38,0,"https://www.semanticscholar.org/paper/f3a6115e5fb2237df938976e005468f0b18da797"
"20b60fb3993d2e9a5af04611f7bdf248e5a3a736",2,"Programming by Example and Text-to-Code Translation for Conversational Code Generation","Modular Programs for Text-guided Hierarchical Synthesis (MPaTHS), a method for integrating Programming by Example and text-to-code systems which uses an accessible natural language interface for synthesizing general programs, is proposed.","ArXiv",2022,"Eli Whitehouse,William Gerard,Yauhen Klimovich,Marc Franco-Salvador",0,21,0,"https://www.semanticscholar.org/paper/20b60fb3993d2e9a5af04611f7bdf248e5a3a736"
"27961ae80ad008bd4006704b1b8fa82664137d69",2,"Coder Reviewer Reranking for Code Generation","Experimental results show that Coder-Reviewer reranking leads to consistent and signiﬁcant improvement (up to 17 % absolute accuracy gain) over reranking with the Coder model only, and when combined with executability ﬁltering,Coder- reviewer reranking can often outperform the minimum Bayes risk method.","ArXiv",2022,"Tianyi Zhang,Tao Yu,Tatsunori Hashimoto,M. Lewis,Wen-tau Yih,Daniel Fried,Sida I. Wang",0,27,0,"https://www.semanticscholar.org/paper/27961ae80ad008bd4006704b1b8fa82664137d69"
"32b58766a1bfcef7ebba07070a272687aa518206",2,"Explicit Knowledge Transfer for Weakly-Supervised Code Generation","It is shown that EKT not only yields better performance than training with expert iteration, but also outperforms knowledge distillation, another form of knowledge transfer, and it is possible for a student model to outperform the teacher using EKT.","ArXiv",2022,"Zhangir Azerbayev,Ansong Ni,Hailey Schoelkopf,Dragomir R. Radev",0,25,0,"https://www.semanticscholar.org/paper/32b58766a1bfcef7ebba07070a272687aa518206"
"9b4055674cd9849f8595240695bed69cd02492bc",2,"A Survey on Natural Language Processing for Programming","This paper comprehensively investigates existing work in natural language processing for programming, rang-ing from early deductive models to the latest competition-level models.","ArXiv",2022,"Qingfu Zhu,Xianzhen Luo,Fang Liu,Cuiyun Gao,Wanxiang Che",0,79,0,"https://www.semanticscholar.org/paper/9b4055674cd9849f8595240695bed69cd02492bc"
"6bc87e51018d6de55011e95a0d43c588dd44a1e8",2,"ERNIE-Code: Beyond English-Centric Cross-lingual Pretraining for Programming Languages","This work releases ERNIE-Code, a uniﬁed pre-trained language model for 116 NLs and 6 PLs, and employs two methods for universal cross-lingual pre-training: span-corruption language modeling that learns patterns from monolingual NL or PL; and pivot-based translationlanguage modeling that re-lies on parallel data of manyNLs and PLs.","ArXiv",2022,"Yekun Chai,Shuohuan Wang,Chao Pang,Yu Sun,Hao Tian,Hua Wu",1,42,0,"https://www.semanticscholar.org/paper/6bc87e51018d6de55011e95a0d43c588dd44a1e8"
"ae441f7305dc2cd58c708528b3ecee3501cc5c46",2,"Plansformer: Generating Symbolic Plans using Transformers","The use of LLMs for automated planning - a branch of AI concerned with the realization of action sequences (plans) to achieve a goal, typically executed by intelligent agents, autonomous robots, and unmanned vehicles are explored.","ArXiv",2022,"Vishal Pallagani,Bharath Muppasani,K. Murugesan,F. Rossi,L. Horesh,Biplav Srivastava,F. Fabiano,Andrea Loreggia",0,36,0,"https://www.semanticscholar.org/paper/ae441f7305dc2cd58c708528b3ecee3501cc5c46"
"6756fcd998caeb7b23702e08559e63710179334c",2,"Reasoning with Language Model Prompting: A Survey","This paper provides a comprehensive survey of cutting-edge research on reasoning with language model prompting and introduces research works with comparisons and summaries and provides systematic resources to help beginners.","ArXiv",2022,"Shuofei Qiao,Yixin Ou,Ningyu Zhang,Xiang Chen,Yunzhi Yao,Shumin Deng,Chuanqi Tan,Fei Huang,Huajun Chen",3,150,0,"https://www.semanticscholar.org/paper/6756fcd998caeb7b23702e08559e63710179334c"
"690c210564226c9307b3bab977cdc07a6a45863a",2,"Execution-Based Evaluation for Open-Domain Code Generation","ODEX corroborates the mer-its of execution-based evaluation over metrics without execution but also unveils their complementary effects, and is released to facilitate research into open-domain problems for the code generation community.","ArXiv",2022,"Zhiruo Wang,Shuyan Zhou,Daniel Fried,Graham Neubig",0,30,0,"https://www.semanticscholar.org/paper/690c210564226c9307b3bab977cdc07a6a45863a"
"ab8a53be2ff8a756776aa0245ad8da41189d60d6",2,"Fuzzing Deep-Learning Libraries via Large Language Models","LLMFuzz is the first automated approach to directly leveraging Large Pre-trained Language Models (LLMs) to generate input programs for fuzzing DL libraries, and is able to detect 65 bugs, with 41 already confirmed as previously unknown bugs.","ArXiv",2022,"Yinlin Deng,Chun Xia,Haoran Peng,Chenyuan Yang,Lingming Zhang",0,65,0,"https://www.semanticscholar.org/paper/ab8a53be2ff8a756776aa0245ad8da41189d60d6"
"69e330037afd18e5546fdcacbc9a9f7deb69bba9",2,"Memorization and Generalization in Neural Code Intelligence Models","This work evaluates the memorization and generalization tendencies in neural code intelligence models through a case study across several benchmarks and model families by leveraging established approaches from other fields that use DNNs, such as introducing targeted noise into the training dataset.","Information and Software Technology",2021,"Md Rafiqul Islam Rabin,Aftab Hussain,V. Hellendoorn,Mohammad Amin Alipour",8,93,0,"https://www.semanticscholar.org/paper/69e330037afd18e5546fdcacbc9a9f7deb69bba9"
"907a77639069bb7dd270f017068745706133cffc",2,"Inaccessible Neural Language Models Could Reinvigorate Linguistic Nativism","This work argues that this lack of accessibility could instill a nativist bias in researchers new to computational linguistics, and calls upon researchers to open source their LLM code wherever possible to allow both empircist and hybrid approaches to remain accessible.","ArXiv",2023,"Patrick Perrine",0,56,0,"https://www.semanticscholar.org/paper/907a77639069bb7dd270f017068745706133cffc"
"642e280df732665249315d6c144871f0e2ceeae6",1,"NeurIPS 2020 NLC2CMD Competition: Translating Natural Language to Bash Commands","The NLC2CMD Competition hosted at NeurIPS 2020 aimed to bring the power of natural language processing to the command line by building models that can transform descriptions of command line tasks in English to their Bash syntax.","NeurIPS",2021,"Mayank Agarwal,T. Chakraborti,Quchen Fu,David Gros,Xi Victoria Lin,Jaron Maene,Kartik Talamadupula,Zhongwei Teng,Jules White",7,41,3,"https://www.semanticscholar.org/paper/642e280df732665249315d6c144871f0e2ceeae6"
"f5eb526492798dd7a53fe78f28431f5f489192da",1,"A Survey on Semantic Parsing for Machine Programming","An overview of the growing body of research in natural language semantic parsing techniques and extracting lessons from the evolution of semantic parsing is provided, drawing parallels between modern efforts in neural semantic parsing and program synthesis.","",2021,"Celine Lee,Justin Emile Gottschlich,D. Roth",0,89,0,"https://www.semanticscholar.org/paper/f5eb526492798dd7a53fe78f28431f5f489192da"
"27e3ca4fd7b8290a0e12ca4fd2b7ad5bcd5900f2",1,"Are Transformers All That Karel Needs?","By changing the base architecture to a transformer based one, speciﬁcally GPT2, this work is able to apply simple execution guidance on top to achieve a generalization accurary of 89.64%, which is within 2.36 percentage points of the current state-of-the-art on Karel which uses ensembling.","",2021,"Abhay Garg,Anand Sriraman,Kunal Pagarey,S. Karande",0,37,0,"https://www.semanticscholar.org/paper/27e3ca4fd7b8290a0e12ca4fd2b7ad5bcd5900f2"
"6a1b25f7a67395ad1e676027322913acbb0a0635",1,"CUAD: An Expert-Annotated NLP Dataset for Legal Contract Review","It is found that Transformer models have nascent performance, but that this performance is strongly influenced by model design and training dataset size, so there is still substantial room for improvement.","NeurIPS Datasets and Benchmarks",2021,"Dan Hendrycks,Collin Burns,Anya Chen,Spencer Ball",38,26,10,"https://www.semanticscholar.org/paper/6a1b25f7a67395ad1e676027322913acbb0a0635"
"27d16a7f2ce8f2b787b34ff1f9b4fece079700c3",1,"Figuring out Figures: Using Textual References to Caption Scientific Figures","This work uses the S CI C AP datasets curated by Hsu et al. and uses a variant of a CLIP+GPT-2 encoder-decoder model with cross-attention to generate captions conditioned on the image, and uses SciBERT to encode the textual metadata and uses this encoding alongside the figure embedding.","",2022,"Stanley Cao,Kevin Liu",0,25,0,"https://www.semanticscholar.org/paper/27d16a7f2ce8f2b787b34ff1f9b4fece079700c3"
"7497360b0f411a44aa6afbd8b830050c40ec8aed",1,"Dataset of Student Solutions to Algorithm and Data Structure Programming Assignments","This paper presents a dataset containing source code solutions to algorithmic programming exercises solved by hundreds of Bachelor-level students at the University of Hamburg, and plans to extend the dataset with tasks and solutions from upcoming courses.","International Conference on Language Resources and Evaluation",2022,"Fynn Petersen-Frey,Marcus Soll,Louis Kobras,Melf Johannsen,Peter Kling,Chris Biemann",0,18,0,"https://www.semanticscholar.org/paper/7497360b0f411a44aa6afbd8b830050c40ec8aed"
"407b9e9478ba6bff43ce4b20e8b6cb2b303477d2",1,"P LANNING WITH L ARGE L ANGUAGE M ODELS FOR C ODE G ENERATION","A novel Transformer decoding algorithm that uses a planning algorithm to do lookahead search and guide the Transformer to generate better programs, and enables controllable code generation, such as concise codes and highly-commented codes by optimizing modified objectives.","",2022,"",0,43,0,"https://www.semanticscholar.org/paper/407b9e9478ba6bff43ce4b20e8b6cb2b303477d2"
"04ff95e0edc3759fc5d18a1b929b3ccf79b032b2",1,"Deconstructing Distributions: A Pointwise Framework of Learning","This work studies a point’s profile : the relationship between models’ average performance on the test distribution and their pointwise performance on this individual point, and finds that profiles can yield new insights into the structure of both models and data—in and out-of-distribution.","ArXiv",2022,"Gal Kaplun,Nikhil Ghosh,S. Garg,B. Barak,Preetum Nakkiran",6,90,0,"https://www.semanticscholar.org/paper/04ff95e0edc3759fc5d18a1b929b3ccf79b032b2"
"1c1ca2392155ddf30408a442e6b504b5d60d4f2a",1,"When to Make Exceptions: Exploring Language Models as Accounts of Human Moral Judgment","This paper presents a novel challenge set consisting of rule-breaking question answering (RBQA) of cases that involve potentially permissible rule- Breaking – inspired by recent moral psychology studies and proposes a novel moral chain of thought prompting strategy that combines the strengths of LLMs with theories of moral reasoning developed in cognitive science to predict human moral judgments.","ArXiv",2022,"Zhijing Jin,Sydney Levine,Fernando Gonzalez,Ojasv Kamal,Maarten Sap,Mrinmaya Sachan,Rada Mihalcea,J. Tenenbaum,B. Schölkopf",1,78,0,"https://www.semanticscholar.org/paper/1c1ca2392155ddf30408a442e6b504b5d60d4f2a"
"a4c216d2ce9dd245c84771acc574722055967fd6",1,"Enhancing Code Classification by Mixup-Based Data Augmentation","A Mixup-based data augmentation approach, MixCode, to enhance the source code classiﬁcation task, which employs multiple code refactoring methods to generate label-consistent code data.","ArXiv",2022,"Zeming Dong,Qiang Hu,Yuejun Guo,Maxime Cordy,Mike Papadakis,Yves Le Traon,Jianjun Zhao",0,79,0,"https://www.semanticscholar.org/paper/a4c216d2ce9dd245c84771acc574722055967fd6"
"cb123f1afd67fb8bae15dc876709c842b626c49c",1,"SimSCOOD: Systematic Analysis of Out-of-Distribution Behavior of Source Code Models","This work contributes the first systematic approach that simulates various OOD scenarios along different dimensions of data properties and investigates the model behaviors in such scenarios and provides insights and sheds light for future research in terms of generalization, ro-bustness, and inductive biases of source code models.","ArXiv",2022,"Hossein Hajipour,Ning Yu,Cristian-Alexandru Staicu,Mario Fritz",0,43,0,"https://www.semanticscholar.org/paper/cb123f1afd67fb8bae15dc876709c842b626c49c"
"205ac1373eb7981aca2d08f2ab651871a001271e",1,"CrystalBLEU: Precisely and Efficiently Measuring the Similarity of Code","The results show that CrystalBLEU differentiates similar and unrelated programs better than the original BLEU score and also a variant designed specifically for source code, CodeBLEU.","2022 IEEE/ACM 44th International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)",2022,"A. Eghbali,Michael Pradel",1,55,0,"https://www.semanticscholar.org/paper/205ac1373eb7981aca2d08f2ab651871a001271e"
"45a37f351bb275d22354b712c78df65715a37cc5",1,"CrystalBLEU: Precisely and Efficiently Measuring the Similarity of Code","The metric preserves the desirable properties of BLEU, such as being language-agnostic, able to handle incomplete or partially incorrect code, and efficient, while reducing the noise caused by trivially shared n-grams.","International Conference on Automated Software Engineering",2022,"A. Eghbali,Michael Pradel",0,55,0,"https://www.semanticscholar.org/paper/45a37f351bb275d22354b712c78df65715a37cc5"
"cdec75f901a93c75ee5386a98abbe44746286e80",1,"Delivering Fairness in Human Resources AI: Mutual Information to the Rescue","This paper proposes to minimize the MI between a candidate’s name and a latent representation of their CV or short biography to mitigate bias from sensitive variables without requiring the collection of these variables.","AACL",2022,"L'eo Hemamou,Willi Coleman",0,46,0,"https://www.semanticscholar.org/paper/cdec75f901a93c75ee5386a98abbe44746286e80"
"82d9f1db6db43cb61fe4b0b26a489a2e72628675",1,"A Test for Evaluating Performance in Human-Computer Systems","This work shows how to perform a Turing test for comparing computer performance to that of humans using the ratio of means as a measure of effect size, and shows that 50 human non- programmers using GPT-3 can perform the task about as well as–and less expensively than–the human programmers.","ArXiv",2022,"Andres Campero,Michelle Vaccaro,Jaeyoon Song,Haoran Wen,Abdullah Almaatouq,T. Malone",1,79,0,"https://www.semanticscholar.org/paper/82d9f1db6db43cb61fe4b0b26a489a2e72628675"
"1c336c18e53ad878bf4688c864acd99f137ae29f",1,"Interactive Code Generation via Test-Driven User-Intent Formalization","This paper proposes the workflow of test-driven user-intent formalization (TDUIF), which leverages lightweight user feedback to jointly formalize the user intent as tests (a partial specification), and generates code that meets the formal user intent.","ArXiv",2022,"Shuvendu K. Lahiri,Aaditya Naik,Georgios Sakkas,Piali Choudhury,Curtis von Veh,M. Musuvathi,J. Inala,Chenglong Wang,Jianfeng Gao",2,27,0,"https://www.semanticscholar.org/paper/1c336c18e53ad878bf4688c864acd99f137ae29f"
"e5993b3afe6384b5e6f90093989773ad1f868f71",1,"Towards Top-Down Deep Code Generation in Limited Scopes","A semantic pyramid framework (SPF) is proposed as the approach, focusing on softwares of high modularity and low complexity, and introduces a three-layer semantic pyramid (SP) to associate text data and code data.","ArXiv",2022,"Jian Gu,H. Gall",0,38,0,"https://www.semanticscholar.org/paper/e5993b3afe6384b5e6f90093989773ad1f868f71"
"2cfd0dacfa267a64a23392332c358d4e3ec6fbd4",1,"The COVID That Wasn’t: Counterfactual Journalism Using GPT","","LATECHCLFL",2022,"S. Hamilton,Andrew Piper",1,33,0,"https://www.semanticscholar.org/paper/2cfd0dacfa267a64a23392332c358d4e3ec6fbd4"
"8a9e437b2e2d813b402ac560c852ef0ab2f1cd3c",1,"Recognizing Families In the Wild (RFIW): The 4th Edition","The purpose of this paper is to describe the 2020 RFIW challenge, end-to-end, along with forecasts in promising future directions.","IEEE International Conference on Automatic Face & Gesture Recognition",2020,"Joseph P. Robinson,Yu Yin,Zaid Khan,Ming Shao,Siyu Xia,Michael Stopa,Samson Timoner,Matthew A. Turk,R. Chellappa,Y. Fu",13,64,3,"https://www.semanticscholar.org/paper/8a9e437b2e2d813b402ac560c852ef0ab2f1cd3c"
"a63535ebbf90d0c51408252c23b85ffaf87f09ae",1,"Towards an AI Assistant for Power Grid Operators","The vision of a new assistant framework rely- ing on an hypervision interface and greater bidirectional interaction is exposed, and the known principles of decision-making driving the assistant design alongside with its supporting assistance functions are reviewed.","HHAI",2020,"Antoine Marot,Alexandre Rozier,Matthieu Dussartre,Laure Crochepierre,Benjamin Donnot",2,111,0,"https://www.semanticscholar.org/paper/a63535ebbf90d0c51408252c23b85ffaf87f09ae"
"4ff14a0580f3b36a9564ec18a51d2ce1d4eafebc",1,"Learning Methods for Solving Astronomy Course Problems","This work trains a specialized machine learning model to solve university undergraduate level Introduction to Astronomy course problems using a Transformer trained on both text and code, namely OpenAI Codex, and introduces the concept of turning questions into programming tasks.","",2021,"Avi Shporer,Brandon Kates",2,34,0,"https://www.semanticscholar.org/paper/4ff14a0580f3b36a9564ec18a51d2ce1d4eafebc"
"bab6893ee48d168d27c227c3b0867f6d471fbea8",1,"Language Models are not Models of Language","It is argued that the term language model is misleading because deep learning models are not theoretical models of language and proposed the adoption of corpus model instead, which better reflects the genesis and contents of the model.","ArXiv",2021,"C. Veres",0,58,0,"https://www.semanticscholar.org/paper/bab6893ee48d168d27c227c3b0867f6d471fbea8"
"b874faa9c6cfb5d7e87e3d79650007ade1394958",1,"Creating new Program Proofs by Combining Abductive and Deductive Reasoning","The abduction system that creates new formal specifications by leveraging a small set of inspiring artefacts to augment a subset of candidate problems by employing knowledge graphs to represent the raw data, discovering latent similarities between graphs using a graph-matching process.","International Conference on Innovative Computing and Cloud Computing",2021,"Kuruvilla George Aiyankovil,D. O'Donoghue,Rosemary Monahan",1,13,0,"https://www.semanticscholar.org/paper/b874faa9c6cfb5d7e87e3d79650007ade1394958"
"d66e80224cda0c1d5a4c1be3798df6a6bfe3713c",1,"GPT-3 for Few-Shot Dialogue State Tracking","It is found that natural language instructions in the prompt have little impact on performance, larger language models do not always induce higher downstream performance and that GPT-3 is highly sensitive to the order and number of the in-context examples.","",2021,"Nicholas Pezzotti",0,51,0,"https://www.semanticscholar.org/paper/d66e80224cda0c1d5a4c1be3798df6a6bfe3713c"
"a3c2b81d8bb5ac69771ed7830d009310d98ac9dc",1,"A First Approach to AGI-based Robot Task Planning","An existing proto-Artificial General Intelligence system, namely OpenCog, is extended and given the ability to effectively solve manipulation tasks whose domains contain four actions: pick, place, stack, and unstack.","AIRO@AI*IA",2021,"Michele Thiella,E. Tosello,E. Pagello",0,23,0,"https://www.semanticscholar.org/paper/a3c2b81d8bb5ac69771ed7830d009310d98ac9dc"
"007153d786caa906255fba2ca265fd67994f8b44",1,"Tracking Blobs in the Turbulent Edge Plasma of Tokamak Fusion Reactors","This work tracks the shape and the position of blobs in high frequency video data obtained from Gas Puff Imaging (GPI) diagnostics, by training a mask R-CNN model on synthetic data and testing on both synthetic and real data.","ArXiv",2021,"W. Han,RA Pietersen,Rafael Villamor-Lora,Matthew Beveridge,N. Offeddu,T. Golfinopoulos,C. Theiler,J. Terry,E. Marmar,Iddo Drori",0,13,0,"https://www.semanticscholar.org/paper/007153d786caa906255fba2ca265fd67994f8b44"
"4da830b6d84e117cb147ff71f205e71500ebbbb1",1,"Machines and Influence","It is suggested that better regulation and management of information systems can more optimally offset the risks of AI and utilise the emerging capabilities which these systems have to offer to policymakers and political institutions across the world.","",2021,"Shashank Yadav",0,128,0,"https://www.semanticscholar.org/paper/4da830b6d84e117cb147ff71f205e71500ebbbb1"
"021bbcefc993c389bad6c1daefd8ff92d0fc2441",1,"Contrastive Code Representation Learning","Contracode is proposed: a contrastive pre-training task that learns code functionality, not form, and improves summarization and TypeScript type inference accuracy by 2 to 13 percentage points over competitive baselines.","Conference on Empirical Methods in Natural Language Processing",2020,"Paras Jain,Ajay Jain,Tianjun Zhang,P. Abbeel,Joseph Gonzalez,I. Stoica",60,94,10,"https://www.semanticscholar.org/paper/021bbcefc993c389bad6c1daefd8ff92d0fc2441"
"4f278ab5ad629267e06196e273252262854c1c57",1,"BF++: a language for general-purpose program synthesis","A new programming language, BF ++ is proposed, designed speciﬁcally for automatic programming of agents in a Partially Observable Markov Decision Process (POMDP) setting and apply neural program synthesis to solve standard OpenAI Gym benchmarks.","",2021,"Vadim Liventsev,A. Harma,M. Petkovi'c",0,57,0,"https://www.semanticscholar.org/paper/4f278ab5ad629267e06196e273252262854c1c57"
"57d1e7ac339e783898f2c3b1af55737cbeee9fc5",1,"Measuring Mathematical Problem Solving With the MATH Dataset","This work introduces MATH, a new dataset of 12, 500 challenging competition mathematics problems which can be used to teach models to generate answer derivations and explanations, and shows that accuracy remains relatively low, even with enormous Transformer models.","NeurIPS Datasets and Benchmarks",2021,"Dan Hendrycks,Collin Burns,Saurav Kadavath,Akul Arora,Steven Basart,Eric Tang,D. Song,J. Steinhardt",85,65,19,"https://www.semanticscholar.org/paper/57d1e7ac339e783898f2c3b1af55737cbeee9fc5"
"09279dc8018a8131e11d527cebb06d0a43c67cff",1,"Creativity and Machine Learning: A Survey","An overview of the history and the state of the art of computational creativity theories, key machine learning techniques (including generative deep learning), and corresponding automatic evaluation methods is presented.","ArXiv",2021,"Giorgio Franceschelli,Mirco Musolesi",13,285,1,"https://www.semanticscholar.org/paper/09279dc8018a8131e11d527cebb06d0a43c67cff"
"98485ce6532d69f34a8ec67de6b09a39532bd221",1,"Communicating Natural Programs to Humans and Machines","LARC, the Language-complete ARC is presented, a collection of natural language descriptions by a group of human participants who instruct each other on how to solve ARC tasks using language alone, which contains successful instructions for 88% of the ARC tasks.","ArXiv",2021,"Samuel Acquaviva,Yewen Pu,Marta Kryven,Catherine Wong,Gabrielle Ecanow,Maxwell Nye,Theo Sechopoulos,Michael Henry Tessler,J. Tenenbaum",7,87,0,"https://www.semanticscholar.org/paper/98485ce6532d69f34a8ec67de6b09a39532bd221"
"26450917d41c828b470ec8818d49f59516a5b9c0",1,"Towards Universality in Multilingual Text Rewriting","This work takes the first steps towards building a universal rewriter: a model capable of rewriting text in any language to exhibit a wide variety of attributes, including styles and languages, while preserving as much of the original semantics as possible.","ArXiv",2021,"Xavier García,Noah Constant,Mandy Guo,Orhan Firat",4,36,0,"https://www.semanticscholar.org/paper/26450917d41c828b470ec8818d49f59516a5b9c0"
"5436193122dff271796bca07df7cecb7a8d6dea6",1,"Natural language-guided programming","The key idea is to adapt code autocompletion tools such that they take into account not only the developer’s already-written code but also the intent of the task the developer is trying to achieve next, formulated in plain natural language.","SIGPLAN symposium on New ideas, new paradigms, and reflections on programming and software",2021,"Geert Heyman,Rafael Huysegems,P. Justen,Tom Van Cutsem",5,53,1,"https://www.semanticscholar.org/paper/5436193122dff271796bca07df7cecb7a8d6dea6"
"4885e616e85d420576196b2578525cbc501137ec",1,"Programming and execution models for next generation code intelligence systems (keynote)","","ESEC/SIGSOFT FSE",2021,"M. Mezini",0,22,0,"https://www.semanticscholar.org/paper/4885e616e85d420576196b2578525cbc501137ec"
"3f97c2067cde9377e50b3160bbd7982c94abd88a",1,"An Empirical Cybersecurity Evaluation of GitHub Copilot's Code Contributions","This work systematically investigates the prevalence and conditions that can cause GitHub Copilot to recommend insecure code, and explores Copilot’s performance on three distinct code generation axes—examining how it performs given diversity of weaknesses, diversity of prompts, and diversity of domains.","ArXiv",2021,"H. Pearce,Baleegh Ahmad,Benjamin Tan,Brendan Dolan-Gavitt,R. Karri",19,29,1,"https://www.semanticscholar.org/paper/3f97c2067cde9377e50b3160bbd7982c94abd88a"
"70087677fd1a6309829b42968934575d05a95f92",1,"What do pre-trained code models know about code?","Four probing tasks are constructed (probing for surface-level, syntactic, structural, and semantic information) for pre-trained code models to identify whether models are deficient in (understanding) certain code properties, characterize different model layers, and get insight into the model sample-efficiency.","International Conference on Automated Software Engineering",2021,"Anjan Karmakar,R. Robbes",19,34,2,"https://www.semanticscholar.org/paper/70087677fd1a6309829b42968934575d05a95f92"
"a176b0de62840f7118006277d94bbc1547162a4d",1,"Learning to Synthesize Programs as Interpretable and Generalizable Policies","Experimental results demonstrate that the proposed framework not only learns to reliably synthesize task-solving programs but also outperforms DRL and program synthesis baselines while producing interpretable and more generalizable policies.","Neural Information Processing Systems",2021,"Dweep Trivedi,Jesse Zhang,Shao-Hua Sun,Joseph J. Lim",13,131,2,"https://www.semanticscholar.org/paper/a176b0de62840f7118006277d94bbc1547162a4d"
"a30f912f8c5e2a2bfb06351d4578e1ba3fa37896",1,"CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation","Comprehensive experiments show that CodeT5 significantly outperforms prior methods on understanding tasks such as code defect detection and clone detection, and generation tasks across various directions including PL-NL, NL-PL, and PL-PL.","Conference on Empirical Methods in Natural Language Processing",2021,"Yue Wang,Weishi Wang,Shafiq R. Joty,S. Hoi",170,40,66,"https://www.semanticscholar.org/paper/a30f912f8c5e2a2bfb06351d4578e1ba3fa37896"
"b8b21c2ddcd7d1c23d7ccfceabb63cb1a05bcfca",1,"HYDRA - Hyper Dependency Representation Attentions","This paper proposes HYDRA heads, lightweight pretrained linguistic self-attention heads to inject knowledge into transformer models without pretraining them again, and empirically verify the framework on benchmark datasets to show the contribution of linguistic knowledge to a transformer model.","ArXiv",2021,"Nguyen Ha Thanh,Vu D. Tran,Binh Dang,Minh Q. Bui,Minh Le Nguyen,Le-Minh Nguyen",0,24,0,"https://www.semanticscholar.org/paper/b8b21c2ddcd7d1c23d7ccfceabb63cb1a05bcfca"
"bc9598dc4ed0472d8b59b87ed3a139f8347d40ee",1,"Towards A Measure Of General Machine Intelligence","A common language of instruction is proposed, a programming language that allows the expression of programs in the form of directed acyclic graphs across a wide variety of real-world domains and computing platforms and evaluates the suitability of some well-known models as general intelligence systems by calculating their g-index scores.","ArXiv",2021,"Gautham Venkatasubramanian,Sibesh Kar,Abhimanyu Singh,Shubham Mishra,Dushyant Yadav,Shreyansh Chandak",0,71,0,"https://www.semanticscholar.org/paper/bc9598dc4ed0472d8b59b87ed3a139f8347d40ee"
"05c2e1ee203be217f100d2da05bdcc52004f00b6",1,"Unsolved Problems in ML Safety","This work provides a new roadmap for ML Safety and presents four problems ready for research, namely withstanding hazards, identifying hazards, steering ML systems, and reducing deployment hazards.","ArXiv",2021,"Dan Hendrycks,Nicholas Carlini,J. Schulman,J. Steinhardt",59,217,4,"https://www.semanticscholar.org/paper/05c2e1ee203be217f100d2da05bdcc52004f00b6"
"6c2d43e71e240e354b5790a38da78a291ceffe7c",1,"Learning to Superoptimize Real-world Programs","A framework to learn to superoptimize real-world programs by using neural sequence-to-sequence models, and an approach to implement and outperforms a standard policy gradient learning approach on this dataset.","ArXiv",2021,"Alex Shypula,P. Yin,Jeremy Lacomis,Claire Le Goues,E. Schwartz,Graham Neubig",2,37,0,"https://www.semanticscholar.org/paper/6c2d43e71e240e354b5790a38da78a291ceffe7c"
"24e775b20adf21e9b5b95c6a9b7a5c164d055849",1,"M6-10T: A Sharing-Delinking Paradigm for Efficient Multi-Trillion Parameter Pretraining","This paper demonstrates a practice of pretraining unprecedented 10-trillion-parameter model, an order of magnitude larger than the state-of-the-art, on solely 512 GPUs within 10 days, and provides a technique, Granular CPU offloading, to manage CPU memory for training large model and maintain high GPU utilities.","ArXiv",2021,"Junyang Lin,An Yang,Jinze Bai,Chang Zhou,Le Jiang,Xianyan Jia,Ang Wang,J. Zhang,Yong Li,Wei Lin,Jingren Zhou,Hongxia Yang",19,52,0,"https://www.semanticscholar.org/paper/24e775b20adf21e9b5b95c6a9b7a5c164d055849"
"360e0197378799d890f473893cc0c773b8182b4e",1,"Searching for Replacement Classes","This work introduces ClassFinder, a system which given a query class Q, and a search corpus S, returns a ranked subset of classes that can replace Q and its functionality, and leverages the complementary strengths of a distributed embeddingsbased search and type-based analysis.","ArXiv",2021,"Malavika Samak,J. Cambronero,M. Rinard",1,36,0,"https://www.semanticscholar.org/paper/360e0197378799d890f473893cc0c773b8182b4e"
"9991bb2eb7e7d7e9d831e257ae77ba2eaeaba3dc",1,"Applying quantum approximate optimization to the heterogeneous vehicle routing problem","","",2021,"David Fitzek,Toheed Ghandriz,L. Laine,M. Granath,A. F. Kockum",6,177,0,"https://www.semanticscholar.org/paper/9991bb2eb7e7d7e9d831e257ae77ba2eaeaba3dc"
"21bc4ead8ea415579ab40e437fcbc274929f17c8",1,"Solving the Families In the Wild Kinship Verification Challenge by Program Synthesis","This work uses Codex to generate model variants, and also demonstrates its ability to generate entire running programs for kinship verification tasks of specific relationships, among the top 3 winning entries in the competition.","2021 16th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2021)",2021,"Junyi Huang,M. Strome,I. Jenkins,Parker Williams,Bo Feng,Yaning Wang,Roman Wang,Vaibhav Bagri,Newman Cheng,Iddo Drori",1,25,0,"https://www.semanticscholar.org/paper/21bc4ead8ea415579ab40e437fcbc274929f17c8"
"8091e51ebbcd2424a1c5b50c036bae5295090525",1,"Top 3 in FG 2021 Families In the Wild Kinship Verification Challenge","This work demonstrates high quality kinship verification by participating in the 2021 Recognizing Families in the Wild challenge which provides the largest publicly available dataset in the field.","ArXiv",2021,"Junyi Huang,M. Strome,Ian Jenkins,Parker Williams,Bo Feng,Yaning Wang,Roman Wang,Vaibhav Bagri,Newman Cheng,Iddo Drori",3,11,0,"https://www.semanticscholar.org/paper/8091e51ebbcd2424a1c5b50c036bae5295090525"
"dace03e57056d736f9e24937bdf486e894f8e866",1,"Is neural machine translation approach accurate enough for coding assistance?","A transcompiler-based back-translation, a data augmentation method that generates parallel corpora from numerous source code repositories and the resulting BLEU indicates that the proposed model is accurate enough to allow coding assistance in the future.","BCNC@SPLASH",2021,"Yuka Akinobu,Momoka Obara,Teruno Kajiura,Shiho Takano,Miyu Tamura,Mayu Tomioka,Kimio Kuramitsu",2,20,1,"https://www.semanticscholar.org/paper/dace03e57056d736f9e24937bdf486e894f8e866"
"21e8e76386aaaa00e0971af70ce84a8a544e1aa1",1,"Cascaded Fast and Slow Models for Efficient Semantic Code Search","An efficient and accurate semantic code search framework with cascaded fast and slow models, in which a fast transformer encoder model is learned to optimize a scalable index for fast retrieval followed by learning a slow classification-based re-ranking model to improve the performance of the top K results from the fast retrieval.","ArXiv",2021,"Akhilesh Deepak Gotmare,Junnan Li,Shafiq R. Joty,S. Hoi",2,24,0,"https://www.semanticscholar.org/paper/21e8e76386aaaa00e0971af70ce84a8a544e1aa1"
"6a269b1abccdbf57e79b3f115a97bff14b435ad9",1,"Automated Support for Unit Test Generation: A Tutorial Book Chapter","This chapter introduces two algorithms that can generate pytest-formatted unit tests, tuned towards coverage of source code statements, and introduces the concept of search-based unit test generation.","ArXiv",2021,"Afonso Fontes,Gregory Gay,F. G. O. Neto,R. Feldt",1,32,0,"https://www.semanticscholar.org/paper/6a269b1abccdbf57e79b3f115a97bff14b435ad9"
"9f260bdd4030af5297a9c1cbb817c75701ac8c83",1,"The 5th Recognizing Families in the Wild Data Challenge: Predicting Kinship from Faces","Submissions for this year's RFIW are summarized, and the results for kinship verification, tri-subject verification, and family member search and retrieval are reviewed.","IEEE International Conference on Automatic Face & Gesture Recognition",2021,"Joseph P. Robinson,Can Qin,Ming Shao,Matthew A. Turk,R. Chellappa,Y. Fu",2,54,0,"https://www.semanticscholar.org/paper/9f260bdd4030af5297a9c1cbb817c75701ac8c83"
"c23d9d44e8bc68408cea9f305d1f24d915bc0d0d",1,"Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey","A survey of recent work that uses large, pre-trained transformer-based language models to solve NLP tasks via pre-training then fine-tuning, prompting, or text generation approaches.","ArXiv",2021,"Bonan Min,Hayley H. Ross,Elior Sulem,Amir Pouran Ben Veyseh,Thien Huu Nguyen,Oscar Sainz,Eneko Agirre,Ilana Heinz,D. Roth",34,322,1,"https://www.semanticscholar.org/paper/c23d9d44e8bc68408cea9f305d1f24d915bc0d0d"
"1444536496d8064f33e10b38b5820fecfab5b367",1,"Automatic Program Repair with OpenAI's Codex: Evaluating QuixBugs","This work investigates whether Codex is able to localize and fix bugs, a task of central interest in the field of automated program repair, and finds that, despite not being trained for APR, Codex is surprisingly effective, and competitive with recent state of the art techniques.","ArXiv",2021,"Julian Aron Prenner,R. Robbes",13,22,1,"https://www.semanticscholar.org/paper/1444536496d8064f33e10b38b5820fecfab5b367"
"4e40595d6ecba027cebb4f2e3b43ae44bcf51daf",1,"Solving Linear Algebra by Program Synthesis","This work uses OpenAI Codex with zero-shot learning to synthesize code from questions and quantifies the difference between the original question text and the transformed question text that yields a correct answer.","ArXiv",2021,"Iddo Drori,Nakul Verma",10,17,0,"https://www.semanticscholar.org/paper/4e40595d6ecba027cebb4f2e3b43ae44bcf51daf"
"f7987fa2aadc0b368c185dc4d2fdb1337a202c32",1,"Solving Probability and Statistics Problems by Program Synthesis","This work is the first to introduce a new dataset of university-level probability and statistics problems and solve these problems in a scalable fashion using the program synthesis capabilities of large language models.","ArXiv",2021,"Leonard Tang,Elizabeth Ke,Nikhil Singh,Nakul Verma,Iddo Drori",8,14,1,"https://www.semanticscholar.org/paper/f7987fa2aadc0b368c185dc4d2fdb1337a202c32"
"04db9b694280134f09af5fa787a306907edba29d",1,"How much do language models copy from their training data? Evaluating linguistic novelty in text generation using RAVEN","AVEN, a suite of analyses for assessing the novelty of generated text, focusing on sequential structure (n-grams) and syntactic structure, is introduced, showing that GPT-2's novel text is usually well-formed morphologically and syntactically but has reasonably frequent semantic issues.","ArXiv",2021,"R. Thomas McCoy,P. Smolensky,Tal Linzen,Jianfeng Gao,Asli Celikyilmaz",16,81,2,"https://www.semanticscholar.org/paper/04db9b694280134f09af5fa787a306907edba29d"
"cecc913290736a5a368642c5b59a130eddd1fa7b",1,"Can Pre-trained Language Models be Used to Resolve Textual and Semantic Merge Conflicts?","The feasibility of automatically repairing merge conflicts (both textual and semantic) using k-shot learning with large neural language models (LM) such as GPT-3 is explored and the results are mixed.","ArXiv",2021,"Jialu Zhang,Todd Mytkowicz,Mike Kaufman,R. Piskac,Shuvendu K. Lahiri",0,22,0,"https://www.semanticscholar.org/paper/cecc913290736a5a368642c5b59a130eddd1fa7b"
"21ab011a3adccbd912aea58f76b84b7873c41df3",1,"Machines&Influence: An Information Systems Lens","","",2021,"Shashank Yadav",1,130,0,"https://www.semanticscholar.org/paper/21ab011a3adccbd912aea58f76b84b7873c41df3"
"92173d081b15824d22a9ef070e118744ceee8052",1,"Show Your Work: Scratchpads for Intermediate Computation with Language Models","Surprisingly, large pre-trained language models are able to perform complex multistep computations—even in the few-shot regime—when asked to perform the operation “step by step”, showing the results of intermediate computations.","ArXiv",2021,"Maxwell Nye,Anders Andreassen,Guy Gur-Ari,H. Michalewski,Jacob Austin,David Bieber,David Dohan,Aitor Lewkowycz,Maarten Bosma,D. Luan,Charles Sutton,Augustus Odena",102,30,10,"https://www.semanticscholar.org/paper/92173d081b15824d22a9ef070e118744ceee8052"
"827a67bbb96c8ed34c0f79e2ea811c5b53a6896b",1,"Controllable Response Generation for Assistive Use-cases","This study shows that keyword-control on end-to-end response generation models is powerful and can enable and empower users with degenerative disorders to carry out their dayto-day communication.","ArXiv",2021,"Shachi H. Kumar,Hsuan Su,R. Manuvinakurike,Saurav Sahay,L. Nachman",0,56,0,"https://www.semanticscholar.org/paper/827a67bbb96c8ed34c0f79e2ea811c5b53a6896b"
"ee042a3e299a32c413532e64603de8d3ddb6aa87",1,"Automap: Towards Ergonomic Automated Parallelism for ML Models","This work presents the prototype of an automated partitioner that seamlessly integrates into existing compilers and existing user workflows and enables SPMD-style parallelism that encompasses data parallelism and parameter/activation sharding.","ArXiv",2021,"Michael Schaarschmidt,Dominik Grewe,Dimitrios Vytiniotis,Adam Paszke,G. Schmid,Tamara Norman,James Molloy,Jonathan Godwin,Norman A. Rink,Vinod Nair,Dan Belov",5,36,0,"https://www.semanticscholar.org/paper/ee042a3e299a32c413532e64603de8d3ddb6aa87"
"091fa84bdc07dcb22a34060c3996d8c58d71cd20",1,"Towards Neural Functional Program Evaluation","A new program generation mechanism is introduced that allows control over syntactic sugar for semantically equivalent programs in transformer-based language models for program evaluation of simple functional programming languages.","ArXiv",2021,"Torsten Scholak,Jonathan Pilault,Joey Velez-Ginorio",0,19,0,"https://www.semanticscholar.org/paper/091fa84bdc07dcb22a34060c3996d8c58d71cd20"
"6ccc0ca964ddab19705e4832758e6a2447325348",1,"End to End Software Engineering Research","The dataset is constructed in a way that enables not only predicting concepts but also investigating their causes, and improves over features based machine learning by not requiring domain experts and being able to extract new knowledge.","ArXiv",2021,"Idan Amit",0,71,0,"https://www.semanticscholar.org/paper/6ccc0ca964ddab19705e4832758e6a2447325348"
"58dd9a3da16c10f5c3cdbb9760a9ff378847bf76",1,"Self-supervision of wearable sensors time-series data for influenza detection","The results show that predicting the next day’s resting heart rate or time-in-bed during sleep provides better representations for ILI prediction, adding to previous work demonstrating the practical application of self-supervised learning from activity data to improve health predictions.","ArXiv",2021,"Arinbjörn Kolbeinsson,Piyusha S. Gade,R. Kainkaryam,Filip Jankovic,L. Foschini",1,14,0,"https://www.semanticscholar.org/paper/58dd9a3da16c10f5c3cdbb9760a9ff378847bf76"
"1b94afca9d6688cc584a744734126473283cbc93",1,"Can Transformers be Strong Treatment Effect Estimators?","A general framework based on the Transformer architecture is developed to address a variety of challenging treatment effect estimation (TEE) problems and a propensity score network is proposed that is trained with TransTEE in an adversarial manner to promote independence between covariates and treatments to further address selection bias.","ArXiv",2022,"Yi-Fan Zhang,Hanlin Zhang,Zachary Chase Lipton,Li Erran Li,Eric Xing",8,58,4,"https://www.semanticscholar.org/paper/1b94afca9d6688cc584a744734126473283cbc93"
"856d2c0f7b3f80dcf1f68d1dc0dcbf5c6fe5679a",1,"Interpreting docstrings without using common sense: the private science of very large language models∗","GPT-3, the natural language model on which Codex is built, and that services such as Copilot ultimately depend on, suffers from scientific deficiencies, and critical remarks on Copilot’s structure and underlying language model are presented.","",2022,"Darren Abramson,Ali Emami",0,39,0,"https://www.semanticscholar.org/paper/856d2c0f7b3f80dcf1f68d1dc0dcbf5c6fe5679a"
"78fd8185c5cd55830c31aa718a9909827e20774e",1,"A Research Agenda for Assessing the Economic Impacts of Code Generation Models","","",2022,"Sam Manning,Pamela Mishkin,Gillian K. Hadfield,Tyna,Eloundou,E. Eisner",0,58,0,"https://www.semanticscholar.org/paper/78fd8185c5cd55830c31aa718a9909827e20774e"
"9a2ca811882ed7513f83014b9de4fb3b4ab218c4",1,"C OMPOSITIONAL G ENERALIZATION AND D ECOMPOSITION IN N EURAL P ROGRAM S YNTHESIS","A suite of generalization tasks, which measure different types of compositional generalization that are desirable for program synthesis and are particularly difﬁcult for current sequence to sequence models, are proposed.","",,"",0,0,0,"https://www.semanticscholar.org/paper/9a2ca811882ed7513f83014b9de4fb3b4ab218c4"
"75c8f2916a2067f7549cf58ea8c9061565eb1dab",1,"C ROSS B EAM : L EARNING TO S EARCH IN B OTTOM -U P P ROGRAM S YNTHESIS","This work uses a neural model to learn a hands-on search policy for bottom-up synthesis, instead of relying on a combinatorial search algorithm, and observes that CROSSBEAM learns to search efficiently, exploring much smaller portions of the program space compared to the state-of-the-art.","",2022,"H. Dai,Kevin Ellis,Charles Sutton",0,49,0,"https://www.semanticscholar.org/paper/75c8f2916a2067f7549cf58ea8c9061565eb1dab"
"8a4dce5735a101ff8f64c2b676afb8c24950a5d8",1,"Zero-shot Mathematical Problem Solving via Generative Pre-trained Transformers","The proposed approach shows that coding based problem-solving is more effective than the natural language reasoning based one, and by exploiting the Python as programming language, the proposed pipeline achieves 54.20% solve rate.","International Conference on Enterprise Information Systems",2022,"Federico A. Galatolo,M. Cimino,G. Vaglini",0,9,0,"https://www.semanticscholar.org/paper/8a4dce5735a101ff8f64c2b676afb8c24950a5d8"
"bee0be592c314435048599281bcd9c72bf63b735",1,"CueBot: Cue-Controlled Response Generation for Assistive Interaction Usages","This work builds a system that can represent people with disabilities, or speech and language disorders, in a social conversation and generate responses that can be controlled by the users using cues/keywords and introduces a keyword-loss to lexically constrain the model response output.","Workshop on Speech and Language Processing for Assistive Technologies",2022,"Shachi H. Kumar,Hsuan Su,R. Manuvinakurike,Maximilian Pinaroc,Sai Prasad,Saurav Sahay,L. Nachman",0,52,0,"https://www.semanticscholar.org/paper/bee0be592c314435048599281bcd9c72bf63b735"
"57c31c709792949bfbb9d4aaee941048aa07cc4b",1,"How to Give Imperfect Automated Guidance to Learners: A Case-Study in Workplace Learning","There was tentative evidence that workers’ behaviors were impacted by the FP/FN trade-oﬀ of their assigned experimental condition even after the ML assistant was removed and evidence that learners modulate their behaviors based on the ﬁne-grained conﬁdence values conveyed by the assistant.","International Conference on Artificial Intelligence in Education",2022,"J. Whitehill,Amitai Erfanian",0,18,0,"https://www.semanticscholar.org/paper/57c31c709792949bfbb9d4aaee941048aa07cc4b"
"2e5b29457ff45b8faba69bc2eaf05521584a7bec",1,"B UG F IX G ENERATION USING G RAPH T RANS","This work proposes FIXUR, a new architecture for generating bug fixing edits, by complementing graph neural networks with Transformer to encode the code graph as a graph that encapsulates rich syntactic and semantic dependencies.","",2022,"",0,25,0,"https://www.semanticscholar.org/paper/2e5b29457ff45b8faba69bc2eaf05521584a7bec"
"f01e316d3b28ccecda25b4d57926f496a9b17d3d",1,"How Robust are Neural Code Completion Models to Source Code Transformation?","This work develops a methodology for systematically evaluating neural code completion models using common source code transformations and provides insights into the strengths and weaknesses of different models, and serves as a foundation for future work towards improving the accuracy and robustness of Neural code completion.","",2022,"",0,22,0,"https://www.semanticscholar.org/paper/f01e316d3b28ccecda25b4d57926f496a9b17d3d"
"24c6982a25c0114bc98805d368b06d1a4f6d8fd5",1,"Researching Alignment Research: Unsupervised Analysis","The field is growing quickly, with several subfields emerging in parallel, and a classifier trained on AI alignment research articles can detect relevant articles that were not originally included in the dataset.","ArXiv",2022,"Jan H. Kirchner,Logan Smith,Jacques Thibodeau,Kyle McDonell,Laria Reynolds",0,0,0,"https://www.semanticscholar.org/paper/24c6982a25c0114bc98805d368b06d1a4f6d8fd5"
"b562be15b076b494023b8ac24fc8c459f4fdf80a",1,"Craft an Iron Sword: Dynamically Generating Interactive Game Characters by Prompting Large Language Models Tuned on Code","It is demonstrated that use of a few example conversational prompts can power a conversational agent to generate both natural language and novel code, which can permit development of NPCs with which players can have grounded conversations that are free-form and less repetitive.","WORDPLAY",2022,"Ryan Volum,Sudha Rao,Michael Xu,Gabriel DesGarennes,Chris Brockett,Benjamin Van Durme,Olivia Deng,Akanksha Malhotra,Bill Dolan",3,21,1,"https://www.semanticscholar.org/paper/b562be15b076b494023b8ac24fc8c459f4fdf80a"
"09e14c4c80e20e80c052e0adb0d49df51aff718d",1,"Yes, You Can Make an App Too: A Systematic Study of Prompt Engineering in the Automatic Generation of Mobile Applications from User Queries","One of the first systematic studies of prompt engineering for the Codex model, a LLM that produces code from a natural-language input, is embarked on, improving the pipeline’s performance from baseline for complex apps using example selection mechanisms and 43% for simple apps.","",2022,"Jasmine Shone",0,16,0,"https://www.semanticscholar.org/paper/09e14c4c80e20e80c052e0adb0d49df51aff718d"
"91260f73dd179487fb16713deb8267634ae14716",1,"CodexDB: Synthesizing Code for Query Processing from Natural Language Instructions using GPT-3 Codex","The CodexDB framework is a framework on top of GPT-3 Codex that decomposes complex SQL queries into a series of simple processing steps, described in natural language, that enables users to customize SQL query processing via natural language instructions.","Proceedings of the VLDB Endowment",2022,"Immanuel Trummer",3,39,0,"https://www.semanticscholar.org/paper/91260f73dd179487fb16713deb8267634ae14716"
"9bf75110ea0923bbed49256b5491f1ec284019ec",1,"From BERT to GPT-3 Codex: Harnessing the Potential of Very Large Language Models for Data Management","The goal of the tutorial is to introduce database researchers to the latest generation of language models, and to their use cases in the domain of data management.","Proc. VLDB Endow.",2022,"Immanuel Trummer",0,35,0,"https://www.semanticscholar.org/paper/9bf75110ea0923bbed49256b5491f1ec284019ec"
"ddab94478a7647ee136b1f6b5076417db3074d0f",1,"Machine Programming: Turning Data into Programmer Productivity","An introduction to machine programming is introduced introducing its three pillars: intention, invention, and adaptation, and an overview of the data ecosystem central to all machine programming systems is provided, highlighting challenges and novel opportunities relevant to the data systems community.","Proc. VLDB Endow.",2022,"A. Wasay,Nesime Tatbul,Justin Emile Gottschlich",0,39,0,"https://www.semanticscholar.org/paper/ddab94478a7647ee136b1f6b5076417db3074d0f"
"2443179d421e1faf7474add557b45add554723c7",1,"Formal Premise Selection With Language Models","This work provides a solution to the problem of selecting a useful premise to prove a new theorem by combining a premise selection model with a language model, and shows that this retrieval-augmented prover achieves significant improvements in proof rates compared to the language model alone.","",2022,"Szymon Tworkowski,Maciej Miku la,Tomasz Odrzygóźdź,K. Czechowski,Szymon Antoniak,Albert Qiaochu Jiang,Christian Szegedy,Lukasz Kucinski,Piotr Mi loś,Yuhuai Wu",0,34,0,"https://www.semanticscholar.org/paper/2443179d421e1faf7474add557b45add554723c7"
"15e767aa26a14455da95a2b2f11e3d59f2c250f6",1,"Autoformalization for Neural Theorem Proving","This work demonstrates the feasibility and usefulness of autoformalization in the context of the newly introduced MiniF2F benchmark, and finds that transformer-based language models trained on a large amount of web data are capable of formalizing mathematical competition problem statements with a relatively high success rate.","",2022,"Yuhuai Wu,Albert Qiaochu Jiang,Wenda Li,Markus N. Rabe,Charles Staats,M. Jamnik,Christian Szegedy",0,11,0,"https://www.semanticscholar.org/paper/15e767aa26a14455da95a2b2f11e3d59f2c250f6"
"a1ef81e17a9ca41e09aba802040a2eca2744716f",1,"Generation Probabilities are Not Enough: Improving Error Highlighting for AI Code Suggestions","It is unclear how best to convey the uncertainty of generative models to human operators or if doing so will positively impact human-AI collaboration.","",2022,"Helena Vasconcelos",1,15,0,"https://www.semanticscholar.org/paper/a1ef81e17a9ca41e09aba802040a2eca2744716f"
"cd155729180ea707dea251f8e9654db241ffd808",1,"Is GPT-3 all you need for machine learning for chemistry?","This work analyzes whether one of the largest pre-trained LLMs, GPT-3, can be directly used for chemistry applications by fine-tuning on only a few data points from a chemistry dataset, i.e., without pre-training on a chemistry-specific dataset.","",2022,"K. Jablonka",0,50,0,"https://www.semanticscholar.org/paper/cd155729180ea707dea251f8e9654db241ffd808"
"0180d35b85dd4daead90e0652b64b1339e754684",1,"Assistance with large language models","A behavioral cloning approach is applied to GPT-3 such that it can respond to clear input questions directly, clarify the intent behind vague input questions, and respond based on the clarification it receives, and this approach leads to quantitative improvements in answer accuracy compared to a baseline that cannot ask for clarifications.","",2022,"Dmitrii Krasheninnikov",1,30,0,"https://www.semanticscholar.org/paper/0180d35b85dd4daead90e0652b64b1339e754684"
"e002bb8dae5a18a5ea1e7e1aafa16e19ad545662",1,"Solving Math Word Problems with Process-based and Outcome-based Feedback","This work runs the first comprehensive comparison between process- and outcome- based approaches trained on a natural language task, GSM8K, and finds that pure outcome-based supervision produces similar final-answer error rates with less label supervision.","",2022,"J. Uesato,Nate Kushman,Ramana Kumar,Francis Song,Noah Siegel,L. Wang,Antonia Creswell,Geoffery Irving,I. Higgins",0,61,0,"https://www.semanticscholar.org/paper/e002bb8dae5a18a5ea1e7e1aafa16e19ad545662"
"b98d6fe8f0ef02ec0d1bb2bcfb924c8f01feb7d4",1,"Convergent Representations of Computer Programs in Human and Artificial Neural Networks","Analysis of brain recordings derived from functional magnetic resonance imaging studies of programmers comprehending Python code suggests at least two distinct neural mechanisms mediating computer program comprehension and evaluation, prompting the design of code model objectives that go beyond static language modeling.","",2022,"Shashank Srikant,Benjamin Lipkin,Anna A. Ivanova,Evelina Fedorenko,Una-May O’Reilly",0,79,0,"https://www.semanticscholar.org/paper/b98d6fe8f0ef02ec0d1bb2bcfb924c8f01feb7d4"
"f9d38e03c97562b5f5942f3a0c43bdb751b9dc1c",1,"Wordplay 2022 The 3rd Wordplay: When Language Meets Games Workshop Proceedings of the Workshop","Novel techniques to generate text in a particular style are described, providing an approach of generating engaging naturalistic conversation responses using knowledge generated by pre-trained language models, considering their recent success in a multitude of NLP tasks.","",2022,"Shrimai Prabhumoye",0,67,0,"https://www.semanticscholar.org/paper/f9d38e03c97562b5f5942f3a0c43bdb751b9dc1c"
"a85c5d7272371345e28a9910080224cad799972e",1,"Schema Matching using Pre-Trained Language Models","The Learned Schema Mapper (LSM) is proposed, a novel linguistic schema matching system that leverages the natural language understanding capabilities of pre-trained language models to improve the overall accuracy and significantly reduce the overall human labeling cost.","",2022,"Yunjia Zhang",0,47,0,"https://www.semanticscholar.org/paper/a85c5d7272371345e28a9910080224cad799972e"
"ae10c4b220a0bc0999bf169d5c219086d1f1aeed",1,"Edinburgh Research Explorer Taxonomy of risks posed by language models","A comprehensive taxonomy of ethical and social risks associated with LMs is developed, drawing on expertise and literature from computer science, linguistics, and the social sciences to ensure that language models are developed responsibly.","",2022,"Laura Weidinger,J. Uesato,M. Rauh,C. Griffin,P. Huang,John F. J. Mellor,A. Glaese,M. Cheng,B. Balle,A. Kasirzadeh,C. Biles,S. Brown,Z. Kenton,W. Hawkins,T. Stepleton,A. Birhane,L. Hendricks,Rimell,Laura Weidinger,J. Uesato,M. Rauh,C. Griffin,John F. J. Mellor,A. Glaese,M. Cheng,B. Balle,A. Kasirzadeh,C. Biles,S. Brown,Z. Kenton,Tom,Stepleton,A. Birhane,Lisa Anne Hendricks,Laura Rimell",0,218,0,"https://www.semanticscholar.org/paper/ae10c4b220a0bc0999bf169d5c219086d1f1aeed"
"60043104ca33a1fc905af57ead32768e52c69103",1,"C3PO: A Lightweight Copying Mechanism for Translating Pseudocode to Code","This work proposes a lightweight alternative to LLMs that exploits the property of code wherein most tokens can be simply copied from the pseudocode, and achieves similar performance to non-C3PO models while reducing the computational cost of training as well as the vocabulary sizes.","AACL",2022,"Vishruth Veerendranath,Vibha Masti,Prajwal Anagani,Mamatha Hr",0,21,0,"https://www.semanticscholar.org/paper/60043104ca33a1fc905af57ead32768e52c69103"
"8a4299a61cc44b60e5be32fef35341c3bc7b2a0d",1,"The Hole Story: Type-Directed Synthesis and Repair","This thesis explores the integration of program synthesis into GHC compiler error messages using typed-hole suggestions to aid the completion of partial programs during development and presents PropR, a tool based on type-driven synthesis aided by propertybased testing and fault-localization in conjunction with genetic algorithms to automatically repair buggy programs.","",2022,"Matthías Páll Gissurarson",0,106,0,"https://www.semanticscholar.org/paper/8a4299a61cc44b60e5be32fef35341c3bc7b2a0d"
"15ef2d1b88f54fa32a32927463a7116219b89529",1,"L EARNING TO S UPEROPTIMIZE R EAL - WORLD P ROGRAMS","","",,"",0,0,0,"https://www.semanticscholar.org/paper/15ef2d1b88f54fa32a32927463a7116219b89529"
"4797e960f8e7a2b47ae0d95c7071ef84fa5d4b5b",1,"Code Generation Using Machine Learning: A Systematic Review","This review provides a broad and detailed overview of studies for code generation using ML, and summarizes the applications, models, datasets, results, limitations, and future work of 37 publications.","IEEE Access",2022,"Enrique Dehaerne,Bappaditya Dey,Sandip Halder,S. De Gendt,Wannes Meert",0,117,0,"https://www.semanticscholar.org/paper/4797e960f8e7a2b47ae0d95c7071ef84fa5d4b5b"
"660ca9e15e19409903a0605f0584d0f263c35c67",1,"S YNCHROMESH : R ELIABLE C ODE G ENERATION FROM P RE - TRAINED L ANGUAGE M ODELS","A framework for substantially improving the reliability of pre-trained models for code generation and observing substantial complementary gains from CSD and TST in prediction accuracy and in effectively preventing run-time errors is proposed.","",2022,"Gabriel Poesia,A. Tiwari,Gustavo Soares,Christopher Meek",0,29,0,"https://www.semanticscholar.org/paper/660ca9e15e19409903a0605f0584d0f263c35c67"
"25c402db512d327f1da143de3b8e797ad6fbfe5b",1,"P ROG P ROMPT : Generating Situated Robot Task Plans using Large Language Models","This work presents a programmatic LLM prompt structure that enables plan generation functional across situated environments, robot capabilities, and tasks, and makes concrete recommendations about prompt structure and generation constraints through ablation experiments.","",2022,"Llm Gpt",0,39,0,"https://www.semanticscholar.org/paper/25c402db512d327f1da143de3b8e797ad6fbfe5b"
"ba5d21b7c65c6598c7bd39a5d992308c205df374",1,"A S YSTEMATIC E VALUATION OF L ARGE L ANGUAGE M ODELS OF C ODE","It is found that existing open-source models do achieve close results in some programming languages, although targeted mainly for natural language modeling, and a new model, PolyCoder, is released that was trained on 249GB of code across 12 programming languages on a single machine.","",2022,"Graham Neubig,V. Hellendoorn",0,33,0,"https://www.semanticscholar.org/paper/ba5d21b7c65c6598c7bd39a5d992308c205df374"
"56e6d62c638a24411f12d15cdc8821a31fc495c8",1,"Source Code Generation from Descriptions in a Natural Language","This work introduces CodeFormer, a Python source code generator pretrained on a massive GitHub crawl consisting of 230M Python functions, and releases the resulting model, built on BART architecture, which generates Python functions based on descriptions in English.","",2022,"Bc. Jan Pašek",0,70,0,"https://www.semanticscholar.org/paper/56e6d62c638a24411f12d15cdc8821a31fc495c8"
"75e36bb95023e55f7dec95d1af557e219ba3d349",1,"CORAL: COde RepresentAtion learning with weakly-supervised transformers for analyzing data analysis","This work proposes a novel weakly supervised transformer-based architecture for computing joint representations of code from both abstract syntax trees and surrounding natural language comments and achieves a 38% increase in accuracy over expert-supplied heuristics and outperforms a suite of baselines.","EPJ Data Science",2020,"Ashley Ge Zhang,Michael Merrill,Yang Liu,Jeffrey Heer,Tim Althoff",7,71,2,"https://www.semanticscholar.org/paper/75e36bb95023e55f7dec95d1af557e219ba3d349"
"8cf3a454556060d6e9aa86dbabf221bd10bf9759",1,"On the Effectiveness of Transfer Learning for Code Search","It is demonstrated that natural language processing models based on the Transformer architecture can be directly applied to source code analysis tasks, such as code search, and the combined use of an information retrieval-based approach followed by a Transformer leads to the best results overall.","IEEE Transactions on Software Engineering",2021,"P. Salza,Christoph Schwizer,Jian Gu,H. Gall",9,86,3,"https://www.semanticscholar.org/paper/8cf3a454556060d6e9aa86dbabf221bd10bf9759"
"6e5eb6167d9766fbb4d14611d15cf95d7b75fb9d",1,"Asleep at the Keyboard? Assessing the Security of GitHub Copilot’s Code Contributions","This work systematically investigates the prevalence and conditions that can cause GitHub Copilot to recommend insecure code, and explores Copilot’s performance on three distinct code generation axes—examining how it performs given diversity of weaknesses, diversity of prompts, and diversity of domains.","IEEE Symposium on Security and Privacy",2021,"H. Pearce,Baleegh Ahmad,Benjamin Tan,Brendan Dolan-Gavitt,R. Karri",26,35,4,"https://www.semanticscholar.org/paper/6e5eb6167d9766fbb4d14611d15cf95d7b75fb9d"
"a1e1297fb132d7769dda3f7917e57757e6e22605",1,"Impact of Evaluation Methodologies on Code Summarization","The time-segmented evaluation methodology is introduced, which is novel to the code summarization research community, and compared with the mixed-project and cross-project methodologies that have been commonly used and shows that different methodologies lead to conflicting evaluation results.","Annual Meeting of the Association for Computational Linguistics",2021,"Pengyu Nie,Jiyang Zhang,Junyi Jessy Li,R. Mooney,Miloš Gligorić",3,56,0,"https://www.semanticscholar.org/paper/a1e1297fb132d7769dda3f7917e57757e6e22605"
"ff0b2681d7b05e16c46dfb71d980cc2f605907cd",1,"Finetuned Language Models Are Zero-Shot Learners","It is shown that instruction tuning —ﬁnetuning language models on a collection of datasets described via instructions—substantially improves zero-shot performance on unseen tasks and outperforms few-shot GPT-3 by a large margin on ANLI, RTE, BoolQ, AI2-ARC, OpenbookQA, and StoryCloze.","International Conference on Learning Representations",2021,"Jason Wei,Maarten Bosma,Vincent Zhao,Kelvin Guu,A. Yu,Brian Lester,Nan Du,Andrew M. Dai,Quoc V. Le",326,167,74,"https://www.semanticscholar.org/paper/ff0b2681d7b05e16c46dfb71d980cc2f605907cd"
"77d956cdab4508d569ae5741549b78e715fd0749",1,"TruthfulQA: Measuring How Models Mimic Human Falsehoods","It is suggested that scaling up models alone is less promising for improving truthfulness than fine-tuning using training objectives other than imitation of text from the web.","Annual Meeting of the Association for Computational Linguistics",2021,"Stephanie C. Lin,Jacob Hilton,Owain Evans",69,70,12,"https://www.semanticscholar.org/paper/77d956cdab4508d569ae5741549b78e715fd0749"
"2672777d25562c9df6fc13b653181db62d39bece",1,"An Empirical Study of GPT-3 for Few-Shot Knowledge-Based VQA","This work proposes PICa, a simple yet effective method that Prompts GPT3 via the use of Image Captions, for knowledge-based VQA, and treats GPT-3 as an implicit and unstructured KB that can jointly acquire and process relevant knowledge.","AAAI Conference on Artificial Intelligence",2021,"Zhengyuan Yang,Zhe Gan,Jianfeng Wang,Xiaowei Hu,Yumao Lu,Zicheng Liu,Lijuan Wang",54,42,20,"https://www.semanticscholar.org/paper/2672777d25562c9df6fc13b653181db62d39bece"
"c6bb04f3d8000b7e800f6359082de39548c7da79",1,"Capturing Structural Locality in Non-parametric Language Models","This paper proposes a simple yet effective approach for adding locality information into non-parametric language models by adding learned parameters that improve the likelihood of retrieving examples from local neighborhoods.","International Conference on Learning Representations",2021,"Frank F. Xu,Junxian He,Graham Neubig,V. Hellendoorn",5,47,0,"https://www.semanticscholar.org/paper/c6bb04f3d8000b7e800f6359082de39548c7da79"
"a421ba0a9150cd35e231dddc323bdd9a59b3af93",1,"Coherence boosting: When your pretrained language model is not paying enough attention","It is found that coherence boosting with state-of-the-art models for various zero-shot NLP tasks yields performance gains with no additional training.","Annual Meeting of the Association for Computational Linguistics",2021,"Nikolay Malkin,Zhen Wang,N. Jojic",4,64,1,"https://www.semanticscholar.org/paper/a421ba0a9150cd35e231dddc323bdd9a59b3af93"
"1cbb3d96242c3f47c3f40aada33616d0f5c07737",1,"Inductive Biases and Variable Creation in Self-Attention Mechanisms","The main result shows that bounded-norm Transformer networks “cre-ate sparse variables”: a single self-attention head can represent a sparse function of the input sequence, with sample complexity scaling only logarithmically with the context length.","International Conference on Machine Learning",2021,"Benjamin Edelman,Surbhi Goel,S. Kakade,Cyril Zhang",11,74,3,"https://www.semanticscholar.org/paper/1cbb3d96242c3f47c3f40aada33616d0f5c07737"
"231e768f0cd280faa0f725bb353262cb4fed08d1",1,"Hierarchical Transformers Are More Efficient Language Models","Hourglass is a hierarchical Transformer language model that sets new state-of-the-art for Transformer models on the ImageNet32 generation task and improves language modeling efﬁciency on the widely studied enwik8 benchmark.","NAACL-HLT",2021,"Piotr Nawrot,Szymon Tworkowski,Michal Tyrolski,Lukasz Kaiser,Yuhuai Wu,Christian Szegedy,H. Michalewski",13,38,1,"https://www.semanticscholar.org/paper/231e768f0cd280faa0f725bb353262cb4fed08d1"
"8417d83e74a63b9d3874cd7695477ebad8b98f8a",1,"Choose your programming copilot: a comparison of the program synthesis performance of github copilot and genetic programming","It is found that the performance of the two approaches on the benchmark problems is quite similar, however, in comparison to GitHub Copilot, the program synthesis approaches based on genetic programming are not yet mature enough to support programmers in practical software development.","Annual Conference on Genetic and Evolutionary Computation",2021,"D. Sobania,Martin Briesch,Franz Rothlauf",14,38,0,"https://www.semanticscholar.org/paper/8417d83e74a63b9d3874cd7695477ebad8b98f8a"
"ecb5a6fe2f5261e4e717ece1e82c464c63cb4862",1,"Controlling Conditional Language Models without Catastrophic Forgetting","DPG is extended to conditional tasks by proposing Conditional DPG (CDPG), and results show thatne-tuning using CDPG robustly moves these pretrained models closer towards meeting control objectives and — in contrast with baseline approaches — does not result in catastrophic forgetting.","ICML",2021,"Tomasz Korbak,Hady ElSahar,Germán Kruszewski,Marc Dymetman",6,37,0,"https://www.semanticscholar.org/paper/ecb5a6fe2f5261e4e717ece1e82c464c63cb4862"
"d095f9ffcb5905bf0858ad1769d3d90e2e8737e2",1,"Jigsaw: Large Language Models meet Program Synthesis","This paper presents an approach to augment these large language models with post-processing steps based on program analysis and synthesis techniques, that understand the syntax and semantics of programs, and presents the experiences from building and evaluating such a tool Jigsaw.","International Conference on Software Engineering",2021,"Naman Jain,Skanda Vaidyanath,Arun Shankar Iyer,Nagarajan Natarajan,Suresh Parthasarathy,S. Rajamani,Rahul Sharma",21,42,1,"https://www.semanticscholar.org/paper/d095f9ffcb5905bf0858ad1769d3d90e2e8737e2"
"6e8f8e2d2c73c91d1c9198eb802f1c64b860ea4a",1,"Few-Shot Semantic Parsing with Language Models Trained on Code","This paper evaluates OpenAI Codex on Overnight and SMCalFlow and finds that unlike GPT-3, Codex performs similarly when targeting meaning representations directly, perhaps because meaning representations are structured similar to code in these datasets.","North American Chapter of the Association for Computational Linguistics",2021,"Richard Shin,Benjamin Van Durme",16,18,3,"https://www.semanticscholar.org/paper/6e8f8e2d2c73c91d1c9198eb802f1c64b860ea4a"